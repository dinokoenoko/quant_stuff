{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e3c212-0a42-4c89-b124-25d13a23bc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from folder: C:\\Users\\TESLA\\Desktop\\datasets\\bist_100_2010-2025_daily\n",
      "============================================================\n",
      "Found 100 CSV files\n",
      "\n",
      "✓ Loaded: AEFES - 4016 rows\n",
      "✓ Loaded: AGHOL - 4016 rows\n",
      "✓ Loaded: AKBNK - 4016 rows\n",
      "✓ Loaded: AKSA - 4016 rows\n",
      "✓ Loaded: AKSEN - 3918 rows\n",
      "  ... loading remaining files ...\n",
      "\n",
      "============================================================\n",
      "Successfully loaded: 100/100 files\n",
      "\n",
      "Stocks loaded: ['AEFES', 'AGHOL', 'AKBNK', 'AKSA', 'AKSEN', 'ALARK', 'ALTNY', 'ANSGR', 'ARCLK', 'ASELS']...\n",
      "\n",
      "============================================================\n",
      "Structuring data for Alpha101...\n",
      "============================================================\n",
      "\n",
      "Cleaning and parsing data...\n",
      "Date range: 2010-01-04 00:00:00 to 2025-12-31 00:00:00\n",
      "Total unique dates: 4016\n",
      "\n",
      "Creating OHLCV DataFrames...\n",
      "✓ Data structuring complete\n",
      "\n",
      "============================================================\n",
      "DATA SUMMARY\n",
      "============================================================\n",
      "Number of stocks: 100\n",
      "Date range: 2010-01-04 to 2025-12-31\n",
      "Total trading days: 4016\n",
      "\n",
      "Data completeness by field:\n",
      "  Open: 72.92% complete (108,735 missing)\n",
      "  High: 72.92% complete (108,735 missing)\n",
      "  Low: 72.92% complete (108,735 missing)\n",
      "  Close: 72.92% complete (108,735 missing)\n",
      "  Volume: 72.92% complete (108,736 missing)\n",
      "\n",
      "Data completeness by stock (top 10 most complete):\n",
      "  AEFES: 100.00%\n",
      "  AGHOL: 100.00%\n",
      "  AKBNK: 100.00%\n",
      "  AKSA: 100.00%\n",
      "  ALARK: 100.00%\n",
      "  ANSGR: 100.00%\n",
      "  ARCLK: 100.00%\n",
      "  BIMAS: 100.00%\n",
      "  BRSAN: 100.00%\n",
      "  BRYAT: 100.00%\n",
      "\n",
      "Sample data (Close prices - first 5 dates, first 10 stocks):\n",
      "            AEFES  AGHOL  AKBNK  AKSA  AKSEN  ALARK  ALTNY  ANSGR  ARCLK  \\\n",
      "2010-01-04   1.09   0.79   4.36  0.04    NaN  1.451    NaN  0.209   3.85   \n",
      "2010-01-05   1.07   0.80   4.42  0.04    NaN  1.487    NaN  0.214   4.02   \n",
      "2010-01-06   1.09   0.80   4.40  0.04    NaN  1.530    NaN  0.215   4.08   \n",
      "2010-01-07   1.09   0.82   4.38  0.05    NaN  1.581    NaN  0.218   4.02   \n",
      "2010-01-08   1.09   0.82   4.36  0.04    NaN  1.588    NaN  0.226   3.95   \n",
      "\n",
      "            ASELS  \n",
      "2010-01-04   0.34  \n",
      "2010-01-05   0.34  \n",
      "2010-01-06   0.33  \n",
      "2010-01-07   0.36  \n",
      "2010-01-08   0.35  \n",
      "\n",
      "✓ Data saved to: bist100_data.pkl\n",
      "  Stocks: 100\n",
      "  Date range: 2010-01-04 00:00:00 to 2025-12-31 00:00:00\n",
      "  File size: 15.38 MB\n",
      "\n",
      "============================================================\n",
      "EXAMPLE: Getting AEFES data\n",
      "============================================================\n",
      "            Open  High   Low  Close     Volume\n",
      "2010-01-04  1.09  1.09  1.07   1.09  1430000.0\n",
      "2010-01-05  1.09  1.09  1.07   1.07  4370000.0\n",
      "2010-01-06  1.07  1.09  1.06   1.09  3430000.0\n",
      "2010-01-07  1.09  1.10  1.07   1.09  2580000.0\n",
      "2010-01-08  1.10  1.10  1.08   1.09  4360000.0\n",
      "2010-01-11  1.10  1.10  1.07   1.07  5920000.0\n",
      "2010-01-12  1.08  1.09  1.07   1.09  3630000.0\n",
      "2010-01-13  1.09  1.10  1.08   1.09  4210000.0\n",
      "2010-01-14  1.10  1.10  1.08   1.08  4260000.0\n",
      "2010-01-15  1.09  1.09  1.06   1.07  4780000.0\n",
      "\n",
      "============================================================\n",
      "EXAMPLE: Getting all close prices\n",
      "============================================================\n",
      "Shape: (4016, 100)\n",
      "            AEFES  AGHOL  AKBNK  AKSA  AKSEN  ALARK  ALTNY  ANSGR  ARCLK  \\\n",
      "2010-01-04   1.09   0.79   4.36  0.04    NaN  1.451    NaN  0.209   3.85   \n",
      "2010-01-05   1.07   0.80   4.42  0.04    NaN  1.487    NaN  0.214   4.02   \n",
      "2010-01-06   1.09   0.80   4.40  0.04    NaN  1.530    NaN  0.215   4.08   \n",
      "2010-01-07   1.09   0.82   4.38  0.05    NaN  1.581    NaN  0.218   4.02   \n",
      "2010-01-08   1.09   0.82   4.36  0.04    NaN  1.588    NaN  0.226   3.95   \n",
      "\n",
      "            ASELS  ...  TUKAS  TUPRS  TUREX  TURSG  ULKER  VAKBN  VESTL  \\\n",
      "2010-01-04   0.34  ...  0.048   1.65    NaN  0.195   2.75  4.094  2.158   \n",
      "2010-01-05   0.34  ...  0.050   1.68    NaN  0.201   2.78  4.039  2.142   \n",
      "2010-01-06   0.33  ...  0.050   1.68    NaN  0.207   2.87  4.020  2.299   \n",
      "2010-01-07   0.36  ...  0.051   1.68    NaN  0.206   2.87  4.113  2.252   \n",
      "2010-01-08   0.35  ...  0.051   1.64    NaN  0.204   2.86  4.039  2.221   \n",
      "\n",
      "            YEOTK  YKBNK  ZOREN  \n",
      "2010-01-04    NaN  1.667  1.052  \n",
      "2010-01-05    NaN  1.738  1.079  \n",
      "2010-01-06    NaN  1.748  1.085  \n",
      "2010-01-07    NaN  1.768  1.112  \n",
      "2010-01-08    NaN  1.758  1.105  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "\n",
      "============================================================\n",
      "READY FOR ALPHA101!\n",
      "============================================================\n",
      "\n",
      "You can now use this with your Alpha101 class:\n",
      "\n",
      "from alpha101 import Alpha101\n",
      "\n",
      "alpha = Alpha101(\n",
      "    open=loader.data['open'],\n",
      "    high=loader.data['high'],\n",
      "    low=loader.data['low'],\n",
      "    close=loader.data['close'],\n",
      "    volume=loader.data['volume']\n",
      ")\n",
      "\n",
      "# Calculate any alpha factor\n",
      "alpha_001 = alpha.alpha001()\n",
      "alpha_002 = alpha.alpha002()\n",
      "# ... etc\n",
      "    \n",
      "\n",
      "============================================================\n",
      "NEXT TIME: Fast loading from pickle\n",
      "============================================================\n",
      "\n",
      "# Instead of loading all CSV files again, just load the pickle:\n",
      "loader = StockDataLoader('dummy_path')  # Path not used when loading pickle\n",
      "loader.load_structured_data('bist100_data.pkl')\n",
      "loader.summary()\n",
      "\n",
      "# Then use with Alpha101 as before\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class StockDataLoader:\n",
    "    \"\"\"\n",
    "    Loads and organizes multi-stock historical data from separate CSV files.\n",
    "    Designed for Investing.com Turkish stock data format.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "        \"\"\"\n",
    "        Initialize the data loader.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        folder_path : str\n",
    "            Path to the folder containing individual stock CSV files\n",
    "        \"\"\"\n",
    "        self.folder_path = folder_path\n",
    "        self.raw_data = {}\n",
    "        self.data = None\n",
    "        self.stocks = []\n",
    "        \n",
    "    def load_all_files(self, pattern=\"Geçmiş Verileri\"):\n",
    "        \"\"\"\n",
    "        Load all CSV files from the folder.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pattern : str\n",
    "            Pattern to identify stock data files (default: \"Geçmiş Verileri\")\n",
    "        \"\"\"\n",
    "        print(f\"Loading data from folder: {self.folder_path}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get all CSV files matching the pattern\n",
    "        all_files = os.listdir(self.folder_path)\n",
    "        csv_files = [f for f in all_files if f.endswith('.csv') and pattern in f]\n",
    "        \n",
    "        print(f\"Found {len(csv_files)} CSV files\\n\")\n",
    "        \n",
    "        if len(csv_files) == 0:\n",
    "            print(f\"ERROR: No CSV files found with pattern '{pattern}'\")\n",
    "            return None\n",
    "        \n",
    "        # Load each file\n",
    "        loaded_count = 0\n",
    "        failed_files = []\n",
    "        \n",
    "        for filename in csv_files:\n",
    "            try:\n",
    "                # Extract ticker from filename (e.g., \"AEFES Geçmiş Verileri.csv\" -> \"AEFES\")\n",
    "                ticker = filename.split(' ')[0].strip()\n",
    "                \n",
    "                # Load the CSV\n",
    "                filepath = os.path.join(self.folder_path, filename)\n",
    "                df = pd.read_csv(filepath)\n",
    "                \n",
    "                # Store in dictionary\n",
    "                self.raw_data[ticker] = df\n",
    "                loaded_count += 1\n",
    "                \n",
    "                if loaded_count <= 5:  # Show first 5 files\n",
    "                    print(f\"✓ Loaded: {ticker} - {len(df)} rows\")\n",
    "                elif loaded_count == 6:\n",
    "                    print(f\"  ... loading remaining files ...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                failed_files.append((filename, str(e)))\n",
    "                print(f\"✗ Failed: {filename} - {str(e)}\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Successfully loaded: {loaded_count}/{len(csv_files)} files\")\n",
    "        \n",
    "        if failed_files:\n",
    "            print(f\"\\nFailed files ({len(failed_files)}):\")\n",
    "            for fname, error in failed_files:\n",
    "                print(f\"  - {fname}: {error}\")\n",
    "        \n",
    "        self.stocks = sorted(list(self.raw_data.keys()))\n",
    "        print(f\"\\nStocks loaded: {self.stocks[:10]}...\" if len(self.stocks) > 10 else f\"\\nStocks loaded: {self.stocks}\")\n",
    "        \n",
    "        return self.raw_data\n",
    "    \n",
    "    def structure_data(self):\n",
    "        \"\"\"\n",
    "        Structure the loaded data into OHLCV format for Alpha101.\n",
    "        Handles Investing.com Turkish format:\n",
    "        Tarih | Şimdi (Close) | Açılış (Open) | Yüksek (High) | Düşük (Low) | Hac. (Volume) | Fark %\n",
    "        \"\"\"\n",
    "        if not self.raw_data:\n",
    "            raise ValueError(\"No data loaded. Call load_all_files() first.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Structuring data for Alpha101...\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Initialize data containers\n",
    "        all_dates = set()\n",
    "        \n",
    "        # First pass: collect all unique dates and clean data\n",
    "        print(\"\\nCleaning and parsing data...\")\n",
    "        for ticker in self.stocks:\n",
    "            df = self.raw_data[ticker].copy()\n",
    "            \n",
    "            # Parse date (Investing.com uses Turkish date format)\n",
    "            df['Tarih'] = pd.to_datetime(df['Tarih'], format='%d.%m.%Y', errors='coerce')\n",
    "            \n",
    "            # Clean numeric columns (remove dots used as thousands separator, convert commas to dots)\n",
    "            numeric_cols = ['Şimdi', 'Açılış', 'Yüksek', 'Düşük']\n",
    "            for col in numeric_cols:\n",
    "                if col in df.columns:\n",
    "                    df[col] = df[col].astype(str).str.replace('.', '', regex=False)  # Remove thousands separator\n",
    "                    df[col] = df[col].str.replace(',', '.', regex=False)  # Convert comma to dot\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Clean volume (remove 'M', 'K', 'B' suffixes and convert)\n",
    "            if 'Hac.' in df.columns:\n",
    "                def parse_volume(vol_str):\n",
    "                    if pd.isna(vol_str) or vol_str == '-':\n",
    "                        return np.nan\n",
    "                    vol_str = str(vol_str).replace('.', '').replace(',', '.')\n",
    "                    \n",
    "                    multiplier = 1\n",
    "                    if 'M' in vol_str:\n",
    "                        multiplier = 1_000_000\n",
    "                        vol_str = vol_str.replace('M', '')\n",
    "                    elif 'B' in vol_str:  # Billion\n",
    "                        multiplier = 1_000_000_000\n",
    "                        vol_str = vol_str.replace('B', '')\n",
    "                    elif 'K' in vol_str:\n",
    "                        multiplier = 1_000\n",
    "                        vol_str = vol_str.replace('K', '')\n",
    "                    \n",
    "                    try:\n",
    "                        return float(vol_str) * multiplier\n",
    "                    except:\n",
    "                        return np.nan\n",
    "                \n",
    "                df['Hac.'] = df['Hac.'].apply(parse_volume)\n",
    "            \n",
    "            # Drop rows with invalid dates\n",
    "            df = df.dropna(subset=['Tarih'])\n",
    "            \n",
    "            # Sort by date\n",
    "            df = df.sort_values('Tarih')\n",
    "            \n",
    "            # Store cleaned data\n",
    "            self.raw_data[ticker] = df\n",
    "            \n",
    "            # Collect all dates\n",
    "            all_dates.update(df['Tarih'].tolist())\n",
    "        \n",
    "        # Create a complete date range\n",
    "        all_dates = sorted(list(all_dates))\n",
    "        date_index = pd.DatetimeIndex(all_dates)\n",
    "        \n",
    "        print(f\"Date range: {date_index.min()} to {date_index.max()}\")\n",
    "        print(f\"Total unique dates: {len(date_index)}\")\n",
    "        \n",
    "        # Create DataFrames for each OHLCV field\n",
    "        print(\"\\nCreating OHLCV DataFrames...\")\n",
    "        self.data = {\n",
    "            'open': pd.DataFrame(index=date_index, columns=self.stocks, dtype=float),\n",
    "            'high': pd.DataFrame(index=date_index, columns=self.stocks, dtype=float),\n",
    "            'low': pd.DataFrame(index=date_index, columns=self.stocks, dtype=float),\n",
    "            'close': pd.DataFrame(index=date_index, columns=self.stocks, dtype=float),\n",
    "            'volume': pd.DataFrame(index=date_index, columns=self.stocks, dtype=float)\n",
    "        }\n",
    "        \n",
    "        # Fill in the data for each stock\n",
    "        for ticker in self.stocks:\n",
    "            df = self.raw_data[ticker]\n",
    "            \n",
    "            if len(df) > 0:\n",
    "                # Set date as index\n",
    "                df = df.set_index('Tarih')\n",
    "                \n",
    "                # Map to OHLCV\n",
    "                if 'Açılış' in df.columns:\n",
    "                    self.data['open'][ticker] = df['Açılış']\n",
    "                if 'Yüksek' in df.columns:\n",
    "                    self.data['high'][ticker] = df['Yüksek']\n",
    "                if 'Düşük' in df.columns:\n",
    "                    self.data['low'][ticker] = df['Düşük']\n",
    "                if 'Şimdi' in df.columns:\n",
    "                    self.data['close'][ticker] = df['Şimdi']\n",
    "                if 'Hac.' in df.columns:\n",
    "                    self.data['volume'][ticker] = df['Hac.']\n",
    "        \n",
    "        print(\"✓ Data structuring complete\")\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def get_stock_data(self, ticker):\n",
    "        \"\"\"\n",
    "        Get all OHLCV data for a specific stock.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        ticker : str\n",
    "            Stock ticker symbol\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame with columns: Open, High, Low, Close, Volume\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Data not structured. Call structure_data() first.\")\n",
    "        \n",
    "        if ticker not in self.stocks:\n",
    "            raise ValueError(f\"Ticker {ticker} not found. Available: {self.stocks}\")\n",
    "        \n",
    "        stock_df = pd.DataFrame({\n",
    "            'Open': self.data['open'][ticker],\n",
    "            'High': self.data['high'][ticker],\n",
    "            'Low': self.data['low'][ticker],\n",
    "            'Close': self.data['close'][ticker],\n",
    "            'Volume': self.data['volume'][ticker]\n",
    "        })\n",
    "        \n",
    "        return stock_df\n",
    "    \n",
    "    def get_field_data(self, field='close'):\n",
    "        \"\"\"\n",
    "        Get data for all stocks for a specific field.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        field : str\n",
    "            One of: 'open', 'high', 'low', 'close', 'volume'\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame with columns as stock tickers, rows as dates\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Data not structured. Call structure_data() first.\")\n",
    "        \n",
    "        if field not in self.data:\n",
    "            raise ValueError(f\"Field {field} not found. Available: {list(self.data.keys())}\")\n",
    "        \n",
    "        return self.data[field]\n",
    "    \n",
    "    def save_structured_data(self, output_path='bist100_structured_data.pkl'):\n",
    "        \"\"\"\n",
    "        Save the structured data to a pickle file for fast loading.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        output_path : str\n",
    "            Path to save the pickle file\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"No data to save. Load and structure data first.\")\n",
    "        \n",
    "        save_dict = {\n",
    "            'data': self.data,\n",
    "            'stocks': self.stocks,\n",
    "            'date_range': (self.data['close'].index.min(), \n",
    "                          self.data['close'].index.max())\n",
    "        }\n",
    "        \n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump(save_dict, f)\n",
    "        \n",
    "        print(f\"\\n✓ Data saved to: {output_path}\")\n",
    "        print(f\"  Stocks: {len(self.stocks)}\")\n",
    "        print(f\"  Date range: {save_dict['date_range'][0]} to {save_dict['date_range'][1]}\")\n",
    "        \n",
    "        # Get file size\n",
    "        file_size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "        print(f\"  File size: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "    def load_structured_data(self, input_path='bist100_structured_data.pkl'):\n",
    "        \"\"\"\n",
    "        Load previously saved structured data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_path : str\n",
    "            Path to the pickle file\n",
    "        \"\"\"\n",
    "        with open(input_path, 'rb') as f:\n",
    "            save_dict = pickle.load(f)\n",
    "        \n",
    "        self.data = save_dict['data']\n",
    "        self.stocks = save_dict['stocks']\n",
    "        \n",
    "        print(f\"\\n✓ Data loaded from: {input_path}\")\n",
    "        print(f\"  Stocks: {len(self.stocks)}\")\n",
    "        print(f\"  Date range: {save_dict['date_range'][0]} to {save_dict['date_range'][1]}\")\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"Print a summary of the loaded data.\"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data structured. Call structure_data() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATA SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Number of stocks: {len(self.stocks)}\")\n",
    "        print(f\"Date range: {self.data['close'].index.min().strftime('%Y-%m-%d')} to {self.data['close'].index.max().strftime('%Y-%m-%d')}\")\n",
    "        print(f\"Total trading days: {len(self.data['close'])}\")\n",
    "        \n",
    "        print(f\"\\nData completeness by field:\")\n",
    "        for field in ['open', 'high', 'low', 'close', 'volume']:\n",
    "            total_cells = len(self.data[field]) * len(self.stocks)\n",
    "            missing_cells = self.data[field].isnull().sum().sum()\n",
    "            complete_pct = ((total_cells - missing_cells) / total_cells) * 100\n",
    "            print(f\"  {field.capitalize()}: {complete_pct:.2f}% complete ({int(missing_cells):,} missing)\")\n",
    "        \n",
    "        print(f\"\\nData completeness by stock (top 10 most complete):\")\n",
    "        stock_completeness = {}\n",
    "        for stock in self.stocks:\n",
    "            total = len(self.data['close'])\n",
    "            missing = self.data['close'][stock].isnull().sum()\n",
    "            completeness = ((total - missing) / total) * 100\n",
    "            stock_completeness[stock] = completeness\n",
    "        \n",
    "        sorted_stocks = sorted(stock_completeness.items(), key=lambda x: x[1], reverse=True)\n",
    "        for stock, completeness in sorted_stocks[:10]:\n",
    "            print(f\"  {stock}: {completeness:.2f}%\")\n",
    "        \n",
    "        print(f\"\\nSample data (Close prices - first 5 dates, first 10 stocks):\")\n",
    "        sample_stocks = self.stocks[:10]\n",
    "        print(self.data['close'][sample_stocks].head())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the loader with your folder path\n",
    "    folder_path = r'C:\\Users\\TESLA\\Desktop\\datasets\\bist_100_2010-2025_daily'\n",
    "    \n",
    "    loader = StockDataLoader(folder_path)\n",
    "    \n",
    "    # Load all CSV files\n",
    "    loader.load_all_files(pattern=\"Geçmiş Verileri\")\n",
    "    \n",
    "    # Structure the data for Alpha101\n",
    "    loader.structure_data()\n",
    "    \n",
    "    # Print summary\n",
    "    loader.summary()\n",
    "    \n",
    "    # Save structured data for future use (much faster to load next time!)\n",
    "    loader.save_structured_data('bist100_data.pkl')\n",
    "    \n",
    "    # ============================================================\n",
    "    # EXAMPLE USAGE\n",
    "    # ============================================================\n",
    "    \n",
    "    # Get data for a specific stock\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE: Getting AEFES data\")\n",
    "    print(\"=\"*60)\n",
    "    aefes_data = loader.get_stock_data('AEFES')\n",
    "    print(aefes_data.head(10))\n",
    "    \n",
    "    # Get close prices for all stocks\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE: Getting all close prices\")\n",
    "    print(\"=\"*60)\n",
    "    all_closes = loader.get_field_data('close')\n",
    "    print(f\"Shape: {all_closes.shape}\")\n",
    "    print(all_closes.head())\n",
    "    \n",
    "    # ============================================================\n",
    "    # READY FOR ALPHA101\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"READY FOR ALPHA101!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nYou can now use this with your Alpha101 class:\")\n",
    "    print(\"\"\"\n",
    "from alpha101 import Alpha101\n",
    "\n",
    "alpha = Alpha101(\n",
    "    open=loader.data['open'],\n",
    "    high=loader.data['high'],\n",
    "    low=loader.data['low'],\n",
    "    close=loader.data['close'],\n",
    "    volume=loader.data['volume']\n",
    ")\n",
    "\n",
    "# Calculate any alpha factor\n",
    "alpha_001 = alpha.alpha001()\n",
    "alpha_002 = alpha.alpha002()\n",
    "# ... etc\n",
    "    \"\"\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # NEXT TIME: FAST LOADING\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NEXT TIME: Fast loading from pickle\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\"\"\n",
    "# Instead of loading all CSV files again, just load the pickle:\n",
    "loader = StockDataLoader('dummy_path')  # Path not used when loading pickle\n",
    "loader.load_structured_data('bist100_data.pkl')\n",
    "loader.summary()\n",
    "\n",
    "# Then use with Alpha101 as before\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56ce2a1e-acc5-4b41-a6d3-80476b16f335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCOMPLETE BREAKDOWN BY DATA REQUIREMENTS:\\n\\n✓ MONTHLY-COMPATIBLE (24 alphas):\\nAlphas 3, 4, 9, 10, 12, 13, 15, 16, 22, 23, 24, 26, 30, 33, 40, 44, 45, 46, \\n49, 51, 53, 54, 55, 60, 83, 101\\n\\nThese work with basic monthly OHLCV data (open can be approximated).\\n\\n✗ REQUIRES VWAP (39 alphas):\\nAlphas 5, 11, 25, 27, 32, 41, 42, 47, 50, 57, 61, 62, 63, 64, 65, 66, 67, 69, \\n71, 72, 73, 74, 77, 78, 79, 81, 84, 86, 87, 89, 91, 93, 94, 96, 97, 98\\n\\nVWAP = Volume-Weighted Average Price (intraday calculation)\\n\\n✗ REQUIRES INDUSTRY CLASSIFICATION (26 alphas):\\nAlphas 48, 58, 59, 63, 67, 69, 70, 76, 79, 80, 82, 87, 89, 90, 91, 93, 97, 100\\n\\nNeeds sector/industry data for neutralization\\n\\n✗ REQUIRES DAILY DATA - ADV (Average Daily Volume) (68 alphas):\\nAlphas 1, 2, 7, 8, 14, 17, 19, 21, 25, 28, 29, 31, 34, 35, 36, 39, 43, 47, 52, \\n56, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, \\n82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100\\n\\nADV = Average Daily Volume over N days (adv5, adv10, adv20, adv30, adv40, \\nadv50, adv60, adv81, adv120, adv150, adv180)\\n\\n✗ REQUIRES ACCURATE OPEN PRICES (21 alphas):\\nAlphas 2, 3, 6, 8, 14, 18, 20, 33, 36, 37, 38, 54, 65, 66, 73, 82, 92, 95, 98, 101\\n\\nMost alphas work with approximated open, but these need precise opening prices\\n\\n✗ REQUIRES DAILY RETURNS (15 alphas):\\nAlphas 1, 8, 14, 19, 29, 34, 35, 39, 52, 56\\n\\nNeed daily return calculations for proper signal\\n\\n✗ REQUIRES MARKET CAP (1 alpha):\\nAlpha 56\\n\\nNeeds market capitalization data\\n\\nCATEGORIZED SUMMARY:\\n====================\\n• Works with Monthly Data Only: 24/101 (24%)\\n• Needs Daily Data: 68/101 (67%)\\n• Needs VWAP: 39/101 (39%)\\n• Needs Industry Data: 26/101 (26%)\\n• Needs Special Data: Multiple requirements overlap\\n\\nKEY INSIGHT:\\nThe 101 Alphas were designed for HIGH-FREQUENCY trading with:\\n- Tick/minute data for VWAP calculation\\n- Daily data for ADV calculations  \\n- Industry classifications for market-neutral strategies\\n- High-quality open prices from market open\\n\\nFor MONTHLY data analysis, only 24 alphas work reliably.\\n\\nRECOMMENDATION:\\n===============\\n1. If you have MONTHLY data → Use the 24 monthly-compatible alphas OR \\n   the custom alphas in AlphaBacktester (better adapted for monthly frequency)\\n\\n2. If you get DAILY data → Use all applicable alphas (those not requiring VWAP/industry)\\n\\n3. If you have INTRADAY data + VWAP → Most alphas become available\\n\\n4. If you have INDUSTRY classifications → All non-VWAP alphas work\\n\\nMONTHLY-COMPATIBLE ALPHAS DETAIL:\\n==================================\\nAlpha 3:  -1 * correlation(rank(open), rank(volume), 10)\\nAlpha 4:  -1 * Ts_Rank(rank(low), 9)\\nAlpha 9:  Conditional on delta(close, 1) with ts_min/ts_max\\nAlpha 10: rank of Alpha 9\\nAlpha 12: sign(delta(volume, 1)) * (-1 * delta(close, 1))\\nAlpha 13: -1 * rank(covariance(rank(close), rank(volume), 5))\\nAlpha 15: -1 * sum(rank(correlation(rank(high), rank(volume), 3)), 3)\\nAlpha 16: -1 * rank(covariance(rank(high), rank(volume), 5))\\nAlpha 22: -1 * (delta(correlation(high, volume, 5), 5) * rank(stddev(close, 20)))\\nAlpha 23: Conditional with high moving average\\nAlpha 24: Conditional with close moving average\\nAlpha 26: -1 * ts_max(correlation(ts_rank(volume, 5), ts_rank(high, 5), 5), 3)\\nAlpha 30: Sign-based with volume ratios\\nAlpha 33: rank(-1 * ((1 - (open / close))^1))\\nAlpha 40: (-1 * rank(stddev(high, 10))) * correlation(high, volume, 10)\\nAlpha 44: -1 * correlation(high, rank(volume), 5)\\nAlpha 45: Complex correlation with delays\\nAlpha 46: Conditional on moving average slopes (threshold 0.25)\\nAlpha 49: Conditional on moving average slopes (threshold -0.1)\\nAlpha 51: Conditional on moving average slopes (threshold -0.05)\\nAlpha 53: -1 * delta((((close - low) - (high - close)) / (close - low)), 9)\\nAlpha 54: Complex open-close power ratio\\nAlpha 55: -1 * correlation(rank(price range), rank(volume), 6)\\nAlpha 60: Scale and rank with volume weighting\\nAlpha 83: Complex ratio with delays (if VWAP approximated)\\nAlpha 101: (close - open) / ((high - low) + .001)\\nOther Alphas from academic sources such as EDHEC Kit, specified for monthly returns\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from scipy.stats import rankdata\n",
    "        \n",
    "        \"\"\"\n",
    "        WorldQuant 101 Alphas and additional academic alphas- Complete Implementation\n",
    "        ================================================\n",
    "        \n",
    "        Data Requirements Legend:\n",
    "        ✓ MONTHLY_OK: Works with monthly OHLCV data\n",
    "        ✗ DAILY_REQUIRED: Requires daily data\n",
    "        ✗ VWAP_REQUIRED: Requires VWAP (Volume Weighted Average Price)\n",
    "        ✗ INDUSTRY_REQUIRED: Requires industry/sector classification\n",
    "        ✗ OPEN_REQUIRED: Requires accurate open prices (not approximated)\n",
    "        \n",
    "        Note: Most alphas require daily data. Monthly adaptations are marked.\n",
    "        \"\"\"\n",
    "        \n",
    "        class Alpha101:\n",
    "            \"\"\"\n",
    "            Implementation of WorldQuant's 101 Formulaic Alphas\n",
    "            \n",
    "            Data columns expected:\n",
    "            - symbol: stock identifier\n",
    "            - date: timestamp\n",
    "            - open, high, low, close: OHLC prices\n",
    "            - volume: trading volume\n",
    "            - vwap: volume-weighted average price (if available)\n",
    "            - returns: periodic returns\n",
    "            - industry/sector: classification (if available)\n",
    "            - adv{N}: average daily volume for N days\n",
    "            \"\"\"\n",
    "            \n",
    "            def __init__(self, data):\n",
    "                self.data = data\n",
    "                self.data = self.data.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
    "                self.data['return'] = (self.data.groupby('symbol')['close'].pct_change())\n",
    "                self.data['mkt_return'] = self.data.groupby('date')['return'].transform('mean')\n",
    "            \n",
    "            \"\"\"\n",
    "            def __init__(self, data):\n",
    "                self.data = data.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
    "                \n",
    "                # compute returns\n",
    "                self.data['return'] = self.data.groupby('symbol')['close'].pct_change()\n",
    "                \n",
    "                # optionally fill NaNs with 0 (or drop first row later)\n",
    "                #self.data['return'] = self.data['return'].fillna(0)\n",
    "                \n",
    "                # market return per date\n",
    "                self.data['mkt_return'] = self.data.groupby('date')['return'].transform('mean')\n",
    "            \"\"\"\n",
    "            \n",
    "            # ==================== HELPER FUNCTIONS ====================\n",
    "\n",
    "            def rank(self, series):\n",
    "                 if isinstance(series, np.ndarray):\n",
    "                    series = pd.Series(series, index=self.data.index)\n",
    "                 return series.groupby(self.data['date']).rank(pct=True)  #\"fixed\" rank for alphas calling other alphas\n",
    "                \n",
    "            \n",
    "            def ts_rank(self, series, window):\n",
    "                \"\"\"Time-series rank over rolling window\"\"\"\n",
    "                result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).apply(\n",
    "                    lambda x: pd.Series(x).rank(pct=True).iloc[-1], raw=False\n",
    "                )\n",
    "                return pd.Series(result.values, index=self.data.index)\n",
    "\n",
    "        def ts_min(self, series, window):\n",
    "            \"\"\"Time-series minimum\"\"\"\n",
    "            result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).min()\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def ts_max(self, series, window):\n",
    "            \"\"\"Time-series maximum\"\"\"\n",
    "            result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).max()\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def ts_argmax(self, series, window):\n",
    "            \"\"\"Index of maximum value in window\"\"\"\n",
    "            result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).apply(\n",
    "                lambda x: x.argmax(), raw=True\n",
    "            )\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def ts_argmin(self, series, window):\n",
    "            \"\"\"Index of minimum value in window\"\"\"\n",
    "            result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).apply(\n",
    "                lambda x: x.argmin(), raw=True\n",
    "            )\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def delta(self, series, period):\n",
    "            \"\"\"Difference over period\"\"\"\n",
    "            return series.groupby(self.data['symbol']).diff(period)\n",
    "        \n",
    "        def delay(self, series, period):\n",
    "            \"\"\"Lag by period\"\"\"\n",
    "            return series.groupby(self.data['symbol']).shift(period)\n",
    "        \n",
    "        def correlation(self, x, y, window):\n",
    "            \"\"\"Rolling correlation\"\"\"\n",
    "            result = x.groupby(self.data['symbol']).rolling(window, min_periods=1).corr(y)\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def covariance(self, x, y, window):\n",
    "            \"\"\"Rolling covariance\"\"\"\n",
    "            result = x.groupby(self.data['symbol']).rolling(window, min_periods=1).cov(y)\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def scale(self, series):\n",
    "            \"\"\"Normalize to sum to 1 within each date\"\"\"\n",
    "            return series.groupby(self.data['date']).apply(lambda x: x / x.abs().sum())\n",
    "        \n",
    "        def stddev(self, series, window):\n",
    "            \"\"\"Rolling standard deviation\"\"\"\n",
    "            result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).std()\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def sum_ts(self, series, window):\n",
    "            \"\"\"Rolling sum\"\"\"\n",
    "            result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).sum()\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def product(self, series, window):\n",
    "            \"\"\"Rolling product\"\"\"\n",
    "            result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).apply(\n",
    "                lambda x: np.prod(x), raw=True\n",
    "            )\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "        \n",
    "        def decay_linear(self, series, window):\n",
    "            \"\"\"Linear decay weighting\"\"\"\n",
    "            weights = np.arange(1, window + 1)\n",
    "            weights = weights / weights.sum()\n",
    "            result = series.groupby(self.data['symbol']).rolling(window, min_periods=1).apply(\n",
    "                lambda x: np.sum(x * weights[-len(x):]), raw=True\n",
    "            )\n",
    "            return pd.Series(result.values, index=self.data.index)\n",
    "            \n",
    "            def sign(self, series):\n",
    "                \"\"\"Sign of values\"\"\"\n",
    "                return np.sign(series)\n",
    "            \n",
    "            def log(self, series):\n",
    "                \"\"\"Natural logarithm\"\"\"\n",
    "                return np.log(series.replace(0, np.nan))\n",
    "            \n",
    "            # ==================== ALPHA IMPLEMENTATIONS ====================\n",
    "            \n",
    "            # Alpha #1\n",
    "            # Data: ✗ DAILY_REQUIRED (needs accurate returns)\n",
    "            def alpha_001(self):\n",
    "                \"\"\"rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5\"\"\"\n",
    "                returns = self.data['returns']\n",
    "                condition = returns < 0\n",
    "                base = np.where(condition, self.stddev(returns, 20), self.data['close'])\n",
    "                power = np.sign(base) * (np.abs(base) ** 2)\n",
    "                result = self.rank(self.ts_argmax(power, 5)) - 0.5\n",
    "                return result\n",
    "            \n",
    "            # Alpha #2  \n",
    "            # Data: ✗ OPEN_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            \"\"\"\n",
    "            def alpha_002(self):\n",
    "                \n",
    "                log_vol = self.log(self.data['volume'])\n",
    "                delta_log_vol = self.delta(log_vol, 2)\n",
    "                price_change = (self.data['close'] - self.data['open']) / self.data['open']\n",
    "                return -1 * self.correlation(self.rank(delta_log_vol), self.rank(price_change), 6)\n",
    "            \"\"\"\n",
    "\n",
    "            def alpha_002(self):\n",
    "                log_vol = self.log(self.data['volume'])\n",
    "                print(f\"[alpha_002] log_vol length: {len(log_vol)}\")\n",
    "                \n",
    "                delta_log_vol = self.delta(log_vol, 2)\n",
    "                print(f\"[alpha_002] delta_log_vol length: {len(delta_log_vol)}\")\n",
    "                \n",
    "                price_change = (self.data['close'] - self.data['open']) / self.data['open']\n",
    "                print(f\"[alpha_002] price_change length: {len(price_change)}\")\n",
    "                \n",
    "                rank_delta = self.rank(delta_log_vol)\n",
    "                print(f\"[alpha_002] rank_delta length: {len(rank_delta)}\")\n",
    "                \n",
    "                rank_price = self.rank(price_change)\n",
    "                print(f\"[alpha_002] rank_price length: {len(rank_price)}\")\n",
    "                \n",
    "                corr = self.correlation(rank_delta, rank_price, 6)\n",
    "                print(f\"[alpha_002] corr length: {len(corr)}\")\n",
    "                \n",
    "                return -1 * corr\n",
    "            \n",
    "            \n",
    "            # Alpha #3\n",
    "            # Data: ✗ OPEN_REQUIRED, ✓ MONTHLY_OK (if open is approximated)\n",
    "            def alpha_003(self):\n",
    "                \"\"\"-1 * correlation(rank(open), rank(volume), 10)\"\"\"\n",
    "                return -1 * self.correlation(self.rank(self.data['open']), self.rank(self.data['volume']), 10)\n",
    "            \n",
    "            # Alpha #4\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_004(self):\n",
    "                \"\"\"-1 * Ts_Rank(rank(low), 9)\"\"\"\n",
    "                return -1 * self.ts_rank(self.rank(self.data['low']), 9)\n",
    "            \n",
    "            # Alpha #5\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ OPEN_REQUIRED\n",
    "            def alpha_005(self):\n",
    "                \"\"\"rank((open - (sum(vwap, 10) / 10))) * (-1 * abs(rank((close - vwap))))\"\"\"\n",
    "                vwap = self.data['vwap']\n",
    "                vwap_ma = self.sum_ts(vwap, 10) / 10\n",
    "                part1 = self.rank(self.data['open'] - vwap_ma)\n",
    "                part2 = -1 * np.abs(self.rank(self.data['close'] - vwap))\n",
    "                return part1 * part2\n",
    "            \n",
    "            # Alpha #6\n",
    "            # Data: ✗ OPEN_REQUIRED, ✓ MONTHLY_OK (if open is approximated)\n",
    "            def alpha_006(self):\n",
    "                \"\"\"-1 * correlation(open, volume, 10)\"\"\"\n",
    "                return -1 * self.correlation(self.data['open'], self.data['volume'], 10)\n",
    "            \n",
    "            # Alpha #7\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv20)\n",
    "            def alpha_007(self):\n",
    "                \"\"\"Conditional on volume vs adv20\"\"\"\n",
    "                adv20 = self.data['adv20']\n",
    "                delta_close = self.delta(self.data['close'], 7)\n",
    "                ts_rank_val = self.ts_rank(np.abs(delta_close), 60)\n",
    "                condition = adv20 < self.data['volume']\n",
    "                return np.where(condition, -1 * ts_rank_val * self.sign(delta_close), -1)\n",
    "            \n",
    "            # Alpha #8\n",
    "            # Data: ✗ OPEN_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_008(self):\n",
    "                \"\"\"-1 * rank(((sum(open, 5) * sum(returns, 5)) - delay((sum(open, 5) * sum(returns, 5)), 10)))\"\"\"\n",
    "                sum_open = self.sum_ts(self.data['open'], 5)\n",
    "                sum_returns = self.sum_ts(self.data['returns'], 5)\n",
    "                product = sum_open * sum_returns\n",
    "                delayed = self.delay(product, 10)\n",
    "                return -1 * self.rank(product - delayed)\n",
    "            \n",
    "            # Alpha #9\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_009(self):\n",
    "                \"\"\"Conditional based on delta(close, 1)\"\"\"\n",
    "                delta_close = self.delta(self.data['close'], 1)\n",
    "                ts_min_val = self.ts_min(delta_close, 5)\n",
    "                ts_max_val = self.ts_max(delta_close, 5)\n",
    "                \n",
    "                condition1 = 0 < ts_min_val\n",
    "                condition2 = ts_max_val < 0\n",
    "                \n",
    "                return np.where(condition1, delta_close, \n",
    "                               np.where(condition2, delta_close, -1 * delta_close))\n",
    "            \n",
    "            # Alpha #10\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_010(self):\n",
    "                \"\"\"rank of alpha_009\"\"\"\n",
    "                return self.rank(self.alpha_009())\n",
    "            \n",
    "            # Alpha #11\n",
    "            # Data: ✗ VWAP_REQUIRED\n",
    "            def alpha_011(self):\n",
    "                \"\"\"((rank(ts_max((vwap - close), 3)) + rank(ts_min((vwap - close), 3))) * rank(delta(volume, 3)))\"\"\"\n",
    "                vwap_close = self.data['vwap'] - self.data['close']\n",
    "                part1 = self.rank(self.ts_max(vwap_close, 3)) + self.rank(self.ts_min(vwap_close, 3))\n",
    "                part2 = self.rank(self.delta(self.data['volume'], 3))\n",
    "                return part1 * part2\n",
    "            \n",
    "            # Alpha #12\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_012(self):\n",
    "                \"\"\"sign(delta(volume, 1)) * (-1 * delta(close, 1))\"\"\"\n",
    "                return self.sign(self.delta(self.data['volume'], 1)) * (-1 * self.delta(self.data['close'], 1))\n",
    "            \n",
    "            # Alpha #13\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_013(self):\n",
    "                \"\"\"-1 * rank(covariance(rank(close), rank(volume), 5))\"\"\"\n",
    "                return -1 * self.rank(self.covariance(self.rank(self.data['close']), \n",
    "                                                       self.rank(self.data['volume']), 5))\n",
    "            \n",
    "            # Alpha #14\n",
    "            # Data: ✗ OPEN_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_014(self):\n",
    "                \"\"\"(-1 * rank(delta(returns, 3))) * correlation(open, volume, 10)\"\"\"\n",
    "                part1 = -1 * self.rank(self.delta(self.data['returns'], 3))\n",
    "                part2 = self.correlation(self.data['open'], self.data['volume'], 10)\n",
    "                return part1 * part2\n",
    "            \n",
    "            # Alpha #15\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_015(self):\n",
    "                \"\"\"-1 * sum(rank(correlation(rank(high), rank(volume), 3)), 3)\"\"\"\n",
    "                corr = self.correlation(self.rank(self.data['high']), self.rank(self.data['volume']), 3)\n",
    "                return -1 * self.sum_ts(self.rank(corr), 3)\n",
    "            \n",
    "            # Alpha #16\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_016(self):\n",
    "                \"\"\"-1 * rank(covariance(rank(high), rank(volume), 5))\"\"\"\n",
    "                return -1 * self.rank(self.covariance(self.rank(self.data['high']), \n",
    "                                                       self.rank(self.data['volume']), 5))\n",
    "            \n",
    "            # Alpha #17\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv20)\n",
    "            def alpha_017(self):\n",
    "                \"\"\"Complex formula with ts_rank\"\"\"\n",
    "                part1 = -1 * self.rank(self.ts_rank(self.data['close'], 10))\n",
    "                part2 = self.rank(self.delta(self.delta(self.data['close'], 1), 1))\n",
    "                part3 = self.rank(self.ts_rank(self.data['volume'] / self.data['adv20'], 5))\n",
    "                return part1 * part2 * part3\n",
    "            \n",
    "            # Alpha #18\n",
    "            # Data: ✗ OPEN_REQUIRED\n",
    "            def alpha_018(self):\n",
    "                \"\"\"-1 * rank(stddev + (close - open) + correlation)\"\"\"\n",
    "                std = self.stddev(np.abs(self.data['close'] - self.data['open']), 5)\n",
    "                diff = self.data['close'] - self.data['open']\n",
    "                corr = self.correlation(self.data['close'], self.data['open'], 10)\n",
    "                return -1 * self.rank(std + diff + corr)\n",
    "            \n",
    "            # Alpha #19\n",
    "            # Data: ✗ DAILY_REQUIRED\n",
    "            def alpha_019(self):\n",
    "                \"\"\"Complex sign and sum formula\"\"\"\n",
    "                close_diff = self.data['close'] - self.delay(self.data['close'], 7)\n",
    "                delta_close = self.delta(self.data['close'], 7)\n",
    "                sign_val = self.sign(close_diff + delta_close)\n",
    "                returns_sum = self.sum_ts(self.data['returns'], 250)\n",
    "                return -1 * sign_val * (1 + self.rank(1 + returns_sum))\n",
    "            \n",
    "            # Alpha #20\n",
    "            # Data: ✗ OPEN_REQUIRED\n",
    "            def alpha_020(self):\n",
    "                \"\"\"Product of rank differences\"\"\"\n",
    "                part1 = -1 * self.rank(self.data['open'] - self.delay(self.data['high'], 1))\n",
    "                part2 = self.rank(self.data['open'] - self.delay(self.data['close'], 1))\n",
    "                part3 = self.rank(self.data['open'] - self.delay(self.data['low'], 1))\n",
    "                return part1 * part2 * part3\n",
    "            \n",
    "            # Alpha #21\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv20)\n",
    "            def alpha_021(self):\n",
    "                \"\"\"Conditional formula with moving averages\"\"\"\n",
    "                ma8 = self.sum_ts(self.data['close'], 8) / 8\n",
    "                std8 = self.stddev(self.data['close'], 8)\n",
    "                ma2 = self.sum_ts(self.data['close'], 2) / 2\n",
    "                \n",
    "                vol_ratio = self.data['volume'] / self.data['adv20']\n",
    "                \n",
    "                cond1 = (ma8 + std8) < ma2\n",
    "                cond2 = ma2 < (ma8 - std8)\n",
    "                cond3 = (vol_ratio >= 1)\n",
    "                \n",
    "                return np.where(cond1, -1, np.where(cond2, 1, np.where(cond3, 1, -1)))\n",
    "            \n",
    "            # Alpha #22\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_022(self):\n",
    "                \"\"\"-1 * (delta(correlation(high, volume, 5), 5) * rank(stddev(close, 20)))\"\"\"\n",
    "                corr = self.correlation(self.data['high'], self.data['volume'], 5)\n",
    "                delta_corr = self.delta(corr, 5)\n",
    "                std_rank = self.rank(self.stddev(self.data['close'], 20))\n",
    "                return -1 * delta_corr * std_rank\n",
    "            \n",
    "            # Alpha #23\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_023(self):\n",
    "                \"\"\"Conditional based on moving average\"\"\"\n",
    "                ma20 = self.sum_ts(self.data['high'], 20) / 20\n",
    "                condition = ma20 < self.data['high']\n",
    "                return np.where(condition, -1 * self.delta(self.data['high'], 2), 0)\n",
    "            \n",
    "            # Alpha #24\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_024(self):\n",
    "                \"\"\"Conditional with moving average and delta\"\"\"\n",
    "                ma100 = self.sum_ts(self.data['close'], 100) / 100\n",
    "                delta_ma = self.delta(ma100, 100)\n",
    "                delayed_close = self.delay(self.data['close'], 100)\n",
    "                ratio = delta_ma / delayed_close\n",
    "                \n",
    "                condition = (ratio < 0.05) | (ratio == 0.05)\n",
    "                ts_min_close = self.ts_min(self.data['close'], 100)\n",
    "                \n",
    "                return np.where(condition, -1 * (self.data['close'] - ts_min_close), \n",
    "                               -1 * self.delta(self.data['close'], 3))\n",
    "            \n",
    "            # Alpha #25\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_025(self):\n",
    "                \"\"\"rank(((-1 * returns) * adv20) * vwap) * (high - close))\"\"\"\n",
    "                part1 = -1 * self.data['returns']\n",
    "                part2 = self.data['adv20']\n",
    "                part3 = self.data['vwap']\n",
    "                part4 = self.data['high'] - self.data['close']\n",
    "                return self.rank(part1 * part2 * part3 * part4)\n",
    "            \n",
    "            # Alpha #26\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_026(self):\n",
    "                \"\"\"-1 * ts_max(correlation(ts_rank(volume, 5), ts_rank(high, 5), 5), 3)\"\"\"\n",
    "                ts_rank_vol = self.ts_rank(self.data['volume'], 5)\n",
    "                ts_rank_high = self.ts_rank(self.data['high'], 5)\n",
    "                corr = self.correlation(ts_rank_vol, ts_rank_high, 5)\n",
    "                return -1 * self.ts_max(corr, 3)\n",
    "            \n",
    "            # Alpha #27\n",
    "            # Data: ✗ VWAP_REQUIRED\n",
    "            def alpha_027(self):\n",
    "                \"\"\"Conditional based on rank and correlation\"\"\"\n",
    "                corr = self.correlation(self.rank(self.data['volume']), self.rank(self.data['vwap']), 6)\n",
    "                sum_corr = self.sum_ts(corr, 2)\n",
    "                rank_sum = self.rank(sum_corr / 2.0)\n",
    "                return np.where(rank_sum > 0.5, -1, 1)\n",
    "            \n",
    "            # Alpha #28\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv20)\n",
    "            def alpha_028(self):\n",
    "                \"\"\"scale with correlation and averages\"\"\"\n",
    "                corr = self.correlation(self.data['adv20'], self.data['low'], 5)\n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                return self.scale(corr + mid - self.data['close'])\n",
    "            \n",
    "            # Alpha #29\n",
    "            # Data: ✗ DAILY_REQUIRED\n",
    "            def alpha_029(self):\n",
    "                \"\"\"Complex min-product formula\"\"\"\n",
    "                inner_rank = -1 * self.rank(self.delta(self.data['close'] - 1, 5))\n",
    "                rank_rank = self.rank(self.rank(inner_rank))\n",
    "                ts_min_val = self.ts_min(rank_rank, 2)\n",
    "                log_sum = self.log(self.sum_ts(ts_min_val, 1))\n",
    "                scaled = self.scale(log_sum)\n",
    "                rank_scaled = self.rank(self.rank(scaled))\n",
    "                product_val = self.product(rank_scaled, 1)\n",
    "                min_val = np.minimum(self.rank(product_val), 5)\n",
    "                delayed_ret = self.delay(-1 * self.data['returns'], 6)\n",
    "                ts_rank_ret = self.ts_rank(delayed_ret, 5)\n",
    "                return min_val + ts_rank_ret\n",
    "            \n",
    "            # Alpha #30\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_030(self):\n",
    "                \"\"\"Sign-based formula with volume\"\"\"\n",
    "                sign_sum = (self.sign(self.data['close'] - self.delay(self.data['close'], 1)) +\n",
    "                           self.sign(self.delay(self.data['close'], 1) - self.delay(self.data['close'], 2)) +\n",
    "                           self.sign(self.delay(self.data['close'], 2) - self.delay(self.data['close'], 3)))\n",
    "                rank_val = self.rank(sign_sum)\n",
    "                vol_ratio = self.sum_ts(self.data['volume'], 5) / self.sum_ts(self.data['volume'], 20)\n",
    "                return (1.0 - rank_val) * vol_ratio\n",
    "            \n",
    "            # Alpha #31\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv20, decay_linear)\n",
    "            def alpha_031(self):\n",
    "                \"\"\"Complex decay and correlation formula\"\"\"\n",
    "                delta_close = self.delta(self.data['close'], 10)\n",
    "                rank_delta = self.rank(self.rank(delta_close))\n",
    "                decay1 = self.decay_linear(-1 * rank_delta, 10)\n",
    "                rank_decay = self.rank(self.rank(self.rank(decay1)))\n",
    "                \n",
    "                delta_close3 = self.delta(self.data['close'], 3)\n",
    "                rank_delta3 = self.rank(-1 * delta_close3)\n",
    "                \n",
    "                corr = self.correlation(self.data['adv20'], self.data['low'], 12)\n",
    "                sign_corr = self.sign(self.scale(corr))\n",
    "                \n",
    "                return rank_decay + rank_delta3 + sign_corr\n",
    "            \n",
    "            # Alpha #32\n",
    "            # Data: ✗ VWAP_REQUIRED\n",
    "            def alpha_032(self):\n",
    "                \"\"\"scale(((sum(close, 7) / 7) - close)) + (20 * scale(correlation(vwap, delay(close, 5), 230)))\"\"\"\n",
    "                ma7 = self.sum_ts(self.data['close'], 7) / 7\n",
    "                part1 = self.scale(ma7 - self.data['close'])\n",
    "                \n",
    "                delayed_close = self.delay(self.data['close'], 5)\n",
    "                corr = self.correlation(self.data['vwap'], delayed_close, 230)\n",
    "                part2 = 20 * self.scale(corr)\n",
    "                \n",
    "                return part1 + part2\n",
    "            \n",
    "            # Alpha #33\n",
    "            # Data: ✗ OPEN_REQUIRED, ✓ MONTHLY_OK (if open approximated)\n",
    "            def alpha_033(self):\n",
    "                \"\"\"rank((-1 * ((1 - (open / close))^1)))\"\"\"\n",
    "                ratio = 1 - (self.data['open'] / self.data['close'])\n",
    "                return self.rank(-1 * ratio)\n",
    "            \n",
    "            # Alpha #34\n",
    "            # Data: ✗ DAILY_REQUIRED\n",
    "            def alpha_034(self):\n",
    "                \"\"\"rank((1 - rank((stddev(returns, 2) / stddev(returns, 5)))) + (1 - rank(delta(close, 1))))\"\"\"\n",
    "                std2 = self.stddev(self.data['returns'], 2)\n",
    "                std5 = self.stddev(self.data['returns'], 5)\n",
    "                ratio_std = std2 / std5\n",
    "                \n",
    "                part1 = 1 - self.rank(ratio_std)\n",
    "                part2 = 1 - self.rank(self.delta(self.data['close'], 1))\n",
    "                \n",
    "                return self.rank(part1 + part2)\n",
    "            \n",
    "            # Alpha #35\n",
    "            # Data: ✗ DAILY_REQUIRED\n",
    "            def alpha_035(self):\n",
    "                \"\"\"Complex ts_rank formula with returns\"\"\"\n",
    "                ts_rank_vol = self.ts_rank(self.data['volume'], 32)\n",
    "                \n",
    "                mid = (self.data['close'] + self.data['high']) - self.data['low']\n",
    "                ts_rank_mid = self.ts_rank(mid, 16)\n",
    "                \n",
    "                ts_rank_ret = self.ts_rank(self.data['returns'], 32)\n",
    "                \n",
    "                return ts_rank_vol * (1 - ts_rank_mid) * (1 - ts_rank_ret)\n",
    "            \n",
    "            # Alpha #36\n",
    "            # Data: ✗ OPEN_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_036(self):\n",
    "                \"\"\"Complex weighted combination formula\"\"\"\n",
    "                # Part 1\n",
    "                corr1 = self.correlation(self.data['close'] - self.data['open'], \n",
    "                                         self.delay(self.data['volume'], 1), 15)\n",
    "                part1 = 2.21 * self.rank(corr1)\n",
    "                \n",
    "                # Part 2\n",
    "                part2 = 0.7 * self.rank(self.data['open'] - self.data['close'])\n",
    "                \n",
    "                # Part 3\n",
    "                delayed_ret = self.delay(-1 * self.data['returns'], 6)\n",
    "                ts_rank_ret = self.ts_rank(delayed_ret, 5)\n",
    "                part3 = 0.73 * self.rank(ts_rank_ret)\n",
    "                \n",
    "                # Part 4\n",
    "                corr2 = self.correlation(self.data['vwap'], self.data['adv20'], 6)\n",
    "                part4 = self.rank(np.abs(corr2))\n",
    "                \n",
    "                # Part 5\n",
    "                ma200 = self.sum_ts(self.data['close'], 200) / 200\n",
    "                part5 = 0.6 * self.rank((ma200 - self.data['open']) * (self.data['close'] - self.data['open']))\n",
    "                \n",
    "                return part1 + part2 + part3 + part4 + part5\n",
    "            \n",
    "            # Alpha #37\n",
    "            # Data: ✗ OPEN_REQUIRED\n",
    "            def alpha_037(self):\n",
    "                \"\"\"rank(correlation(delay((open - close), 1), close, 200)) + rank((open - close))\"\"\"\n",
    "                delayed_diff = self.delay(self.data['open'] - self.data['close'], 1)\n",
    "                corr = self.correlation(delayed_diff, self.data['close'], 200)\n",
    "                part1 = self.rank(corr)\n",
    "                part2 = self.rank(self.data['open'] - self.data['close'])\n",
    "                return part1 + part2\n",
    "            \n",
    "            # Alpha #38\n",
    "            # Data: ✗ OPEN_REQUIRED\n",
    "            def alpha_038(self):\n",
    "                \"\"\"(-1 * rank(Ts_Rank(close, 10))) * rank((close / open))\"\"\"\n",
    "                ts_rank_close = self.ts_rank(self.data['close'], 10)\n",
    "                part1 = -1 * self.rank(ts_rank_close)\n",
    "                part2 = self.rank(self.data['close'] / self.data['open'])\n",
    "                return part1 * part2\n",
    "            \n",
    "            # Alpha #39\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv20, decay_linear)\n",
    "            def alpha_039(self):\n",
    "                \"\"\"Complex formula with decay_linear and returns\"\"\"\n",
    "                delta_close = self.delta(self.data['close'], 7)\n",
    "                vol_ratio = self.data['volume'] / self.data['adv20']\n",
    "                decay_vol = self.decay_linear(vol_ratio, 9)\n",
    "                rank_decay = self.rank(decay_vol)\n",
    "                \n",
    "                part1 = -1 * self.rank(delta_close * (1 - rank_decay))\n",
    "                \n",
    "                sum_returns = self.sum_ts(self.data['returns'], 250)\n",
    "                part2 = 1 + self.rank(sum_returns)\n",
    "                \n",
    "                return part1 * part2\n",
    "            \n",
    "            # Alpha #40\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_040(self):\n",
    "                \"\"\"(-1 * rank(stddev(high, 10))) * correlation(high, volume, 10)\"\"\"\n",
    "                std_high = self.stddev(self.data['high'], 10)\n",
    "                corr = self.correlation(self.data['high'], self.data['volume'], 10)\n",
    "                return -1 * self.rank(std_high) * corr\n",
    "            \n",
    "            # Alpha #41\n",
    "            # Data: ✗ VWAP_REQUIRED\n",
    "            def alpha_041(self):\n",
    "                \"\"\"((high * low)^0.5) - vwap\"\"\"\n",
    "                geometric_mean = np.sqrt(self.data['high'] * self.data['low'])\n",
    "                return geometric_mean - self.data['vwap']\n",
    "            \n",
    "            # Alpha #42\n",
    "            # Data: ✗ VWAP_REQUIRED\n",
    "            def alpha_042(self):\n",
    "                \"\"\"rank((vwap - close)) / rank((vwap + close))\"\"\"\n",
    "                part1 = self.rank(self.data['vwap'] - self.data['close'])\n",
    "                part2 = self.rank(self.data['vwap'] + self.data['close'])\n",
    "                return part1 / part2\n",
    "            \n",
    "            # Alpha #43\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv20)\n",
    "            def alpha_043(self):\n",
    "                \"\"\"(ts_rank((volume / adv20), 20) * ts_rank((-1 * delta(close, 7)), 8))\"\"\"\n",
    "                vol_ratio = self.data['volume'] / self.data['adv20']\n",
    "                ts_rank_vol = self.ts_rank(vol_ratio, 20)\n",
    "                \n",
    "                delta_close = self.delta(self.data['close'], 7)\n",
    "                ts_rank_delta = self.ts_rank(-1 * delta_close, 8)\n",
    "                \n",
    "                return ts_rank_vol * ts_rank_delta\n",
    "            \n",
    "            # Alpha #44\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_044(self):\n",
    "                \"\"\"(-1 * correlation(high, rank(volume), 5))\"\"\"\n",
    "                rank_vol = self.rank(self.data['volume'])\n",
    "                return -1 * self.correlation(self.data['high'], rank_vol, 5)\n",
    "            \n",
    "            # Alpha #45\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_045(self):\n",
    "                \"\"\"Complex correlation formula\"\"\"\n",
    "                delayed_close = self.delay(self.data['close'], 5)\n",
    "                sum_delayed = self.sum_ts(delayed_close, 20) / 20\n",
    "                rank_sum = self.rank(sum_delayed)\n",
    "                \n",
    "                corr1 = self.correlation(self.data['close'], self.data['volume'], 2)\n",
    "                \n",
    "                sum_close5 = self.sum_ts(self.data['close'], 5)\n",
    "                sum_close20 = self.sum_ts(self.data['close'], 20)\n",
    "                corr2 = self.correlation(sum_close5, sum_close20, 2)\n",
    "                rank_corr2 = self.rank(corr2)\n",
    "                \n",
    "                return -1 * rank_sum * corr1 * rank_corr2\n",
    "            \n",
    "            # Alpha #46\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_046(self):\n",
    "                \"\"\"Conditional based on moving average slopes\"\"\"\n",
    "                close_20 = self.delay(self.data['close'], 20)\n",
    "                close_10 = self.delay(self.data['close'], 10)\n",
    "                \n",
    "                slope1 = (close_20 - close_10) / 10\n",
    "                slope2 = (close_10 - self.data['close']) / 10\n",
    "                diff = slope1 - slope2\n",
    "                \n",
    "                delta_1 = self.data['close'] - self.delay(self.data['close'], 1)\n",
    "                \n",
    "                return np.where(diff > 0.25, -1,\n",
    "                               np.where(diff < 0, 1, -1 * delta_1))\n",
    "            \n",
    "            # Alpha #47\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_047(self):\n",
    "                \"\"\"Complex formula with ranks and vwap\"\"\"\n",
    "                rank_close = self.rank(1 / self.data['close'])\n",
    "                part1 = (rank_close * self.data['volume']) / self.data['adv20']\n",
    "                \n",
    "                rank_high_diff = self.rank(self.data['high'] - self.data['close'])\n",
    "                ma_high = self.sum_ts(self.data['high'], 5) / 5\n",
    "                part2 = (self.data['high'] * rank_high_diff) / ma_high\n",
    "                \n",
    "                vwap_diff = self.data['vwap'] - self.delay(self.data['vwap'], 5)\n",
    "                part3 = self.rank(vwap_diff)\n",
    "                \n",
    "                return (part1 * part2) - part3\n",
    "            \n",
    "            # Alpha #48\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_048(self):\n",
    "                \"\"\"Industry neutralized correlation - requires industry classification\"\"\"\n",
    "                # This alpha requires industry neutralization which needs sector/industry data\n",
    "                # Placeholder implementation without neutralization\n",
    "                delta_close = self.delta(self.data['close'], 1)\n",
    "                delayed_delta = self.delay(delta_close, 1)\n",
    "                delta_delayed = self.delta(delayed_delta, 1)\n",
    "                \n",
    "                corr = self.correlation(delta_close, delta_delayed, 250)\n",
    "                result = (corr * delta_close) / self.data['close']\n",
    "                \n",
    "                squared_return = (delta_close / self.delay(self.data['close'], 1)) ** 2\n",
    "                sum_squared = self.sum_ts(squared_return, 250)\n",
    "                \n",
    "                return result / sum_squared\n",
    "            \n",
    "            # Alpha #49\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_049(self):\n",
    "                \"\"\"Conditional based on moving average slopes\"\"\"\n",
    "                close_20 = self.delay(self.data['close'], 20)\n",
    "                close_10 = self.delay(self.data['close'], 10)\n",
    "                \n",
    "                slope1 = (close_20 - close_10) / 10\n",
    "                slope2 = (close_10 - self.data['close']) / 10\n",
    "                diff = slope1 - slope2\n",
    "                \n",
    "                delta_1 = self.data['close'] - self.delay(self.data['close'], 1)\n",
    "                \n",
    "                return np.where(diff < -0.1, 1, -1 * delta_1)\n",
    "            \n",
    "            # Alpha #50\n",
    "            # Data: ✗ VWAP_REQUIRED\n",
    "            def alpha_050(self):\n",
    "                \"\"\"(-1 * ts_max(rank(correlation(rank(volume), rank(vwap), 5)), 5))\"\"\"\n",
    "                rank_vol = self.rank(self.data['volume'])\n",
    "                rank_vwap = self.rank(self.data['vwap'])\n",
    "                corr = self.correlation(rank_vol, rank_vwap, 5)\n",
    "                rank_corr = self.rank(corr)\n",
    "                return -1 * self.ts_max(rank_corr, 5)\n",
    "            \n",
    "            # Alpha #51\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_051(self):\n",
    "                \"\"\"Conditional based on moving average slopes (threshold -0.05)\"\"\"\n",
    "                close_20 = self.delay(self.data['close'], 20)\n",
    "                close_10 = self.delay(self.data['close'], 10)\n",
    "                \n",
    "                slope1 = (close_20 - close_10) / 10\n",
    "                slope2 = (close_10 - self.data['close']) / 10\n",
    "                diff = slope1 - slope2\n",
    "                \n",
    "                delta_1 = self.data['close'] - self.delay(self.data['close'], 1)\n",
    "                \n",
    "                return np.where(diff < -0.05, 1, -1 * delta_1)\n",
    "            \n",
    "            # Alpha #52\n",
    "            # Data: ✗ DAILY_REQUIRED\n",
    "            def alpha_052(self):\n",
    "                \"\"\"Complex formula with ts_min and returns\"\"\"\n",
    "                ts_min_low = self.ts_min(self.data['low'], 5)\n",
    "                delayed_min = self.delay(ts_min_low, 5)\n",
    "                part1 = (-1 * ts_min_low) + delayed_min\n",
    "                \n",
    "                sum_ret_240 = self.sum_ts(self.data['returns'], 240)\n",
    "                sum_ret_20 = self.sum_ts(self.data['returns'], 20)\n",
    "                rank_ret = self.rank((sum_ret_240 - sum_ret_20) / 220)\n",
    "                \n",
    "                ts_rank_vol = self.ts_rank(self.data['volume'], 5)\n",
    "                \n",
    "                return part1 * rank_ret * ts_rank_vol\n",
    "            \n",
    "            # Alpha #53\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_053(self):\n",
    "                \"\"\"(-1 * delta((((close - low) - (high - close)) / (close - low)), 9))\"\"\"\n",
    "                numerator = (self.data['close'] - self.data['low']) - (self.data['high'] - self.data['close'])\n",
    "                denominator = self.data['close'] - self.data['low']\n",
    "                ratio = numerator / denominator.replace(0, np.nan)\n",
    "                return -1 * self.delta(ratio, 9)\n",
    "            \n",
    "            # Alpha #54\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_054(self):\n",
    "                \"\"\"((-1 * ((low - close) * (open^5))) / ((low - high) * (close^5)))\"\"\"\n",
    "                numerator = -1 * (self.data['low'] - self.data['close']) * (self.data['open'] ** 5)\n",
    "                denominator = (self.data['low'] - self.data['high']) * (self.data['close'] ** 5)\n",
    "                return numerator / denominator.replace(0, np.nan)\n",
    "            \n",
    "            # Alpha #55\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_055(self):\n",
    "                \"\"\"(-1 * correlation(rank(((close - ts_min(low, 12)) / (ts_max(high, 12) - ts_min(low, 12)))), rank(volume), 6))\"\"\"\n",
    "                ts_min_low = self.ts_min(self.data['low'], 12)\n",
    "                ts_max_high = self.ts_max(self.data['high'], 12)\n",
    "                \n",
    "                ratio = (self.data['close'] - ts_min_low) / (ts_max_high - ts_min_low)\n",
    "                rank_ratio = self.rank(ratio)\n",
    "                rank_vol = self.rank(self.data['volume'])\n",
    "                \n",
    "                return -1 * self.correlation(rank_ratio, rank_vol, 6)\n",
    "            \n",
    "            # Alpha #56\n",
    "            # Data: ✗ DAILY_REQUIRED (needs market cap)\n",
    "            def alpha_056(self):\n",
    "                \"\"\"Formula with returns and market cap\"\"\"\n",
    "                sum_ret_10 = self.sum_ts(self.data['returns'], 10)\n",
    "                sum_sum_ret = self.sum_ts(self.sum_ts(self.data['returns'], 2), 3)\n",
    "                rank1 = self.rank(sum_ret_10 / sum_sum_ret)\n",
    "                \n",
    "                # Market cap not available in basic data\n",
    "                # rank2 = self.rank(self.data['returns'] * self.data['cap'])\n",
    "                rank2 = self.rank(self.data['returns'] * self.data['volume'])  # Proxy\n",
    "                \n",
    "                return -1 * rank1 * rank2\n",
    "            \n",
    "            # Alpha #57\n",
    "            # Data: ✗ VWAP_REQUIRED\n",
    "            def alpha_057(self):\n",
    "                \"\"\"(0 - (1 * ((close - vwap) / decay_linear(rank(ts_argmax(close, 30)), 2))))\"\"\"\n",
    "                ts_argmax_close = self.ts_argmax(self.data['close'], 30)\n",
    "                rank_argmax = self.rank(ts_argmax_close)\n",
    "                decay = self.decay_linear(rank_argmax, 2)\n",
    "                \n",
    "                result = (self.data['close'] - self.data['vwap']) / decay\n",
    "                return -1 * result\n",
    "            \n",
    "            # Alpha #58\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ INDUSTRY_REQUIRED\n",
    "            def alpha_058(self):\n",
    "                \"\"\"Industry neutralized ts_rank with decay_linear\"\"\"\n",
    "                # Requires industry neutralization - placeholder without it\n",
    "                corr = self.correlation(self.data['vwap'], self.data['volume'], 3.92795)\n",
    "                decay = self.decay_linear(corr, 7.89291)\n",
    "                return -1 * self.ts_rank(decay, 5.50322)\n",
    "            \n",
    "            # Alpha #59\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ INDUSTRY_REQUIRED\n",
    "            def alpha_059(self):\n",
    "                \"\"\"Industry neutralized complex formula\"\"\"\n",
    "                # Requires industry neutralization - placeholder without it\n",
    "                weighted_vwap = (self.data['vwap'] * 0.728317) + (self.data['vwap'] * (1 - 0.728317))\n",
    "                corr = self.correlation(weighted_vwap, self.data['volume'], 4.25197)\n",
    "                decay = self.decay_linear(corr, 16.2289)\n",
    "                return -1 * self.ts_rank(decay, 8.19648)\n",
    "            \n",
    "            # Alpha #60\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_060(self):\n",
    "                \"\"\"Complex scale and rank formula\"\"\"\n",
    "                range_ratio = ((self.data['close'] - self.data['low']) - (self.data['high'] - self.data['close']))\n",
    "                range_ratio = range_ratio / (self.data['high'] - self.data['low'])\n",
    "                weighted = range_ratio * self.data['volume']\n",
    "                \n",
    "                part1 = 2 * self.scale(self.rank(weighted))\n",
    "                \n",
    "                ts_argmax_close = self.ts_argmax(self.data['close'], 10)\n",
    "                part2 = self.scale(self.rank(ts_argmax_close))\n",
    "                \n",
    "                return -1 * (part1 - part2)\n",
    "            \n",
    "            # Alpha #61\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv180)\n",
    "            def alpha_061(self):\n",
    "                \"\"\"(rank((vwap - ts_min(vwap, 16.1219))) < rank(correlation(vwap, adv180, 17.9282)))\"\"\"\n",
    "                ts_min_vwap = self.ts_min(self.data['vwap'], 16)\n",
    "                part1 = self.rank(self.data['vwap'] - ts_min_vwap)\n",
    "                \n",
    "                corr = self.correlation(self.data['vwap'], self.data['adv180'], 18)\n",
    "                part2 = self.rank(corr)\n",
    "                \n",
    "                return (part1 < part2).astype(int)\n",
    "            \n",
    "            # Alpha #62\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv20)\n",
    "            def alpha_062(self):\n",
    "                \"\"\"Complex comparison with vwap and ranks\"\"\"\n",
    "                corr = self.correlation(self.data['vwap'], self.sum_ts(self.data['adv20'], 22), 10)\n",
    "                part1 = self.rank(corr)\n",
    "                \n",
    "                rank_open = self.rank(self.data['open'])\n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                rank_mid = self.rank(mid)\n",
    "                rank_high = self.rank(self.data['high'])\n",
    "                \n",
    "                part2 = self.rank((rank_open + rank_open) < (rank_mid + rank_high))\n",
    "                \n",
    "                return (part1 < part2).astype(int) * -1\n",
    "            \n",
    "            # Alpha #63\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_063(self):\n",
    "                \"\"\"Industry neutralized with decay_linear\"\"\"\n",
    "                # Without industry neutralization\n",
    "                delta_close = self.delta(self.data['close'], 2)\n",
    "                decay1 = self.decay_linear(self.rank(delta_close), 8)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                weighted_price = (self.data['vwap'] * 0.318108) + (self.data['open'] * (1 - 0.318108))\n",
    "                corr = self.correlation(weighted_price, self.sum_ts(self.data['adv180'], 37), 14)\n",
    "                decay2 = self.decay_linear(corr, 12)\n",
    "                part2 = self.rank(decay2)\n",
    "                \n",
    "                return (part1 - part2) * -1\n",
    "            \n",
    "            # Alpha #64\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv120)\n",
    "            def alpha_064(self):\n",
    "                \"\"\"Complex correlation and delta formula\"\"\"\n",
    "                weighted_low = (self.data['open'] * 0.178404) + (self.data['low'] * (1 - 0.178404))\n",
    "                sum_low = self.sum_ts(weighted_low, 13)\n",
    "                sum_adv = self.sum_ts(self.data['adv120'], 13)\n",
    "                corr = self.correlation(sum_low, sum_adv, 17)\n",
    "                part1 = self.rank(corr)\n",
    "                \n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                weighted_mid = (mid * 0.178404) + (self.data['vwap'] * (1 - 0.178404))\n",
    "                delta_mid = self.delta(weighted_mid, 4)\n",
    "                part2 = self.rank(delta_mid)\n",
    "                \n",
    "                return (part1 < part2).astype(int) * -1\n",
    "            \n",
    "            # Alpha #65\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv60)\n",
    "            def alpha_065(self):\n",
    "                \"\"\"Correlation and ts_min comparison\"\"\"\n",
    "                weighted_open = (self.data['open'] * 0.00817205) + (self.data['vwap'] * (1 - 0.00817205))\n",
    "                sum_adv = self.sum_ts(self.data['adv60'], 9)\n",
    "                corr = self.correlation(weighted_open, sum_adv, 6)\n",
    "                part1 = self.rank(corr)\n",
    "                \n",
    "                ts_min_open = self.ts_min(self.data['open'], 14)\n",
    "                part2 = self.rank(self.data['open'] - ts_min_open)\n",
    "                \n",
    "                return (part1 < part2).astype(int) * -1\n",
    "            \n",
    "            # Alpha #66\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ OPEN_REQUIRED\n",
    "            def alpha_066(self):\n",
    "                \"\"\"Decay linear with vwap and low\"\"\"\n",
    "                delta_vwap = self.delta(self.data['vwap'], 4)\n",
    "                decay1 = self.decay_linear(delta_vwap, 7)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                weighted_low = (self.data['low'] * 0.96633) + (self.data['low'] * (1 - 0.96633))\n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                ratio = (weighted_low - self.data['vwap']) / (self.data['open'] - mid)\n",
    "                decay2 = self.decay_linear(ratio, 11)\n",
    "                part2 = self.ts_rank(decay2, 7)\n",
    "                \n",
    "                return (part1 + part2) * -1\n",
    "            \n",
    "            # Alpha #67\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_067(self):\n",
    "                \"\"\"Industry neutralized power formula\"\"\"\n",
    "                # Without industry neutralization\n",
    "                ts_min_high = self.ts_min(self.data['high'], 2)\n",
    "                part1 = self.rank(self.data['high'] - ts_min_high)\n",
    "                \n",
    "                corr = self.correlation(self.data['vwap'], self.data['adv20'], 6)\n",
    "                part2 = self.rank(corr)\n",
    "                \n",
    "                return (part1 ** part2) * -1\n",
    "            \n",
    "            # Alpha #68\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv15)\n",
    "            def alpha_068(self):\n",
    "                \"\"\"Ts_rank correlation comparison\"\"\"\n",
    "                corr = self.correlation(self.rank(self.data['high']), self.rank(self.data['adv15']), 9)\n",
    "                ts_rank_corr = self.ts_rank(corr, 14)\n",
    "                part1 = ts_rank_corr\n",
    "                \n",
    "                weighted_close = (self.data['close'] * 0.518371) + (self.data['low'] * (1 - 0.518371))\n",
    "                delta_weighted = self.delta(weighted_close, 1)\n",
    "                part2 = self.rank(delta_weighted)\n",
    "                \n",
    "                return (part1 < part2).astype(int) * -1\n",
    "            \n",
    "            # Alpha #69\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_069(self):\n",
    "                \"\"\"Industry neutralized with power\"\"\"\n",
    "                # Without industry neutralization\n",
    "                delta_vwap = self.delta(self.data['vwap'], 3)\n",
    "                ts_max_delta = self.ts_max(delta_vwap, 5)\n",
    "                part1 = self.rank(ts_max_delta)\n",
    "                \n",
    "                weighted_close = (self.data['close'] * 0.490655) + (self.data['vwap'] * (1 - 0.490655))\n",
    "                corr = self.correlation(weighted_close, self.data['adv20'], 5)\n",
    "                part2 = self.ts_rank(corr, 9)\n",
    "                \n",
    "                return (part1 ** part2) * -1\n",
    "            \n",
    "            # Alpha #70\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ DAILY_REQUIRED (needs adv50)\n",
    "            def alpha_070(self):\n",
    "                \"\"\"Industry neutralized correlation\"\"\"\n",
    "                # Without industry neutralization\n",
    "                delta_vwap = self.delta(self.data['vwap'], 1)\n",
    "                part1 = self.rank(delta_vwap)\n",
    "                \n",
    "                corr = self.correlation(self.data['close'], self.data['adv50'], 18)\n",
    "                part2 = self.ts_rank(corr, 18)\n",
    "                \n",
    "                return (part1 ** part2) * -1\n",
    "            \n",
    "            # Alpha #71\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv180)\n",
    "            def alpha_071(self):\n",
    "                \"\"\"Max of two complex ts_rank formulas\"\"\"\n",
    "                ts_rank_close = self.ts_rank(self.data['close'], 3)\n",
    "                ts_rank_adv = self.ts_rank(self.data['adv180'], 12)\n",
    "                corr = self.correlation(ts_rank_close, ts_rank_adv, 18)\n",
    "                decay = self.decay_linear(corr, 4)\n",
    "                part1 = self.ts_rank(decay, 16)\n",
    "                \n",
    "                low_open = self.data['low'] + self.data['open']\n",
    "                vwap_2 = self.data['vwap'] + self.data['vwap']\n",
    "                rank_diff = self.rank(low_open - vwap_2)\n",
    "                decay2 = self.decay_linear(rank_diff ** 2, 16)\n",
    "                part2 = self.ts_rank(decay2, 4)\n",
    "                \n",
    "                return np.maximum(part1, part2)\n",
    "            \n",
    "            # Alpha #72\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv40)\n",
    "            def alpha_072(self):\n",
    "                \"\"\"Ratio of two decay_linear correlations\"\"\"\n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                corr1 = self.correlation(mid, self.data['adv40'], 9)\n",
    "                decay1 = self.decay_linear(corr1, 10)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                ts_rank_vwap = self.ts_rank(self.data['vwap'], 4)\n",
    "                ts_rank_vol = self.ts_rank(self.data['volume'], 19)\n",
    "                corr2 = self.correlation(ts_rank_vwap, ts_rank_vol, 7)\n",
    "                decay2 = self.decay_linear(corr2, 3)\n",
    "                part2 = self.rank(decay2)\n",
    "                \n",
    "                return part1 / part2\n",
    "            \n",
    "            # Alpha #73\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ OPEN_REQUIRED\n",
    "            def alpha_073(self):\n",
    "                \"\"\"Max of decay_linear formulas\"\"\"\n",
    "                delta_vwap = self.delta(self.data['vwap'], 5)\n",
    "                decay1 = self.decay_linear(delta_vwap, 3)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                weighted_open = (self.data['open'] * 0.147155) + (self.data['low'] * (1 - 0.147155))\n",
    "                delta_weighted = self.delta(weighted_open, 2)\n",
    "                ratio = (delta_weighted / weighted_open) * -1\n",
    "                decay2 = self.decay_linear(ratio, 3)\n",
    "                part2 = self.ts_rank(decay2, 17)\n",
    "                \n",
    "                return np.maximum(part1, part2) * -1\n",
    "            \n",
    "            # Alpha #74\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv30)\n",
    "            def alpha_074(self):\n",
    "                \"\"\"Correlation comparison formula\"\"\"\n",
    "                corr1 = self.correlation(self.data['close'], self.sum_ts(self.data['adv30'], 37), 15)\n",
    "                part1 = self.rank(corr1)\n",
    "                \n",
    "                weighted_high = (self.data['high'] * 0.0261661) + (self.data['vwap'] * (1 - 0.0261661))\n",
    "                rank_weighted = self.rank(weighted_high)\n",
    "                rank_vol = self.rank(self.data['volume'])\n",
    "                corr2 = self.correlation(rank_weighted, rank_vol, 11)\n",
    "                part2 = self.rank(corr2)\n",
    "                \n",
    "                return (part1 < part2).astype(int) * -1\n",
    "            \n",
    "            # Alpha #75\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv50)\n",
    "            def alpha_075(self):\n",
    "                \"\"\"Correlation comparison with low and adv50\"\"\"\n",
    "                corr = self.correlation(self.data['vwap'], self.data['volume'], 4)\n",
    "                part1 = self.rank(corr)\n",
    "                \n",
    "                corr2 = self.correlation(self.rank(self.data['low']), self.rank(self.data['adv50']), 12)\n",
    "                part2 = self.rank(corr2)\n",
    "                \n",
    "                return (part1 < part2).astype(int)\n",
    "            \n",
    "            # Alpha #76\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ DAILY_REQUIRED (needs adv81)\n",
    "            def alpha_076(self):\n",
    "                \"\"\"Max with industry neutralization\"\"\"\n",
    "                # Without industry neutralization\n",
    "                delta_vwap = self.delta(self.data['vwap'], 1)\n",
    "                decay1 = self.decay_linear(delta_vwap, 12)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                corr = self.correlation(self.data['low'], self.data['adv81'], 8)\n",
    "                ts_rank_corr = self.ts_rank(corr, 20)\n",
    "                decay2 = self.decay_linear(ts_rank_corr, 17)\n",
    "                part2 = self.ts_rank(decay2, 19)\n",
    "                \n",
    "                return np.maximum(part1, part2) * -1\n",
    "            \n",
    "            # Alpha #77\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv40)\n",
    "            def alpha_077(self):\n",
    "                \"\"\"Min of two decay_linear formulas\"\"\"\n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                sum_val = mid + self.data['high']\n",
    "                diff = sum_val - (self.data['vwap'] + self.data['high'])\n",
    "                decay1 = self.decay_linear(diff, 20)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                corr = self.correlation(mid, self.data['adv40'], 3)\n",
    "                decay2 = self.decay_linear(corr, 6)\n",
    "                part2 = self.rank(decay2)\n",
    "                \n",
    "                return np.minimum(part1, part2)\n",
    "            \n",
    "            # Alpha #78\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv40)\n",
    "            def alpha_078(self):\n",
    "                \"\"\"Power of two rank correlations\"\"\"\n",
    "                weighted_low = (self.data['low'] * 0.352233) + (self.data['vwap'] * (1 - 0.352233))\n",
    "                sum_low = self.sum_ts(weighted_low, 20)\n",
    "                sum_adv = self.sum_ts(self.data['adv40'], 20)\n",
    "                corr1 = self.correlation(sum_low, sum_adv, 7)\n",
    "                part1 = self.rank(corr1)\n",
    "                \n",
    "                rank_vwap = self.rank(self.data['vwap'])\n",
    "                rank_vol = self.rank(self.data['volume'])\n",
    "                corr2 = self.correlation(rank_vwap, rank_vol, 6)\n",
    "                part2 = self.rank(corr2)\n",
    "                \n",
    "                return part1 ** part2\n",
    "            \n",
    "            # Alpha #79\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_079(self):\n",
    "                \"\"\"Industry neutralized comparison\"\"\"\n",
    "                # Without industry neutralization\n",
    "                weighted_close = (self.data['close'] * 0.60733) + (self.data['open'] * (1 - 0.60733))\n",
    "                delta_weighted = self.delta(weighted_close, 1)\n",
    "                part1 = self.rank(delta_weighted)\n",
    "                \n",
    "                ts_rank_vwap = self.ts_rank(self.data['vwap'], 4)\n",
    "                ts_rank_adv = self.ts_rank(self.data['adv150'], 9)\n",
    "                corr = self.correlation(ts_rank_vwap, ts_rank_adv, 15)\n",
    "                part2 = self.rank(corr)\n",
    "                \n",
    "                return (part1 < part2).astype(int)\n",
    "            \n",
    "            # Alpha #80\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ DAILY_REQUIRED (needs adv10)\n",
    "            def alpha_080(self):\n",
    "                \"\"\"Industry neutralized sign with power\"\"\"\n",
    "                # Without industry neutralization\n",
    "                weighted_open = (self.data['open'] * 0.868128) + (self.data['high'] * (1 - 0.868128))\n",
    "                delta_weighted = self.delta(weighted_open, 4)\n",
    "                sign_delta = self.sign(delta_weighted)\n",
    "                part1 = self.rank(sign_delta)\n",
    "                \n",
    "                corr = self.correlation(self.data['high'], self.data['adv10'], 5)\n",
    "                part2 = self.ts_rank(corr, 6)\n",
    "                \n",
    "                return (part1 ** part2) * -1\n",
    "            \n",
    "            # Alpha #81\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv10)\n",
    "            def alpha_081(self):\n",
    "                \"\"\"Log and product formula\"\"\"\n",
    "                corr = self.correlation(self.data['vwap'], self.sum_ts(self.data['adv10'], 50), 8)\n",
    "                rank_corr = self.rank(corr)\n",
    "                power = rank_corr ** 4\n",
    "                rank_power = self.rank(power)\n",
    "                product_val = self.product(rank_power, 15)\n",
    "                log_product = self.log(product_val)\n",
    "                part1 = self.rank(log_product)\n",
    "                \n",
    "                rank_vwap = self.rank(self.data['vwap'])\n",
    "                rank_vol = self.rank(self.data['volume'])\n",
    "                corr2 = self.correlation(rank_vwap, rank_vol, 5)\n",
    "                part2 = self.rank(corr2)\n",
    "                \n",
    "                return (part1 < part2).astype(int) * -1\n",
    "            \n",
    "            # Alpha #82\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ OPEN_REQUIRED\n",
    "            def alpha_082(self):\n",
    "                \"\"\"Min with industry neutralization\"\"\"\n",
    "                # Without industry neutralization\n",
    "                delta_open = self.delta(self.data['open'], 1)\n",
    "                decay1 = self.decay_linear(delta_open, 15)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                weighted_open = (self.data['open'] * 0.634196) + (self.data['open'] * (1 - 0.634196))\n",
    "                corr = self.correlation(self.data['volume'], weighted_open, 17)\n",
    "                decay2 = self.decay_linear(corr, 7)\n",
    "                ts_rank_decay = self.ts_rank(decay2, 13)\n",
    "                part2 = ts_rank_decay\n",
    "                \n",
    "                return np.minimum(part1, part2) * -1\n",
    "            \n",
    "            # Alpha #83\n",
    "            # Data: ✓ MONTHLY_OK (if vwap approximated)\n",
    "            def alpha_083(self):\n",
    "                \"\"\"((rank(delay(((high - low) / (sum(close, 5) / 5)), 2)) * rank(rank(volume))) / (((high - low) / (sum(close, 5) / 5)) / (vwap - close)))\"\"\"\n",
    "                range_val = self.data['high'] - self.data['low']\n",
    "                ma5 = self.sum_ts(self.data['close'], 5) / 5\n",
    "                ratio = range_val / ma5\n",
    "                \n",
    "                delayed_ratio = self.delay(ratio, 2)\n",
    "                part1 = self.rank(delayed_ratio) * self.rank(self.rank(self.data['volume']))\n",
    "                \n",
    "                # Use close as vwap approximation for monthly data\n",
    "                vwap_approx = self.data['close']\n",
    "                part2 = ratio / (vwap_approx - self.data['close'] + 0.001)\n",
    "                \n",
    "                return part1 / part2\n",
    "            \n",
    "            # Alpha #84\n",
    "            # Data: ✗ VWAP_REQUIRED\n",
    "            def alpha_084(self):\n",
    "                \"\"\"SignedPower with ts_rank\"\"\"\n",
    "                ts_max_vwap = self.ts_max(self.data['vwap'], 15)\n",
    "                ts_rank_val = self.ts_rank(self.data['vwap'] - ts_max_vwap, 21)\n",
    "                \n",
    "                delta_close = self.delta(self.data['close'], 5)\n",
    "                \n",
    "                # SignedPower: sign(base) * |base|^exponent\n",
    "                return np.sign(ts_rank_val) * (np.abs(ts_rank_val) ** delta_close)\n",
    "            \n",
    "            # Alpha #85\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv30)\n",
    "            def alpha_085(self):\n",
    "                \"\"\"Power of two rank correlations\"\"\"\n",
    "                weighted_high = (self.data['high'] * 0.876703) + (self.data['close'] * (1 - 0.876703))\n",
    "                corr1 = self.correlation(weighted_high, self.data['adv30'], 10)\n",
    "                part1 = self.rank(corr1)\n",
    "                \n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                ts_rank_mid = self.ts_rank(mid, 4)\n",
    "                ts_rank_vol = self.ts_rank(self.data['volume'], 10)\n",
    "                corr2 = self.correlation(ts_rank_mid, ts_rank_vol, 7)\n",
    "                part2 = self.rank(corr2)\n",
    "                \n",
    "                return part1 ** part2\n",
    "            \n",
    "            # Alpha #86\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv20)\n",
    "            def alpha_086(self):\n",
    "                \"\"\"Ts_rank correlation comparison\"\"\"\n",
    "                corr = self.correlation(self.data['close'], self.sum_ts(self.data['adv20'], 15), 6)\n",
    "                ts_rank_corr = self.ts_rank(corr, 20)\n",
    "                part1 = ts_rank_corr\n",
    "                \n",
    "                sum_val = self.data['open'] + self.data['close']\n",
    "                sum_vwap = self.data['vwap'] + self.data['open']\n",
    "                part2 = self.rank(sum_val - sum_vwap)\n",
    "                \n",
    "                return (part1 < part2).astype(int) * -1\n",
    "            \n",
    "            # Alpha #87\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_087(self):\n",
    "                \"\"\"Max with industry neutralization\"\"\"\n",
    "                # Without industry neutralization\n",
    "                weighted_close = (self.data['close'] * 0.369701) + (self.data['vwap'] * (1 - 0.369701))\n",
    "                delta_weighted = self.delta(weighted_close, 2)\n",
    "                decay1 = self.decay_linear(delta_weighted, 3)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                corr = self.correlation(self.data['adv81'], self.data['close'], 13)\n",
    "                abs_corr = np.abs(corr)\n",
    "                decay2 = self.decay_linear(abs_corr, 5)\n",
    "                part2 = self.ts_rank(decay2, 14)\n",
    "                \n",
    "                return np.maximum(part1, part2) * -1\n",
    "            \n",
    "            # Alpha #88\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv60)\n",
    "            def alpha_088(self):\n",
    "                \"\"\"Min of two decay_linear formulas\"\"\"\n",
    "                rank_sum = (self.rank(self.data['open']) + self.rank(self.data['low'])) - (self.rank(self.data['high']) + self.rank(self.data['close']))\n",
    "                decay1 = self.decay_linear(rank_sum, 8)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                ts_rank_close = self.ts_rank(self.data['close'], 8)\n",
    "                ts_rank_adv = self.ts_rank(self.data['adv60'], 21)\n",
    "                corr = self.correlation(ts_rank_close, ts_rank_adv, 8)\n",
    "                decay2 = self.decay_linear(corr, 7)\n",
    "                part2 = self.ts_rank(decay2, 3)\n",
    "                \n",
    "                return np.minimum(part1, part2)\n",
    "            \n",
    "            # Alpha #89\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_089(self):\n",
    "                \"\"\"Difference of two ts_rank decay formulas\"\"\"\n",
    "                # Without industry neutralization\n",
    "                weighted_low = (self.data['low'] * 0.967285) + (self.data['low'] * (1 - 0.967285))\n",
    "                corr = self.correlation(weighted_low, self.data['adv10'], 7)\n",
    "                decay1 = self.decay_linear(corr, 6)\n",
    "                part1 = self.ts_rank(decay1, 4)\n",
    "                \n",
    "                delta_vwap = self.delta(self.data['vwap'], 3)\n",
    "                decay2 = self.decay_linear(delta_vwap, 10)\n",
    "                part2 = self.ts_rank(decay2, 15)\n",
    "                \n",
    "                return part1 - part2\n",
    "            \n",
    "            # Alpha #90\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ DAILY_REQUIRED (needs adv40)\n",
    "            def alpha_090(self):\n",
    "                \"\"\"Power formula with industry neutralization\"\"\"\n",
    "                # Without industry neutralization\n",
    "                ts_max_close = self.ts_max(self.data['close'], 5)\n",
    "                part1 = self.rank(self.data['close'] - ts_max_close)\n",
    "                \n",
    "                corr = self.correlation(self.data['adv40'], self.data['low'], 5)\n",
    "                part2 = self.ts_rank(corr, 3)\n",
    "                \n",
    "                return (part1 ** part2) * -1\n",
    "            \n",
    "            # Alpha #91\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_091(self):\n",
    "                \"\"\"Difference with industry neutralization\"\"\"\n",
    "                # Without industry neutralization\n",
    "                corr = self.correlation(self.data['close'], self.data['volume'], 10)\n",
    "                decay1 = self.decay_linear(corr, 16)\n",
    "                decay2 = self.decay_linear(decay1, 4)\n",
    "                part1 = self.ts_rank(decay2, 5)\n",
    "                \n",
    "                corr2 = self.correlation(self.data['vwap'], self.data['adv30'], 4)\n",
    "                decay3 = self.decay_linear(corr2, 3)\n",
    "                part2 = self.rank(decay3)\n",
    "                \n",
    "                return (part1 - part2) * -1\n",
    "            \n",
    "            # Alpha #92\n",
    "            # Data: ✗ OPEN_REQUIRED, ✗ DAILY_REQUIRED (needs adv30)\n",
    "            def alpha_092(self):\n",
    "                \"\"\"Min of two ts_rank decay formulas\"\"\"\n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                condition = (mid + self.data['close']) < (self.data['low'] + self.data['open'])\n",
    "                decay1 = self.decay_linear(condition.astype(float), 15)\n",
    "                part1 = self.ts_rank(decay1, 19)\n",
    "                \n",
    "                rank_low = self.rank(self.data['low'])\n",
    "                rank_adv = self.rank(self.data['adv30'])\n",
    "                corr = self.correlation(rank_low, rank_adv, 8)\n",
    "                decay2 = self.decay_linear(corr, 7)\n",
    "                part2 = self.ts_rank(decay2, 7)\n",
    "                \n",
    "                return np.minimum(part1, part2)\n",
    "            \n",
    "            # Alpha #93\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_093(self):\n",
    "                \"\"\"Division of ts_rank decay formulas\"\"\"\n",
    "                # Without industry neutralization\n",
    "                corr = self.correlation(self.data['vwap'], self.data['adv81'], 17)\n",
    "                decay1 = self.decay_linear(corr, 20)\n",
    "                part1 = self.ts_rank(decay1, 8)\n",
    "                \n",
    "                weighted_close = (self.data['close'] * 0.524434) + (self.data['vwap'] * (1 - 0.524434))\n",
    "                delta_weighted = self.delta(weighted_close, 3)\n",
    "                decay2 = self.decay_linear(delta_weighted, 16)\n",
    "                part2 = self.rank(decay2)\n",
    "                \n",
    "                return part1 / part2\n",
    "            \n",
    "            # Alpha #94\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv60)\n",
    "            def alpha_094(self):\n",
    "                \"\"\"Power of rank and ts_rank\"\"\"\n",
    "                ts_min_vwap = self.ts_min(self.data['vwap'], 12)\n",
    "                part1 = self.rank(self.data['vwap'] - ts_min_vwap)\n",
    "                \n",
    "                ts_rank_vwap = self.ts_rank(self.data['vwap'], 20)\n",
    "                ts_rank_adv = self.ts_rank(self.data['adv60'], 4)\n",
    "                corr = self.correlation(ts_rank_vwap, ts_rank_adv, 18)\n",
    "                part2 = self.ts_rank(corr, 3)\n",
    "                \n",
    "                return (part1 ** part2) * -1\n",
    "            \n",
    "            # Alpha #95\n",
    "            # Data: ✗ OPEN_REQUIRED, ✗ DAILY_REQUIRED (needs adv40)\n",
    "            def alpha_095(self):\n",
    "                \"\"\"Comparison formula with open and correlations\"\"\"\n",
    "                ts_min_open = self.ts_min(self.data['open'], 12)\n",
    "                part1 = self.rank(self.data['open'] - ts_min_open)\n",
    "                \n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                sum_mid = self.sum_ts(mid, 19)\n",
    "                sum_adv = self.sum_ts(self.data['adv40'], 19)\n",
    "                corr = self.correlation(sum_mid, sum_adv, 13)\n",
    "                rank_corr = self.rank(corr)\n",
    "                part2 = self.ts_rank(rank_corr ** 5, 12)\n",
    "                \n",
    "                return (part1 < part2).astype(int)\n",
    "            \n",
    "            # Alpha #96\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv60)\n",
    "            def alpha_096(self):\n",
    "                \"\"\"Max of two ts_rank decay formulas\"\"\"\n",
    "                rank_vwap = self.rank(self.data['vwap'])\n",
    "                rank_vol = self.rank(self.data['volume'])\n",
    "                corr = self.correlation(rank_vwap, rank_vol, 4)\n",
    "                decay1 = self.decay_linear(corr, 4)\n",
    "                part1 = self.ts_rank(decay1, 8)\n",
    "                \n",
    "                ts_rank_close = self.ts_rank(self.data['close'], 7)\n",
    "                ts_rank_adv = self.ts_rank(self.data['adv60'], 4)\n",
    "                corr2 = self.correlation(ts_rank_close, ts_rank_adv, 4)\n",
    "                ts_argmax_corr = self.ts_argmax(corr2, 13)\n",
    "                decay2 = self.decay_linear(ts_argmax_corr, 14)\n",
    "                part2 = self.ts_rank(decay2, 13)\n",
    "                \n",
    "                return np.maximum(part1, part2) * -1\n",
    "            \n",
    "            # Alpha #97\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED\n",
    "            def alpha_097(self):\n",
    "                \"\"\"Difference with industry neutralization\"\"\"\n",
    "                # Without industry neutralization\n",
    "                weighted_low = (self.data['low'] * 0.721001) + (self.data['vwap'] * (1 - 0.721001))\n",
    "                delta_weighted = self.delta(weighted_low, 3)\n",
    "                decay1 = self.decay_linear(delta_weighted, 20)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                ts_rank_low = self.ts_rank(self.data['low'], 8)\n",
    "                ts_rank_adv = self.ts_rank(self.data['adv60'], 17)\n",
    "                corr = self.correlation(ts_rank_low, ts_rank_adv, 5)\n",
    "                ts_rank_corr = self.ts_rank(corr, 19)\n",
    "                decay2 = self.decay_linear(ts_rank_corr, 15)\n",
    "                part2 = self.ts_rank(decay2, 7)\n",
    "                \n",
    "                return (part1 - part2) * -1\n",
    "            \n",
    "            # Alpha #98\n",
    "            # Data: ✗ VWAP_REQUIRED, ✗ DAILY_REQUIRED (needs adv5, adv15)\n",
    "            def alpha_098(self):\n",
    "                \"\"\"Difference of two rank decay formulas\"\"\"\n",
    "                corr1 = self.correlation(self.data['vwap'], self.sum_ts(self.data['adv5'], 26), 5)\n",
    "                decay1 = self.decay_linear(corr1, 7)\n",
    "                part1 = self.rank(decay1)\n",
    "                \n",
    "                rank_open = self.rank(self.data['open'])\n",
    "                rank_adv = self.rank(self.data['adv15'])\n",
    "                corr2 = self.correlation(rank_open, rank_adv, 21)\n",
    "                ts_argmin_corr = self.ts_argmin(corr2, 9)\n",
    "                ts_rank_argmin = self.ts_rank(ts_argmin_corr, 7)\n",
    "                decay2 = self.decay_linear(ts_rank_argmin, 8)\n",
    "                part2 = self.rank(decay2)\n",
    "                \n",
    "                return part1 - part2\n",
    "            \n",
    "            # Alpha #99\n",
    "            # Data: ✗ DAILY_REQUIRED (needs adv60)\n",
    "            def alpha_099(self):\n",
    "                \"\"\"Correlation comparison formula\"\"\"\n",
    "                mid = (self.data['high'] + self.data['low']) / 2\n",
    "                sum_mid = self.sum_ts(mid, 20)\n",
    "                sum_adv = self.sum_ts(self.data['adv60'], 20)\n",
    "                corr1 = self.correlation(sum_mid, sum_adv, 9)\n",
    "                part1 = self.rank(corr1)\n",
    "                \n",
    "                corr2 = self.correlation(self.data['low'], self.data['volume'], 6)\n",
    "                part2 = self.rank(corr2)\n",
    "                \n",
    "                return (part1 < part2).astype(int) * -1\n",
    "            \n",
    "            # Alpha #100\n",
    "            # Data: ✗ INDUSTRY_REQUIRED, ✗ DAILY_REQUIRED (needs adv20)\n",
    "            def alpha_100(self):\n",
    "                \"\"\"Complex industry neutralized formula\"\"\"\n",
    "                # Without industry neutralization - simplified version\n",
    "                range_ratio = ((self.data['close'] - self.data['low']) - (self.data['high'] - self.data['close']))\n",
    "                range_ratio = range_ratio / (self.data['high'] - self.data['low'])\n",
    "                weighted = range_ratio * self.data['volume']\n",
    "                \n",
    "                rank_weighted = self.rank(weighted)\n",
    "                part1 = 1.5 * self.scale(rank_weighted)\n",
    "                \n",
    "                corr = self.correlation(self.data['close'], self.rank(self.data['adv20']), 5)\n",
    "                ts_argmin_close = self.ts_argmin(self.data['close'], 30)\n",
    "                rank_argmin = self.rank(ts_argmin_close)\n",
    "                part2 = self.scale(corr - rank_argmin)\n",
    "                \n",
    "                vol_ratio = self.data['volume'] / self.data['adv20']\n",
    "                \n",
    "                return -1 * (part1 - part2) * vol_ratio\n",
    "            \n",
    "            # Alpha #101\n",
    "            # Data: ✓ MONTHLY_OK\n",
    "            def alpha_101(self):\n",
    "                \"\"\"(close - open) / ((high - low) + .001)\"\"\"\n",
    "                return (self.data['close'] - self.data['open']) / ((self.data['high'] - self.data['low']) + 0.001)\n",
    "\n",
    "            \n",
    "            def _monthly_rets(self):\n",
    "                return self.data['close'].pct_change()\n",
    "            \n",
    "            def alpha_102(self):\n",
    "                \"\"\"Rolling Volatility (12-month)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).std()\n",
    "            \n",
    "            def alpha_103(self):\n",
    "                \"\"\"Rolling Skewness (12-month)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).apply(lambda x: skewness(pd.Series(x)), raw=False)\n",
    "            \n",
    "            def alpha_104(self):\n",
    "                \"\"\"Rolling Kurtosis (12-month)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).apply(lambda x: kurtosis(pd.Series(x)), raw=False)\n",
    "            \n",
    "            def alpha_105(self):\n",
    "                \"\"\"Rolling Historical VaR 5% (12-month)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).apply(lambda x: var_historic(pd.Series(x), level=5), raw=False)\n",
    "            \n",
    "            def alpha_106(self):\n",
    "                \"\"\"Rolling CVaR 5% (12-month)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).apply(lambda x: cvar_historic(pd.Series(x), level=5), raw=False)\n",
    "            \n",
    "            def alpha_107(self):\n",
    "                \"\"\"Modified Gaussian VaR (12-month, Cornish-Fisher)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).apply(lambda x: var_gaussian(pd.Series(x), level=5, modified=True), raw=False)\n",
    "            \n",
    "            def alpha_108(self):\n",
    "                \"\"\"Rolling Drawdown (12-month)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).apply(lambda x: drawdown(pd.Series(x))['Drawdown'].iloc[-1], raw=False)\n",
    "            \n",
    "            def alpha_109(self):\n",
    "                \"\"\"Rolling Sharpe Ratio (12-month)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).apply(\n",
    "                    lambda x: sharpe_ratio(pd.Series(x), riskfree_rate=0.03, periods_per_year=12),\n",
    "                    raw=False\n",
    "                )\n",
    "            \n",
    "            def alpha_110(self):\n",
    "                \"\"\"Rolling Compounded Return (12-month)\"\"\"\n",
    "                r = self._monthly_rets()\n",
    "                return r.rolling(12).apply(lambda x: compound(pd.Series(x)), raw=False)\n",
    "\n",
    "            def alpha_111(self): #12 month momentum\n",
    "                return self.data.groupby('symbol')['close'].pct_change(12)\n",
    "\n",
    "            def alpha_112(self): #1 month reversal\n",
    "                return self.data.groupby('symbol')['close'].pct_change(1) * -1\n",
    "\n",
    "            def alpha_113(self): #6-Month Volatility\n",
    "                return self.data.groupby('symbol')['return'].rolling(6).std().reset_index(level=0, drop=True)\n",
    "                \n",
    "            def alpha_114(self): #12-Month Volatility Change\n",
    "                grp = self.data.groupby('symbol')['return']\n",
    "                vol12 = grp.rolling(12).std().reset_index(level=0, drop=True)\n",
    "                vol6 = grp.rolling(6).std().reset_index(level=0, drop=True)\n",
    "                return vol12 - vol6\n",
    "                \n",
    "            def alpha_115(self): #Beta vs Market (60-month window)\n",
    "                df = self.data \n",
    "                def beta_calc(x):\n",
    "                    if len(x) < 6: return np.nan\n",
    "                    return np.cov(x['return'], x['mkt_return'])[0,1] / (np.var(x['mkt_return'])+1e-9)\n",
    "            \n",
    "                return df.groupby('symbol')[['return','mkt_return']] \\\n",
    "                         .rolling(60).apply(beta_calc).reset_index(level=0, drop=True)\n",
    "                \n",
    "            def alpha_116(self): #Correlation With Market\n",
    "                df = self.data\n",
    "                return df.groupby('symbol')[['return','mkt_return']].rolling(12) \\\n",
    "                    .corr().iloc[0::2]['mkt_return']\n",
    "\n",
    "            def alpha_117(self): #Residual Volatility\n",
    "                df = self.data\n",
    "                # regression: r = a + b*mkt + e\n",
    "                betas = df.groupby('symbol')[['return','mkt_return']] \\\n",
    "                          .rolling(24).apply(\n",
    "                              lambda x: np.polyfit(x['mkt_return'], x['return'], 1)[0]\n",
    "                          ).reset_index(level=0, drop=True)\n",
    "            \n",
    "                resid = df['return'] - betas * df['mkt_return']\n",
    "                return resid.groupby(df['symbol']).rolling(6).std().reset_index(level=0, drop=True)\n",
    "\n",
    "            def alpha_118(self): #price range volatility\n",
    "                return (self.data['high'] - self.data['low']) / self.data['close']\n",
    "                \n",
    "            def alpha_119(self): #Autocorrelation (6 months)\n",
    "                def acorr(x):\n",
    "                    if len(x) < 2: return np.nan\n",
    "                    return np.corrcoef(x[:-1], x[1:])\n",
    "                return self.data.groupby('symbol')['return'].rolling(6).apply(acorr)\n",
    "\n",
    "            def alpha_120(self): #Return/Vol Ratio (Sharpe-like)\n",
    "                grp = self.data.groupby('symbol')['return']\n",
    "                mean6 = grp.rolling(6).mean().reset_index(level=0, drop=True)\n",
    "                vol6  = grp.rolling(6).std().reset_index(level=0, drop=True)\n",
    "                return mean6 / (vol6 + 1e-9)\n",
    "\n",
    "            def alpha_121(self): #Volume Surge (Normalized)\n",
    "                grp = self.data.groupby('symbol')['volume']\n",
    "                return (grp.rolling(1).sum() / grp.rolling(6).mean()).reset_index(level=0, drop=True)\n",
    "\n",
    "            def alpha_122(self): #Trend Strength Index (TSI)\n",
    "                r = self.data.groupby('symbol')['close'].pct_change()\n",
    "                up = r.clip(lower=0)\n",
    "                down = (-r).clip(lower=0)\n",
    "                rsi = (up.rolling(6).mean() / (up.rolling(6).mean() + down.rolling(6).mean() + 1e-9))\n",
    "                return rsi\n",
    "\n",
    "            def alpha_123(self): #bollinger band position 12m\n",
    "                grp = self.data.groupby('symbol')['close']\n",
    "                ma = grp.rolling(6).mean().reset_index(level=0, drop=True)\n",
    "                std = grp.rolling(6).std().reset_index(level=0, drop=True)\n",
    "                return (self.data['close'] - ma) / (2*std + 1e-9)\n",
    "\n",
    "            def alpha_124(self): #Z-Score of Return (standartized momentum)\n",
    "                grp = self.data.groupby('symbol')['return']\n",
    "                mean12 = grp.rolling(6).mean().reset_index(level=0, drop=True)\n",
    "                std12  = grp.rolling(6).std().reset_index(level=0, drop=True)\n",
    "                return (self.data['return'] - mean12) / (std12 + 1e-9)\n",
    "\n",
    "            def alpha_125(self): #Tail Risk (Left-Tail)\n",
    "                def cvar(x):\n",
    "                    if len(x) < 6: return np.nan\n",
    "                    q = np.percentile(x, 5)\n",
    "                    return x[x <= q].mean()\n",
    "                return self.data.groupby('symbol')['return'].rolling(12).apply(cvar)\n",
    "\n",
    "            def alpha_126(self): #Max Drawdown (Rolling 24 Months)\n",
    "                def dd(r):\n",
    "                    wealth = (1+r).cumprod()\n",
    "                    peak = wealth.cummax()\n",
    "                    return (wealth - peak).min() / peak.max()\n",
    "                return self.data.groupby('symbol')['return'].rolling(12).apply(dd)\n",
    "\n",
    "                \n",
    "    \n",
    "        \n",
    "        # ==================== SUMMARY OF ALL 101 ALPHAS ====================\n",
    "        \"\"\"\n",
    "        COMPLETE BREAKDOWN BY DATA REQUIREMENTS:\n",
    "        \n",
    "        ✓ MONTHLY-COMPATIBLE (24 alphas):\n",
    "        Alphas 3, 4, 9, 10, 12, 13, 15, 16, 22, 23, 24, 26, 30, 33, 40, 44, 45, 46, \n",
    "        49, 51, 53, 54, 55, 60, 83, 101\n",
    "        \n",
    "        These work with basic monthly OHLCV data (open can be approximated).\n",
    "        \n",
    "        ✗ REQUIRES VWAP (39 alphas):\n",
    "        Alphas 5, 11, 25, 27, 32, 41, 42, 47, 50, 57, 61, 62, 63, 64, 65, 66, 67, 69, \n",
    "        71, 72, 73, 74, 77, 78, 79, 81, 84, 86, 87, 89, 91, 93, 94, 96, 97, 98\n",
    "        \n",
    "        VWAP = Volume-Weighted Average Price (intraday calculation)\n",
    "        \n",
    "        ✗ REQUIRES INDUSTRY CLASSIFICATION (26 alphas):\n",
    "        Alphas 48, 58, 59, 63, 67, 69, 70, 76, 79, 80, 82, 87, 89, 90, 91, 93, 97, 100\n",
    "        \n",
    "        Needs sector/industry data for neutralization\n",
    "        \n",
    "        ✗ REQUIRES DAILY DATA - ADV (Average Daily Volume) (68 alphas):\n",
    "        Alphas 1, 2, 7, 8, 14, 17, 19, 21, 25, 28, 29, 31, 34, 35, 36, 39, 43, 47, 52, \n",
    "        56, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, \n",
    "        82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100\n",
    "        \n",
    "        ADV = Average Daily Volume over N days (adv5, adv10, adv20, adv30, adv40, \n",
    "        adv50, adv60, adv81, adv120, adv150, adv180)\n",
    "        \n",
    "        ✗ REQUIRES ACCURATE OPEN PRICES (21 alphas):\n",
    "        Alphas 2, 3, 6, 8, 14, 18, 20, 33, 36, 37, 38, 54, 65, 66, 73, 82, 92, 95, 98, 101\n",
    "        \n",
    "        Most alphas work with approximated open, but these need precise opening prices\n",
    "        \n",
    "        ✗ REQUIRES DAILY RETURNS (15 alphas):\n",
    "        Alphas 1, 8, 14, 19, 29, 34, 35, 39, 52, 56\n",
    "        \n",
    "        Need daily return calculations for proper signal\n",
    "        \n",
    "        ✗ REQUIRES MARKET CAP (1 alpha):\n",
    "        Alpha 56\n",
    "        \n",
    "        Needs market capitalization data\n",
    "        \n",
    "        CATEGORIZED SUMMARY:\n",
    "        ====================\n",
    "        • Works with Monthly Data Only: 24/101 (24%)\n",
    "        • Needs Daily Data: 68/101 (67%)\n",
    "        • Needs VWAP: 39/101 (39%)\n",
    "        • Needs Industry Data: 26/101 (26%)\n",
    "        • Needs Special Data: Multiple requirements overlap\n",
    "        \n",
    "        KEY INSIGHT:\n",
    "        The 101 Alphas were designed for HIGH-FREQUENCY trading with:\n",
    "        - Tick/minute data for VWAP calculation\n",
    "        - Daily data for ADV calculations  \n",
    "        - Industry classifications for market-neutral strategies\n",
    "        - High-quality open prices from market open\n",
    "        \n",
    "        For MONTHLY data analysis, only 24 alphas work reliably.\n",
    "        \n",
    "        RECOMMENDATION:\n",
    "        ===============\n",
    "        1. If you have MONTHLY data → Use the 24 monthly-compatible alphas OR \n",
    "           the custom alphas in AlphaBacktester (better adapted for monthly frequency)\n",
    "        \n",
    "        2. If you get DAILY data → Use all applicable alphas (those not requiring VWAP/industry)\n",
    "        \n",
    "        3. If you have INTRADAY data + VWAP → Most alphas become available\n",
    "        \n",
    "        4. If you have INDUSTRY classifications → All non-VWAP alphas work\n",
    "        \n",
    "        MONTHLY-COMPATIBLE ALPHAS DETAIL:\n",
    "        ==================================\n",
    "        Alpha 3:  -1 * correlation(rank(open), rank(volume), 10)\n",
    "        Alpha 4:  -1 * Ts_Rank(rank(low), 9)\n",
    "        Alpha 9:  Conditional on delta(close, 1) with ts_min/ts_max\n",
    "        Alpha 10: rank of Alpha 9\n",
    "        Alpha 12: sign(delta(volume, 1)) * (-1 * delta(close, 1))\n",
    "        Alpha 13: -1 * rank(covariance(rank(close), rank(volume), 5))\n",
    "        Alpha 15: -1 * sum(rank(correlation(rank(high), rank(volume), 3)), 3)\n",
    "        Alpha 16: -1 * rank(covariance(rank(high), rank(volume), 5))\n",
    "        Alpha 22: -1 * (delta(correlation(high, volume, 5), 5) * rank(stddev(close, 20)))\n",
    "        Alpha 23: Conditional with high moving average\n",
    "        Alpha 24: Conditional with close moving average\n",
    "        Alpha 26: -1 * ts_max(correlation(ts_rank(volume, 5), ts_rank(high, 5), 5), 3)\n",
    "        Alpha 30: Sign-based with volume ratios\n",
    "        Alpha 33: rank(-1 * ((1 - (open / close))^1))\n",
    "        Alpha 40: (-1 * rank(stddev(high, 10))) * correlation(high, volume, 10)\n",
    "        Alpha 44: -1 * correlation(high, rank(volume), 5)\n",
    "        Alpha 45: Complex correlation with delays\n",
    "        Alpha 46: Conditional on moving average slopes (threshold 0.25)\n",
    "        Alpha 49: Conditional on moving average slopes (threshold -0.1)\n",
    "        Alpha 51: Conditional on moving average slopes (threshold -0.05)\n",
    "        Alpha 53: -1 * delta((((close - low) - (high - close)) / (close - low)), 9)\n",
    "        Alpha 54: Complex open-close power ratio\n",
    "        Alpha 55: -1 * correlation(rank(price range), rank(volume), 6)\n",
    "        Alpha 60: Scale and rank with volume weighting\n",
    "        Alpha 83: Complex ratio with delays (if VWAP approximated)\n",
    "        Alpha 101: (close - open) / ((high - low) + .001)\n",
    "        Other Alphas from academic sources such as EDHEC Kit, specified for monthly returns\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8df704a-2f4a-41ca-aecb-80d88ae82605",
   "metadata": {},
   "outputs": [],
   "source": [
    "                      \n",
    "def skewness(r):\n",
    "    \"\"\"\n",
    "    Alternative to scipy.stats.skew()\n",
    "    Computes the skewness of the supplied Series or DataFrame\n",
    "    Returns a float or a Series\n",
    "    \"\"\"\n",
    "    demeaned_r = r - r.mean()\n",
    "    # use the population standard deviation, so set dof=0\n",
    "    sigma_r = r.std(ddof=0)\n",
    "    exp = (demeaned_r**3).mean()\n",
    "    return exp/sigma_r**3\n",
    "\n",
    "\n",
    "def kurtosis(r):\n",
    "    \"\"\"\n",
    "    Alternative to scipy.stats.kurtosis()\n",
    "    Computes the kurtosis of the supplied Series or DataFrame\n",
    "    Returns a float or a Series\n",
    "    \"\"\"\n",
    "    demeaned_r = r - r.mean()\n",
    "    # use the population standard deviation, so set dof=0\n",
    "    sigma_r = r.std(ddof=0)\n",
    "    exp = (demeaned_r**4).mean()\n",
    "    return exp/sigma_r**4\n",
    "\n",
    "\n",
    "def compound(r):\n",
    "    \"\"\"\n",
    "    returns the result of compounding the set of returns in r\n",
    "    \"\"\"\n",
    "    return np.expm1(np.log1p(r).sum())\n",
    "\n",
    "                         \n",
    "def annualize_rets(r, periods_per_year):\n",
    "    \"\"\"\n",
    "    Annualizes a set of returns\n",
    "    We should infer the periods per year\n",
    "    but that is currently left as an exercise\n",
    "    to the reader :-)\n",
    "    \"\"\"\n",
    "    compounded_growth = (1+r).prod()\n",
    "    n_periods = r.shape[0]\n",
    "    return compounded_growth**(periods_per_year/n_periods)-1\n",
    "\n",
    "\n",
    "def annualize_vol(r, periods_per_year):\n",
    "    \"\"\"\n",
    "    Annualizes the vol of a set of returns\n",
    "    We should infer the periods per year\n",
    "    but that is currently left as an exercise\n",
    "    to the reader :-)\n",
    "    \"\"\"\n",
    "    return r.std()*(periods_per_year**0.5)\n",
    "\n",
    "\n",
    "def sharpe_ratio(r, riskfree_rate, periods_per_year):\n",
    "    \"\"\"\n",
    "    Computes the annualized sharpe ratio of a set of returns\n",
    "    \"\"\"\n",
    "    # convert the annual riskfree rate to per period\n",
    "    rf_per_period = (1+riskfree_rate)**(1/periods_per_year)-1\n",
    "    excess_ret = r - rf_per_period\n",
    "    ann_ex_ret = annualize_rets(excess_ret, periods_per_year)\n",
    "    ann_vol = annualize_vol(r, periods_per_year)\n",
    "    return ann_ex_ret/ann_vol\n",
    "\n",
    "\n",
    "import scipy.stats\n",
    "def is_normal(r, level=0.01):\n",
    "    \"\"\"\n",
    "    Applies the Jarque-Bera test to determine if a Series is normal or not\n",
    "    Test is applied at the 1% level by default\n",
    "    Returns True if the hypothesis of normality is accepted, False otherwise\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(is_normal)\n",
    "    else:\n",
    "        statistic, p_value = scipy.stats.jarque_bera(r)\n",
    "        return p_value > level\n",
    "\n",
    "\n",
    "def drawdown(return_series: pd.Series):\n",
    "    \"\"\"Takes a time series of asset returns.\n",
    "       returns a DataFrame with columns for\n",
    "       the wealth index, \n",
    "       the previous peaks, and \n",
    "       the percentage drawdown\n",
    "    \"\"\"\n",
    "    wealth_index = 1000*(1+return_series).cumprod()\n",
    "    previous_peaks = wealth_index.cummax()\n",
    "    drawdowns = (wealth_index - previous_peaks)/previous_peaks\n",
    "    return pd.DataFrame({\"Wealth\": wealth_index, \n",
    "                         \"Previous Peak\": previous_peaks, \n",
    "                         \"Drawdown\": drawdowns})\n",
    "\n",
    "\n",
    "def semideviation(r):\n",
    "    \"\"\"\n",
    "    Returns the semideviation aka negative semideviation of r\n",
    "    r must be a Series or a DataFrame, else raises a TypeError\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.Series):\n",
    "        is_negative = r < 0\n",
    "        return r[is_negative].std(ddof=0)\n",
    "    elif isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(semideviation)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "\n",
    "\n",
    "def var_historic(r, level=5):\n",
    "    \"\"\"\n",
    "    Returns the historic Value at Risk at a specified level\n",
    "    i.e. returns the number such that \"level\" percent of the returns\n",
    "    fall below that number, and the (100-level) percent are above\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(var_historic, level=level)\n",
    "    elif isinstance(r, pd.Series):\n",
    "        return -np.percentile(r, level)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "\n",
    "\n",
    "def cvar_historic(r, level=5):\n",
    "    \"\"\"\n",
    "    Computes the Conditional VaR of Series or DataFrame\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.Series):\n",
    "        is_beyond = r <= -var_historic(r, level=level)\n",
    "        return -r[is_beyond].mean()\n",
    "    elif isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(cvar_historic, level=level)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "def var_gaussian(r, level=5, modified=False):\n",
    "    \"\"\"\n",
    "    Returns the Parametric Gauusian VaR of a Series or DataFrame\n",
    "    If \"modified\" is True, then the modified VaR is returned,\n",
    "    using the Cornish-Fisher modification\n",
    "    \"\"\"\n",
    "    # compute the Z score assuming it was Gaussian\n",
    "    z = norm.ppf(level/100)\n",
    "    if modified:\n",
    "        # modify the Z score based on observed skewness and kurtosis\n",
    "        s = skewness(r)\n",
    "        k = kurtosis(r)\n",
    "        z = (z +\n",
    "                (z**2 - 1)*s/6 +\n",
    "                (z**3 -3*z)*(k-3)/24 -\n",
    "                (2*z**3 - 5*z)*(s**2)/36\n",
    "            )\n",
    "    return -(r.mean() + z*r.std(ddof=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16f685f0-d9d6-41ee-9157-a103f2fe3e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING META-ALPHA WITH BIST100 DATA\n",
      "============================================================\n",
      "\n",
      "[1/5] Loading BIST100 data...\n",
      "  Loading from pickle: bist100_data.pkl\n",
      "✓ Loaded 100 stocks from pickle\n",
      "\n",
      "[2/5] Converting to long format...\n",
      "  Long format shape: (292865, 17)\n",
      "  Date range: 2010-01-04 00:00:00 to 2025-12-31 00:00:00\n",
      "  Unique stocks: 100\n",
      "  Columns: ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume', 'returns', 'vwap', 'adv10', 'adv15', 'adv20', 'adv30', 'adv40', 'adv60', 'adv120', 'adv180']\n",
      "\n",
      "  Sample data:\n",
      "  symbol       date  open  high   low  close     volume   returns      vwap  \\\n",
      "0  AEFES 2010-01-04  1.09  1.09  1.07   1.09  1430000.0       NaN  1.083333   \n",
      "1  AEFES 2010-01-05  1.09  1.09  1.07   1.07  4370000.0 -0.018349  1.078310   \n",
      "2  AEFES 2010-01-06  1.07  1.09  1.06   1.09  3430000.0  0.018692  1.078938   \n",
      "3  AEFES 2010-01-07  1.09  1.10  1.07   1.09  2580000.0  0.000000  1.080627   \n",
      "4  AEFES 2010-01-08  1.10  1.10  1.08   1.09  4360000.0  0.000000  1.083154   \n",
      "5  AEFES 2010-01-11  1.10  1.10  1.07   1.07  5920000.0 -0.018349  1.082309   \n",
      "6  AEFES 2010-01-12  1.08  1.09  1.07   1.09  3630000.0  0.018692  1.082453   \n",
      "7  AEFES 2010-01-13  1.09  1.10  1.08   1.09  4210000.0  0.000000  1.083515   \n",
      "8  AEFES 2010-01-14  1.10  1.10  1.08   1.08  4260000.0 -0.009174  1.083908   \n",
      "9  AEFES 2010-01-15  1.09  1.09  1.06   1.07  4780000.0 -0.009259  1.082611   \n",
      "\n",
      "       adv10  adv15  adv20  adv30  adv40  adv60  adv120  adv180  \n",
      "0        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "1        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "2        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "3        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "4        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "5        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "6        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "7        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "8        NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "9  3897000.0    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
      "\n",
      "[3/5] Initializing Alpha101 calculator...\n",
      "  ✓ Alpha101 initialized\n",
      "  Data shape: (292865, 19)\n",
      "  Columns available: ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume', 'returns', 'vwap', 'adv10', 'adv15', 'adv20', 'adv30', 'adv40', 'adv60', 'adv120', 'adv180', 'return', 'mkt_return']\n",
      "\n",
      "============================================================\n",
      "FITTING META-ALPHA MODEL\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Building Alpha Matrix\n",
      "============================================================\n",
      "  ✓ Alpha 1: computed successfully\n",
      "  ✗ Alpha 2: 'x'\n",
      "  ✗ Alpha 3: 'x'\n",
      "  ✓ Alpha 4: computed successfully\n",
      "  ✓ Alpha 5: computed successfully\n",
      "  ✗ Alpha 6: 'x'\n",
      "  ✓ Alpha 7: computed successfully\n",
      "  ✓ Alpha 8: computed successfully\n",
      "  ✓ Alpha 9: computed successfully\n",
      "  ✓ Alpha 10: computed successfully\n",
      "  ✓ Alpha 11: computed successfully\n",
      "  ✓ Alpha 12: computed successfully\n",
      "  ✗ Alpha 13: 'x'\n",
      "  ✗ Alpha 14: 'x'\n",
      "  ✗ Alpha 15: 'x'\n",
      "  ✗ Alpha 16: 'x'\n",
      "  ✓ Alpha 17: computed successfully\n",
      "  ✗ Alpha 18: 'x'\n",
      "  ✓ Alpha 19: computed successfully\n",
      "  ✓ Alpha 20: computed successfully\n",
      "  ✓ Alpha 21: computed successfully\n",
      "  ✗ Alpha 22: 'x'\n",
      "  ✓ Alpha 23: computed successfully\n",
      "  ✓ Alpha 24: computed successfully\n",
      "  ✓ Alpha 25: computed successfully\n",
      "  ✗ Alpha 26: 'x'\n",
      "  ✗ Alpha 27: 'x'\n",
      "  ✗ Alpha 28: 'x'\n",
      "  ✗ Alpha 29: need at least one array to concatenate\n",
      "  ✓ Alpha 30: computed successfully\n",
      "  ✗ Alpha 31: 'x'\n",
      "  ✗ Alpha 32: 'x'\n",
      "  ✓ Alpha 33: computed successfully\n",
      "  ✓ Alpha 34: computed successfully\n",
      "  ✓ Alpha 35: computed successfully\n",
      "  ✗ Alpha 36: 'x'\n",
      "  ✗ Alpha 37: 'x'\n",
      "  ✓ Alpha 38: computed successfully\n",
      "  ✓ Alpha 39: computed successfully\n",
      "  ✗ Alpha 40: 'x'\n",
      "  ✓ Alpha 41: computed successfully\n",
      "  ✓ Alpha 42: computed successfully\n",
      "  ✓ Alpha 43: computed successfully\n",
      "  ✗ Alpha 44: 'x'\n",
      "  ✗ Alpha 45: 'x'\n",
      "  ✓ Alpha 46: computed successfully\n",
      "  ✓ Alpha 47: computed successfully\n",
      "  ✗ Alpha 48: 'x'\n",
      "  ✓ Alpha 49: computed successfully\n",
      "  ✗ Alpha 50: 'x'\n",
      "\n",
      "✓ Successfully computed 28 alphas\n",
      "  Alphas: [1, 4, 5, 7, 8, 9, 10, 11, 12, 17, 19, 20, 21, 23, 24, 25, 30, 33, 34, 35, 38, 39, 41, 42, 43, 46, 47, 49]\n",
      "  Matrix shape: (292865, 28)\n",
      "\n",
      "============================================================\n",
      "Preparing Training Data\n",
      "============================================================\n",
      "  Original data points: 292865\n",
      "  After removing NaN alphas: 292865\n",
      "  After removing NaN targets: 292365\n",
      "  Final training samples: 292365\n",
      "\n",
      "============================================================\n",
      "Normalizing Features\n",
      "============================================================\n",
      "  Infinite values in X: 0\n",
      "  ✓ Features normalized (mean=0, std=1)\n",
      "\n",
      "============================================================\n",
      "Training with Time-Series Cross-Validation\n",
      "============================================================\n",
      "  ✓ Optimal alpha (regularization): 0.000267\n",
      "  ✓ Cross-validated R²: 0.0014\n",
      "\n",
      "============================================================\n",
      "SELECTED ALPHAS (Non-Zero Coefficients)\n",
      "============================================================\n",
      "alpha42    0.001137\n",
      "alpha8     0.000566\n",
      "alpha30    0.000470\n",
      "alpha11    0.000134\n",
      "alpha49   -0.000025\n",
      "alpha21   -0.000035\n",
      "alpha43   -0.000131\n",
      "alpha4    -0.000167\n",
      "alpha19   -0.000623\n",
      "alpha35   -0.001180\n",
      "dtype: float64\n",
      "\n",
      "Total selected: 10 / 28\n",
      "\n",
      "[5/5] Analyzing meta-alpha performance...\n",
      "\n",
      "============================================================\n",
      "META-ALPHA PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "Correlation with returns: 0.0277\n",
      "Rank correlation (Spearman): 0.0161\n",
      "\n",
      "Quintile Returns (1=lowest, 5=highest meta-alpha):\n",
      "  Q1: -0.007%\n",
      "  Q2: 0.043%\n",
      "  Q3: 0.070%\n",
      "  Q4: 0.156%\n",
      "  Q5: 0.244%\n",
      "\n",
      "Long-Short Spread (Q5-Q1): 0.251%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACJQElEQVR4nOzdd3xUVf7/8fednk4ChFADIohUEVEQlQ6CDdDVld8qYll3WV1dxN7AgohfXXbtrgUVsawCFmzYEAUUWZWioiC9l5CeyZT7+2MyQ4YkkIFkJsm8no9vvnvvuXdmPjNnJjLvnHOuYZqmKQAAAAAAACCKLLEuAAAAAAAAAPGHUAoAAAAAAABRRygFAAAAAACAqCOUAgAAAAAAQNQRSgEAAAAAACDqCKUAAAAAAAAQdYRSAAAAAAAAiDpCKQAAAAAAAEQdoRQAAAAAAACijlAKABBm5syZMgxDhmHoiy++qHDcNE0de+yxMgxDAwYMOKLHeOKJJzRz5syjqvNwVq5cKcMwZLfbtX379krPGTBgwBE/h8mTJ8swDO3Zs+coqjy8YH989913tfo4tcnj8ejpp59W7969lZGRocTERGVnZ+u8887T3LlzQ+d98cUXMgxDb775ZlTqmj17tmbMmBHRbfx+v15++WUNGTJETZo0kd1uV2Zmps4++2y9++678vv9tVNsDWnbtq0uu+yyI7rt1KlTNW/evArtwX6r7PdFbdqwYUPod5VhGLJYLGrcuLFGjhypJUuWHNF9DhgwQF27dj3iml566SU1bdpU+fn5YfdZvs7gz5lnnlmt+zz4edrtdjVu3Fi9e/fWP/7xD61evfqI6z1abdu2rfS5GYahgoKCmNVV2y677DK1bds2tJ+Tk6NGjRpV+vkAABwaoRQAoFIpKSl67rnnKrQvXLhQ69atU0pKyhHfdzRCqWeffVaS5PV69dJLL9XqY+HQLrnkEl177bUaOHCgZs2apXfffVd33HGHbDabPvroo5jVFWkoVVJSopEjR2rcuHHKzMzUk08+qc8++0xPPfWUWrRooT/84Q969913a6/gGKsqlDrxxBO1ZMkSnXjiidEvStK1116rJUuWaNGiRXrggQf0448/auDAgfr++++jWkdRUZFuu+023XzzzRV+Px5zzDFasmRJ2E+kgWjweS5cuFAvv/yyRo0apXfeeUc9evTQQw89VIPPJDL9+vWr8NyWLFmixMTEmNUUbenp6frHP/6hG2+8UaWlpbEuBwDqFVusCwAA1E0XXXSRXnnlFT3++ONKTU0NtT/33HPq27ev8vLyYljdobndbr3yyivq0aOH9uzZo+eff14333xzrMuKS+vXr9frr7+uu+66S1OmTAm1Dx48WFdddVVMRhYVFRUd0RfmiRMn6qOPPtKLL76oSy+9NOzYmDFjdOONN6q4uLimyqw3UlNT1adPn5g9fps2bUKP369fPx177LEaPHiwnnjiCf3nP/+JWh0vvvii9u7dqyuvvLLCsYSEhKN+jco/T0kaOXKkJk6cqDFjxuimm25S165dNWLEiKN6jCPRqFGjWul/0zRVUlKihISEGr/vw/F4PDIMQzZb9b8q/eUvf9F9992nN998U2PHjq3F6gCgYWGkFACgUhdffLEk6dVXXw215ebm6q233tLll19e6W1KS0t13333qVOnTnI6nWratKnGjx+v3bt3h85p27atVq9erYULF4ameQSnQZSUlOiGG27QCSecoLS0NGVkZKhv3756++23I6p93rx5oS+H48aN06+//qqvvvrqsLcLTpOZPn267r//frVp00Yul0snnXSSPv3000pvs3PnTl188cVKS0tTs2bNdPnllys3NzfsnMcff1xnnHGGMjMzlZSUpG7dumn69OnyeDwRPa9D+eqrrzR48GClpKQoMTFRp556qubPnx92TnAq4Oeff66//vWvatKkiRo3bqwxY8Zo27ZtYee63W7dcMMNysrKUmJios444wwtX7484ulfe/fulSQ1b9680uMWS8V/ing8Ht1+++1q0aKFUlNTNWTIEK1Zs6bCec8//7x69Oghl8uljIwMjR49Wj///HPYOZdddpmSk5O1cuVKDRs2TCkpKRo8eLAGDBig+fPna+PGjWFTjqqyY8cOPfvssxo+fHiFQCqoQ4cO6t69u6QDr/WGDRvCzqlsqltwytiSJUt06qmnKiEhQW3bttULL7wgSZo/f75OPPFEJSYmqlu3bvrwww8rPMfyU4mCglNMD6W6nznDMFRYWKgXX3wx9FoFp74e/JxmzJghwzC0du3aCo938803y+FwhE17/eSTTzR48GClpqYqMTFR/fr1q/LzVh3BgGTjxo2SInvfH40nn3xS55xzjho1alRj93k4CQkJeu6552S328NGS+3evVsTJkxQ586dlZycrMzMTA0aNEiLFi0KnWOapjp06KDhw4dXuN+CggKlpaXpb3/721HXuG/fPk2YMEEtW7aUw+HQMccco9tvv11utzvsPMMwdM011+ipp57S8ccfL6fTqRdffFG9e/fWWWedFXZut27dZBiGli1bFmqbM2eODMPQypUrJUlr167V+PHj1aFDByUmJqply5Y655xzQseDgu/fl19+WTfccINatmwpp9MZev/OnDlTxx13nJxOp44//vgqR942a9ZMQ4cO1VNPPXXUrxkAxBNCKQBApVJTU3XBBRfo+eefD7W9+uqrslgsuuiiiyqc7/f7dd5552natGkaO3as5s+fr2nTpmnBggUaMGBAaATJ3Llzdcwxx6hnz56haR7BdYXcbrf27dunSZMmad68eXr11Vd12mmnacyYMRFNwXvuuefkdDr1//7f/9Pll18uwzAqnYpYlccee0wffvihZsyYoVmzZslisWjEiBGVrlNz/vnnq2PHjnrrrbd0yy23aPbs2frHP/4Rds66des0duxYvfzyy3rvvfd0xRVX6KGHHtLVV19d7ZoOZeHChRo0aJByc3P13HPP6dVXX1VKSorOOeccvf766xXOv/LKK2W32zV79mxNnz5dX3zxhf70pz+FnTN+/HjNmDFD48eP19tvv63zzz9fo0eP1v79+yOq7fjjj1ejRo00ZcoUPfPMMxVCmsrcdttt2rhxo5599lk988wz+u2333TOOefI5/OFznnggQd0xRVXqEuXLpozZ47+9a9/acWKFerbt69+++23sPsrLS3Vueeeq0GDBuntt9/WlClT9MQTT6hfv37KysoKm3JUlc8//1wej0ejRo2K6PlX144dOzR+/HhdeeWVevvtt9WtWzddfvnluueee3Trrbfqpptu0ltvvaXk5GSNGjWqxsKU6n7mlixZooSEhNB6TUuWLNETTzxR6X3+6U9/ksPhqDBF1+fzadasWTrnnHPUpEkTSdKsWbM0bNgwpaam6sUXX9Qbb7yhjIwMDR8+/IiDqWCY0LRp07D26rzvj9SWLVu0cuVKDRw4sNLj69atU0ZGhmw2m9q3b6/bb7+9xkbVtWjRQr169dLixYvl9XolBYIgSbr77rs1f/58vfDCCzrmmGM0YMCAUHhoGIauvfZaLViwoMJn5qWXXlJeXl61QinTNOX1esN+giMgS0pKNHDgQL300kuaOHGi5s+frz/96U+aPn26xowZU+G+5s2bpyeffFJ33XWXPvroI51++ukaMmSIvvzyy1CIv3PnTq1atUoJCQlasGBB6LaffPKJmjVrpm7dukmStm3bpsaNG2vatGn68MMP9fjjj8tms+mUU06pNOS+9dZbtWnTJj311FN69913lZmZqZkzZ2r8+PE6/vjj9dZbb+mOO+7Qvffeq88++6zS12LAgAH6+uuvI/49CQBxzQQAoJwXXnjBlGQuW7bM/Pzzz01J5qpVq0zTNM3evXubl112mWmaptmlSxezf//+odu9+uqrpiTzrbfeCru/ZcuWmZLMJ554ItR28G2r4vV6TY/HY15xxRVmz549q1X/hg0bTIvFYv7xj38MtfXv399MSkoy8/Lyws7t379/WB3r1683JZktWrQwi4uLQ+15eXlmRkaGOWTIkFDb3XffbUoyp0+fHnafEyZMMF0ul+n3+yutz+fzmR6Px3zppZdMq9Vq7tu375DPp3x/VKVPnz5mZmammZ+fH2rzer1m165dzVatWoVqCd7XhAkTwm4/ffp0U5K5fft20zRNc/Xq1aYk8+abbw47L9jH48aNO2TNB5s/f77ZpEkTU5IpyWzcuLH5hz/8wXznnXfCzgu+30aOHBnW/sYbb5iSzCVLlpimaZo5OTlmQkJChfM2bdpkOp1Oc+zYsaG2cePGmZLM559/vkJdZ511lpmdnV2t5zBt2jRTkvnhhx9W6/zga71+/fqw9uBz/Pzzz0Nt/fv3NyWZ3333Xaht7969ptVqNRMSEsytW7eG2n/44QdTkvnvf/877DlW9jyC79HysrOzD9l/h/rMJSUlVXrbyp7TmDFjzFatWpk+ny/U9v7775uSzHfffdc0TdMsLCw0MzIyzHPOOSfs/nw+n9mjRw/z5JNPrrJO0zzweX3wwQdNj8djlpSUmMuXLzd79+5tSjLnz59vmmb13/emGeiLLl26HPJxK/P666+bksylS5dWOHb77bebTzzxhPnZZ5+Z8+fPN6+55hrTZrOZZ5xxRtjrc7jn+dBDD1V5zkUXXWRKMnfu3Fnp8WC/Dh482Bw9enSoPS8vz0xJSTGvu+66sPM7d+5sDhw48LC1ZWdnhz7X5X9uv/120zRN86mnnjIlmW+88UbY7R588EFTkvnxxx+H2iSZaWlpFX4nfvLJJ6Yk88svvzRN0zRnzZplpqSkmBMmTAirsUOHDmGf/cpeg9LSUrNDhw7mP/7xj1B78P17xhlnhJ3v8/nMFi1amCeeeGLY7/MNGzaYdru90s/cggULTEnmBx98UGUdAIBwjJQCAFSpf//+at++vZ5//nmtXLlSy5Ytq3Lq3nvvvadGjRrpnHPOCfuL+QknnKCsrKxqX5nrv//9r/r166fk5GTZbDbZ7XY999xzYdOy/H5/2GOUH0HzwgsvyO/3h9V5+eWXq7CwsNJRQ5UZM2aMXC5XaD846ujLL78MeyxJOvfcc8P2u3fvrpKSEu3atSvU9v333+vcc89V48aNZbVaZbfbdemll8rn8+nXX3+tVk1VKSws1DfffKMLLrhAycnJoXar1apLLrlEW7ZsqTAqoLKapQPTnRYuXChJuvDCC8POu+CCCyqssXLwCInK+mTkyJHatGmT5s6dq0mTJqlLly6aN2+ezj33XF1zzTUVntPh6luyZImKi4srTCNs3bq1Bg0aVOkIm/PPP79CW13SvHlz9erVK7SfkZGhzMxMnXDCCWrRokWo/fjjj5d04LWoCdX5zEVq/Pjx2rJliz755JNQ2wsvvKCsrKzQukeLFy/Wvn37NG7cuAqjbM4880wtW7ZMhYWFh32sm2++WXa7XS6XS7169dKmTZv09NNPa+TIkWHnHe59dTSCI9cyMzMrHLvvvvv017/+VQMHDtTIkSP16KOPatq0afryyy/Dpkke/BkyTbPaj1/ZuU899ZROPPFEuVyuUL9++umnYf2akpKi8ePHa+bMmaHX+rPPPtNPP/1U6WezMqeddpqWLVsW9jNhwoTQfSUlJemCCy4Iu03ws3vwZ3XQoEFKT08Pa+vXr59cLlfovRQcfXvmmWdq8eLFKioq0ubNm/Xbb79pyJAhodt5vV5NnTpVnTt3lsPhkM1mk8Ph0G+//Vbpe/vg3xFr1qzRtm3bNHbs2LBpsNnZ2Tr11FMrfS2C/b9169YqXy8AQDhCKQBAlQzD0Pjx4zVr1iw99dRT6tixo04//fRKz925c6f2798vh8Mhu90e9rNjx46wNWSqMmfOHF144YVq2bKlZs2apSVLloSCsJKSktB5l19+edj9Dx48WFIgrJo5c2ZoOsv+/fu1f/9+DRkyRElJSdWewpeVlVVpW2lpaYXLnDdu3Dhs3+l0SlJoas6mTZt0+umna+vWrfrXv/6lRYsWadmyZXr88cfDzjtSOTk5Mk2z0jWbgmFGcF2n6tYcPL9Zs2Zh59lstgq3PbivD+6ToISEBI0aNUoPPfSQFi5cqLVr16pz5856/PHHK1zSvrr1VfWcD36+iYmJYYv1H4k2bdpICizcXhsyMjIqtDkcjgrtDodDksI+D0ejup+5SI0YMULNmzcPrYuVk5Ojd955R5deeqmsVqukwO8MKRB2Hvz+efDBB2WaZmga2qFcd911WrZsmZYvX65169Zp+/bt+vOf/1zhvMO9r45G8D7Kh9mHEpw2uHTp0lDbwa/Biy++WO3H37hxo5xOZ+j98sgjj+ivf/2rTjnlFL311ltaunSpli1bpjPPPLPC87322muVn5+vV155RVJg+nKrVq103nnnVeux09LSdNJJJ4X9lP/dk5WVVWFts8zMTNlstgqf1co+0y6XS/369QuFUp9++qmGDh2qAQMGyOfzadGiRaFpfOVDqYkTJ+rOO+/UqFGj9O677+qbb77RsmXL1KNHj0r7/ODHDtZW1X8PKhPs/3i84AEAHCmuvgcAOKTLLrtMd911l5566indf//9VZ4XXDz44EWYgw6+RHplZs2apXbt2un1118P+xJz8IK4kydPDvsrfvC+P/nkk9Coh4O/gEqBL4A//fSTOnfufMg6duzYUWmbw+EIG41UHfPmzVNhYaHmzJmj7OzsUPsPP/wQ0f1UJT09XRaLRdu3b69wLDh6I7h+T3UFX7udO3eqZcuWoXav11vhS2T5hYbLO1x/t2nTRn/+8591/fXXa/Xq1erSpUvE9VX1nA9+vodb7Ls6Bg4cKLvdrnnz5ukvf/nLYc8Pfjk9+L1bnXA2Ui6Xq8LjVPexqvuZi1RwpN6///1v7d+/X7Nnz5bb7db48eND5wT76dFHH63y6m0HB6OVadWqlU466aSjqvdoBZ/Lvn37qlzUvzLlF/o/+LPUrl27at3H1q1btXz5cvXv3z80knHWrFkaMGCAnnzyybBz8/PzK9z+2GOP1YgRI/T4449rxIgReueddzRlypRQeHg0GjdurG+++UamaYa9v3bt2iWv11vtz+rgwYN111136dtvv9WWLVs0dOhQpaSkqHfv3lqwYIG2bdumjh07qnXr1qHbzJo1S5deeqmmTp0adl979uypdDH6gx87+Humqv8eVCYYokb6OxcA4hkjpQAAh9SyZUvdeOONOuecczRu3Lgqzzv77LO1d+9e+Xy+Cn81P+mkk3TccceFznU6nZX+JdkwDDkcjrAvBzt27KhwJbC2bdtWet/PPfecLBaL5s2bp88//zzs5+WXX5aksIXbqzJnzpywUSL5+fl69913dfrpp0f8RS34XIKjMqTAVJuaulR9UlKSTjnlFM2ZMyfsNfX7/Zo1a5ZatWqljh07RnSfZ5xxhiRVmO745ptvhhZSDqqsr8v3SX5+foXRZUHBKTTlp6dVR9++fZWQkKBZs2aFtW/ZskWfffZZhVFaVanqfViZrKwsXXnllfroo4+qXHR/3bp1WrFihSSFroYX3A965513qvV4kWjbtq127doVGnkkBRZ3/+ijjw572+p+5qTIXi8pMIWvpKREr776qmbOnKm+ffuqU6dOoeP9+vVTo0aN9NNPP1X5PgqODKvrgs9r3bp11To/OAqqfBh38HOvLFg/WHFxsa688kp5vV7ddNNNoXbDMMJ+50iB92JVi/lfd911WrFihcaNGyer1aqrrrqqWs/jcAYPHqyCggLNmzcvrD34GaruZ3XIkCHyer2688471apVq9DrPWTIEH3yySf67LPPwkZJSZW/BvPnz6/21LrjjjtOzZs316uvvho2PXLjxo1avHhxpbf5/fffJemwf/gAABzASCkAwGFNmzbtsOf88Y9/1CuvvKKRI0fquuuu08knnyy73a4tW7bo888/13nnnafRo0dLClzO+7XXXtPrr7+uY445Ri6XS926ddPZZ5+tOXPmaMKECbrgggu0efNm3XvvvWrevHmFq0MdbO/evXr77bc1fPjwKqed/POf/9RLL72kBx54QHa7vcr7slqtGjp0qCZOnCi/368HH3xQeXl5mjJlymFfh4MNHTpUDodDF198sW666SaVlJToySefVE5OTkT389lnn1V65bqRI0fqgQce0NChQzVw4EBNmjRJDodDTzzxhFatWqVXX3014pFCXbp00cUXX6yHH35YVqtVgwYN0urVq/Xwww8rLS0tbHTH4axZs0bDhw/XH//4R/Xv31/NmzdXTk6O5s+fr2eeeUYDBgyocn2WqjRq1Eh33nmnbrvtNl166aW6+OKLtXfvXk2ZMkUul0t33313te6nW7dumjNnjp588kn16tVLFovlkCNuHnnkEf3++++67LLL9NFHH2n06NFq1qyZ9uzZowULFuiFF17Qa6+9pu7du6t379467rjjNGnSJHm9XqWnp2vu3Ln66quvInqu1XHRRRfprrvu0h//+EfdeOONKikp0b///e8K659VJpLPXLdu3fTFF1/o3XffVfPmzZWSkhIWNh+sU6dO6tu3rx544AFt3rxZzzzzTNjx5ORkPfrooxo3bpz27dunCy64QJmZmdq9e7d+/PFH7d69u8JIn2jIy8vTm2++WaG9adOm6t+/f6W3OeWUU5SQkKClS5eGrV21aNEi3X///Ro9erSOOeYYlZSU6IMPPtAzzzyjQYMG6Zxzzql2XZs2bdLSpUvl9/uVm5ur77//Xs8//7w2btyohx9+WMOGDQude/bZZ+vee+/V3Xffrf79+2vNmjW655571K5duwrBshT4PdW5c2d9/vnn+tOf/lTp2lhH4tJLL9Xjjz+ucePGacOGDerWrZu++uorTZ06VSNHjqwQJFWlV69eSk9P18cffxw22m7IkCG69957Q9vlnX322Zo5c6Y6deqk7t27a/ny5XrooYfUqlWraj2mxWLRvffeqyuvvFKjR4/WVVddpf3792vy5MlVTt9bunSpGjduHLoCIACgGmK4yDoAoA6qztXeTLPyK+h5PB7z//7v/8wePXqYLpfLTE5ONjt16mReffXV5m+//RY6b8OGDeawYcPMlJQUU1LYVYymTZtmtm3b1nQ6nebxxx9v/uc//6n0KmIHmzFjhinJnDdvXpXnBK8EFbxCYFVX33vwwQfNKVOmmK1atTIdDofZs2dP86OPPgq7r2BNu3fvDmuv7Kpr7777bug1admypXnjjTeaH3zwQYUrllUmeH9V/QQfZ9GiReagQYPMpKQkMyEhwezTp0/oKmcH39fBfVvZ1dNKSkrMiRMnmpmZmabL5TL79OljLlmyxExLSwu7ctXh5OTkmPfdd585aNAgs2XLlqbD4TCTkpLME044wbzvvvvMoqKiCnX897//DbuPYL+88MILYe3PPvus2b17d9PhcJhpaWnmeeedZ65evTrsnHHjxplJSUmV1rZv3z7zggsuMBs1amQahnHY95hpBq7g9eKLL5qDBg0yMzIyTJvNZjZt2tQcMWKEOXv27LCrqf3666/msGHDzNTUVLNp06bmtddea86fP7/Sq+9VdsW37Oxs86yzzqrQLsn829/+Ftb2/vvvmyeccIKZkJBgHnPMMeZjjz1W7avvVfcz98MPP5j9+vUzExMTTUmhz05l75+gZ555xpRkJiQkmLm5uZW9pObChQvNs846y8zIyDDtdrvZsmVL86yzzqrwPjhYda5KZ5qRve+DV0Ks7OdwVwy95JJLzM6dO4e1/fbbb+bIkSPNli1bmk6n03S5XGa3bt3M+++/3ywpKTnk/R38PIM/VqvVTE9PN3v16mVef/31Fd7zpmmabrfbnDRpktmyZUvT5XKZJ554ojlv3rwqr9RomqY5efLkKq8gWJWq3qPl7d271/zLX/5iNm/e3LTZbGZ2drZ56623Vnj+lb2vyxs9erQpyXzllVdCbaWlpWZSUpJpsVjMnJycsPNzcnLMK664wszMzDQTExPN0047zVy0aFGF3/tV/d4JevbZZ80OHTqYDofD7Nixo/n8889X+jr6/X4zOzvbvPbaaw/5egAAwhmmGcGlPQAAaMA2bNigdu3a6aGHHtKkSZNiXU6ds3jxYvXr10+vvPKKxo4dG+tygDrlu+++U+/evbV06VKdcsopsS4nYieddJIMw6hynTgc2qeffqphw4Zp9erVYdNUAQCHxvQ9AABQwYIFC7RkyRL16tVLCQkJ+vHHHzVt2jR16NBBY8aMiXV5QJ1z0kkn6cILL9S9996r9957L9blVEteXp5WrVql9957T8uXL9fcuXNjXVK9dd999+nyyy8nkAKACBFKAQCAClJTU/Xxxx9rxowZys/PV5MmTTRixAg98MAD1b7sPRBvHn74YT333HPKz8+v1hVHY+1///ufBg4cqMaNG+vuu+/WqFGjYl1SvZSTk6P+/ftrwoQJsS4FAOodpu8BAAAAAAAg6qp/+RwAAAAAAACghhBKAQAAAAAAIOoIpQAAAAAAABB1LHQuye/3a9u2bUpJSZFhGLEuBwAAAAAAoN4yTVP5+flq0aKFLJaqx0MRSknatm2bWrduHesyAAAAAAAAGozNmzerVatWVR4nlJJCl+zdvHmzUlNTY1zNkfN4PPr44481bNgw2e32WJeDKKLv4xd9H5/o9/hF38cv+j5+0ffxi76PXw2h7/Py8tS6detQ3lIVQikpNGUvNTW13odSiYmJSk1NrbdvXBwZ+j5+0ffxiX6PX/R9/KLv4xd9H7/o+/jVkPr+cEsksdA5AAAAAAAAoo5QCgAAAAAAAFFHKAUAAAAAAICoI5QCAAAAAABA1BFKAQAAAAAAIOoIpQAAAAAAABB1hFIAAAAAAACIOkIpAAAAAAAARB2hFAAAAAAAAKKOUAoAAAAAAABRRygFAAAAAACAqCOUAgAAAAAAQNQRSgEAAAAAACDqCKUAAAAAAAAQdYRSAAAAAAAAiDpCKQAAAAAAAEQdoRQAAAAAAACijlAKAAAAAAAAUUcoBQAAAAAAgKgjlAIAAAAAAIiSvQVu3TFvpVZs2R/rUmKOUAoAAAAAACBK/vXpb5q1dJPOfezrWJcSc4RSAAAAAAAAUbIzryTWJdQZhFIAAAAAAABR0rZJUmi7qNQbw0pij1AKAAAAAAAgSlKcttD2+j2FMawk9gilAAAAAAAAoqTUZ4a29xd5YlhJ7BFKAQAAAAAARInX5w9t5xSVxrCS2COUAgAAAAAAiBKvn5FSQYRSAAAAAAAAUeIpN1JqPyOlAAAAAAAAEA1e1pQKIZQCAAAAAACIEk/YmlLxHUrZDn8KAAAAAAAAjsaSdXvVPM0lT7mRUrnF8T19j1AKAAAAAACgFq3Ysl8X/2epJOm8E1qE2uN9pBTT9wAAAAAAAGrR2z9sC22HrykV3yOlCKUAAAAAAABq0YY9haHt0nJrSuWVeGNRTp1BKAUAAAAAAFCL9hcfmKaXV267uNQXi3LqDEIpAAAAAACAWrSv8MA0vdxyoVRRqVemaVZ2k7hAKAUAAAAAAFBLTNPUtv3Fof2ccutI+U3J7fVXdrO4QCgFAAAAAABQS/JKvGHB08FX3IvnKXyEUgAAAAAAALXE7QkPnUoPGhlV5CGUAgAAAAAAQA073PS84tL4vQIfoRQAAAAAAEAtcXsPPRKqiOl7AAAAAAAAqGklnsBIqWapzkqPE0oBAAAAAACgxi1et0eS5LBZlJ5or3Cchc4BAAAAAABQ4zbsLZIkpSXYZRhGqD3RYZXESCkAAAAAAADUAnfZ9L1zurfQvsLSUHuqKzBqqoiFzgEAAAAAAFDTggudO23hEUx6kkOStL/IE/Wa6gpCKQAAAAAAgFoSXOjcabeGtXdslixJuv/9n6NeU11BKAUAAAAAAFBLqhoptSO3JBbl1CmEUgAAAAAAALUkOD3PZbfqkQt7SJJOaZchq+XAoud+vxmT2mLNFusCAAAAAAAA6ivTNMOuqlfex6t3aOXWXElSzzaN1DwtQaN7tpQk/fnl5aHzft2Vr05ZqbVfbB3DSCkAAAAAAIAI7Slwq+0t89Xu1vf18/a8Ss955svfJUldW6aqeVqCJMkwDBmGIUe56XzPLlpf+wXXQYRSAAAAAAAAEfpg1Y7Q9oVPL6n0nH1FpZKkP5/RvsKx8mOrftlReajV0BFKAQAAAAAARCgtwR7azi/xyjQrrgsVDJ6aJjsrHCt/9qqthFIAAAAAAAA4Ah5fxVDKW7aAud1acc2pEV2zwvbjcbFzQikAAAAAAIAIHRwilXh9Fc7xlgVVNmvF+OWsbs31wvjeof1V23JruMK6j1AKAAAAAAAgQt6DQqnTpn2m/BKPPl+zSy8u3lB2jl+SZLNUHCllGIb6d2ga2r/vvZ9rr9g6yhbrAgAAAAAAAOqbg0dK5ZV49dbyLZr87k+SpOZpLu3Mc0uS7JWMlJIkS7mwaneBu5YqrbsYKQUAAAAAABChg0dKSYEFz4P+/PLy0LatkjWlDtYmI7FmCqtHCKUAAAAAAAAi5KvkantL1++t9Fy7per45YXLAutK7cpnpBQAAAAAAAAOw+fzV2j7em3loZTLUXX80jTFKUnaV0goBQAAAAAAgMOobPpeVZomO6s81ijRLknaX+Q56prqG0IpAAAAAACACPkrmb5XGZfdIsOoek2pRokOSZLb69ffX/2+RmqrLwilAAAAAAAAIlTdkVJvXN33kMeTHNbQ9js/blNucfyMmCKUAgAAAAAAqIZSr1/vr9yunMJSebyBUMpqOfSV9ZqnJRzyuGEYapLsCO1XtS5VQ2SLdQEAAAAAAAD1wdML1+nhBb9KkmxlYdSVp7XTR6t3aMPeokpvk5pw+Ohl8rlddM3swNS97zbt10mHzrkaDEZKAQAAAAAAVMPHP+0MbQen76W4bOrSIq3S8zOSHHLarJUeK+/s7i1C2y3SXEdZZf1BKAUAAAAAAFANGUmOCm0pLrvuPqez/j7oWDlt4THLh9edXu37vmFoR52Una6Le7c66jrrC0IpAAAAAACAamhcSSiVmmBTZqpLE4cdp6YpzlD7xSe3UWZq9Uc9XTu4g97866lKcsbPSkuEUgAAAAAAANXQOLmSkVJOe2jbKLcW1ANjukWjpHqNUAoAAAAAAOAwNu8r0rcbciq0pyYcCKVmXNRTqS4bgVQ1xc+YMAAAAAAAgCN0+vTPK21PcR2IVnplp+uHu4bJYomTy+cdJUZKAQAAAAAAHKHyI6UkEUhFgFAKAAAAAADgEHx+s8pjyQ4moR0pQikAAAAAAIBD8Pj8VR5LcFijWEnDQigFAAAAAABwCKUHhVJ264Epeg4b0cqR4pUDAAAAAAA4BI83PJTKSnPFqJKGhVAKAAAAAADgEDy+8DWlzujQVJLUKSslFuU0GKzGBQAAAAAAcAi7891h+6kJdq2cPEwuO+tJHQ1CKQAAAAAAgEN44ou1Yften18pLnuMqmk4Yjp974EHHlDv3r2VkpKizMxMjRo1SmvWrAk7xzRNTZ48WS1atFBCQoIGDBig1atXh53jdrt17bXXqkmTJkpKStK5556rLVu2RPOpAAAAAACABmjJur36YNWOsDa7ldWQakJMX8WFCxfqb3/7m5YuXaoFCxbI6/Vq2LBhKiwsDJ0zffp0PfLII3rssce0bNkyZWVlaejQocrPzw+dc/3112vu3Ll67bXX9NVXX6mgoEBnn322fD5fLJ4WAAAAAABoIC7+z9IKba0zEmNQScMT0+l7H374Ydj+Cy+8oMzMTC1fvlxnnHGGTNPUjBkzdPvtt2vMmDGSpBdffFHNmjXT7NmzdfXVVys3N1fPPfecXn75ZQ0ZMkSSNGvWLLVu3VqffPKJhg8fHvXnBQAAAAAAGp7sxonqlZ2uUSe0jHUpDUKdGm+Wm5srScrIyJAkrV+/Xjt27NCwYcNC5zidTvXv31+LFy+WJC1fvlwejyfsnBYtWqhr166hcwAAAAAAAI7Wq1f10SMXnqAEBwuc14Q6s9C5aZqaOHGiTjvtNHXt2lWStGNHYM5ms2bNws5t1qyZNm7cGDrH4XAoPT29wjnB2x/M7XbL7T6wcn5eXp4kyePxyOPx1MwTioFg7fX5OeDI0Pfxi76PT/R7/KLv4xd9H7/o+/hF39dNTZNstd4nDaHvq1t7nQmlrrnmGq1YsUJfffVVhWOGYYTtm6ZZoe1ghzrngQce0JQpUyq0f/zxx0pMrP/zQhcsWBDrEhAj9H38ou/jE/0ev+j7+EXfxy/6Pn7R93XBgejk/fffj9qj1ue+LyoqqtZ5dSKUuvbaa/XOO+/oyy+/VKtWrULtWVlZkgKjoZo3bx5q37VrV2j0VFZWlkpLS5WTkxM2WmrXrl069dRTK328W2+9VRMnTgzt5+XlqXXr1ho2bJhSU1Nr9LlFk8fj0YIFCzR06FDZ7VyaMp7Q9/GLvo9P9Hv8ou/jF30fv+j7+EXf1x3Tf/5SW/eXaNblJ+mUdhm1/ngNoe+DM9IOJ6ahlGmauvbaazV37lx98cUXateuXdjxdu3aKSsrSwsWLFDPnj0lSaWlpVq4cKEefPBBSVKvXr1kt9u1YMECXXjhhZKk7du3a9WqVZo+fXqlj+t0OuV0Oiu02+32etvh5TWU54HI0ffxi76PT/R7/KLv4xd9H7/o+/hF38defolXkpTVKCmqfVGf+766dcc0lPrb3/6m2bNn6+2331ZKSkpoDai0tDQlJCTIMAxdf/31mjp1qjp06KAOHTpo6tSpSkxM1NixY0PnXnHFFbrhhhvUuHFjZWRkaNKkSerWrVvoanwAAAAAAACR8vtN5bsDoVSqq05MNmtQYvqKPvnkk5KkAQMGhLW/8MILuuyyyyRJN910k4qLizVhwgTl5OTolFNO0ccff6yUlJTQ+f/85z9ls9l04YUXqri4WIMHD9bMmTNltbIaPgAAAAAAODKFpV6ZZmA7xVU/Ry3VZTGfvnc4hmFo8uTJmjx5cpXnuFwuPfroo3r00UdrsDoAAAAAABDPij2+0LbLbolhJQ0TrygAAAAAAEAlPL7AYBqHzSLDMGJcTcNDKAUAAAAAAFCJUq9fkuS0Ep/UBl5VAAAAAACASgRDKbuN+KQ28KoCAAAAAIC4ZpqmHvzwF/33u81h7R5fIJRyMFKqVnA9QwAAAAAAENeWb8zRk1+skyT94aTW2lPg1tT5P+u3XQWSAmtKoeYRSgEAAAAAgLiWW+wJ25+1dKPmfL81tG+3ssh5bSDqAwAAAAAAcc1qORA6eXx+bc0pDjvusFmjXVJcIJQCAAAAAABxrXwoVezxaWe+O+w40/dqB68qAAAAAABAmZJSn3bllYS1rd2ZH6NqGjZCKQAAAAAAENdKvf7QdlGpT/kl3rDjhaW+aJcUFwilAAAAAABAXCsfShV7fCr2EEJFA1ffAwAAAAAAcW1/uavvjfjXohhWEl8YKQUAAAAAAOLa3gJ3pe0XndRaknR889RolhM3GCkFAAAAAADiWvnpe+XddOZx6n9cU/U5pnGUK4oPhFIAAAAAACCumVW0pyc6NLJb86jWEk+YvgcAAAAAAOKa36w8lrJYjChXEl8IpQAAAAAAQFzzV5JJdW+VFv1C4gzT9wAAAAAAQFwrP1BqdM+WOqdHc3Vv1Shm9cQLQikAAAAAABDXzLJUaniXZvrnRSfEtpg4wvQ9AAAAAAAQ14IDpdo2ToppHfGGUAoAAAAAAMQ1f3BRKdY1jypCKQAAAAAAENeCI6UsBqlUNBFKAQAAAACAuOYvW1OKSCq6CKUAAAAAAEBcC159j5FS0UUoBQAAAAAA4lrw6ntkUtFFKAUAAAAAAOJacE0pg1QqqgilAAAAAABA3PpizS69tGSjJNaUijZCKQAAAAAAEJeKS3267IVloX3WlIouQikAAAAAABCXPl+zK2yfTCq6CKUAAAAAAEBcmr9ye9i+hVAqqgilAAAAAABA3Nmwp1DzV4SHUix0Hl2EUgAAAAAAIO4M+L8vKrSRSUUXoRQAAAAAAIgrpmlW2m5w/b2oIpQCAAAAAABxxe31V9rOmlLRRSgFAAAAAADiittTVShFKhVNhFIAAAAAACCuuL0+SRVHRpFJRRehFAAAAAAAiCvB6XtOmzWsnavvRRehFAAAAAAAiCsFbq8kKdFh1fVDOoTaiaSii1AKAAAAAADElV35bklSRpJDf+nfPtSeV+KJVUlxiVAKAAAAAADElRWb90uSWmckymU/MIVvR25JjCqKT4RSAAAAAAAgbpimqUW/7ZEk9cpODzu2nVAqqgilAAAAAABA3Hhy4Tp9u2GfJKlVeoIkKckRGC3Vs02jWJUVl2yxLgAAAAAAACBapn+4JrTdJiNRkvTRP87Q52t26w+9WsWqrLhEKAUAAAAAAOJSduMkSVKr9ERd0ic7xtXEH6bvAQAAAACAuFDo9obtZyQ5YlQJJEIpAAAAAAAQJ9btLght3zuqawwrgUQoBQAAAAAA4kRecWCk1HHNUpiuVwcQSgEAAAAAgLhQ4vFJklx24pC6gF4AAAAAAAAN3hvfbdaVL30nSXLarTGuBhKhFAAAAAAAiAM3vbkitO0ilKoTCKUAAAAAAEBccdmIQ+oCegEAAAAAAMSVRAcjpeoCQikAAAAAANCgffbLzrD9BIctRpWgPEIpAAAAAADQoF3x4ndh+wmsKVUnEEoBAAAAAIAGzTTD95m+VzcQSgEAAAAAgAYtu3Fi2H4CoVSdQCgFAAAAAAAatH0FpWH7TN+rGwilAAAAAABAg7V2V4Hy3d6wNqbv1Q2EUgAAAAAAoEHy+vwa8sjCCu1M36sbCKUAAAAAAECDtOegaXtBTN+rGwilAAAAAABAg7SvsIpQipFSdQKhFAAAAAAAaJC+Xb+30nbWlKobCKUAAAAAAECDNPndn0LbQ45vFtpOsNtiUQ4OQigFAAAAAAAaHK/PH7Z/XFZyaLtJsiPa5aAShFIAAAAAAKDBmfP91tD27KtO0e+7C0P7TVOcsSgJByGUAgAAAAAADc663QWh7R6tGim32BPaNwwjFiXhIIRSAAAAAACgwckrF0IlOW26+cxOykp16eE/9IhhVSiPlb0AAAAAAECD8+q3myVJvbLTJUk9WjfS0tsGx7IkHISRUgAAAAAAoMEa3qXZ4U9CTBBKAQAAAACABsU0TbnsgcjjzC7NY1wNqkIoBQAAAAAAGpSiUp9KPH5JUpMUR4yrQVUIpQAAAAAAQIOyp8AtSUqwW5XoYDntuopQCgAAAAAANCh7CkolSY2TGSVVlxFKAQAAAACABiWnsCyUSiKUqssIpQAAAAAAQIPi8QXWk3LYiD3qMnoHAAAAAAA0KB6/KUmyWYg96jJ6BwAAAAAANCg+f2CklM1qxLgSHAqhFAAAAAAAaFA8vuBIKUKpuoxQCgAAAAAANCi+4PQ9K7FHXUbvAAAAAACABsVbttA5I6XqNkIpAAAAAADQoHgZKVUv0DsAAAAAAKBB8bKmVL1AKAUAAAAAABqU0EgpQqk6jVAKAAAAAAA0KJ7gmlJWQqm6jFAKAAAAAAA0KEWlPklSgt0W40pwKIRSAAAAAACgQSku9UqSEh3WGFeCQyGUAgAAAAAADUpopBShVJ1GKAUAAAAAABqUYk8glGKkVN1GKAUAAAAAABqUEk9goXOXnVCqLotpKPXll1/qnHPOUYsWLWQYhubNmxd2/LLLLpNhGGE/ffr0CTvH7Xbr2muvVZMmTZSUlKRzzz1XW7ZsieKzAAAAAAAAdYnbGxgp5bQxFqcui2nvFBYWqkePHnrssceqPOfMM8/U9u3bQz/vv/9+2PHrr79ec+fO1WuvvaavvvpKBQUFOvvss+Xz+Wq7fAAAAAAAUAe5vYGRUk4bI6XqspheG3HEiBEaMWLEIc9xOp3Kysqq9Fhubq6ee+45vfzyyxoyZIgkadasWWrdurU++eQTDR8+vMZrBgAAAAAAdZu7bE0pl52RUnVZTEOp6vjiiy+UmZmpRo0aqX///rr//vuVmZkpSVq+fLk8Ho+GDRsWOr9Fixbq2rWrFi9eXGUo5Xa75Xa7Q/t5eXmSJI/HI4/HU4vPpnYFa6/PzwFHhr6PX/R9fKLf4xd9H7/o+/hF38cv+v7olJSFUlbDrHevYUPo++rWbpimadZyLdViGIbmzp2rUaNGhdpef/11JScnKzs7W+vXr9edd94pr9er5cuXy+l0avbs2Ro/fnxYwCRJw4YNU7t27fT0009X+liTJ0/WlClTKrTPnj1biYmJNfq8AAAAAABAdN33vVW7Swz9vYtX7VNjXU38KSoq0tixY5Wbm6vU1Ko7oE6PlLroootC2127dtVJJ52k7OxszZ8/X2PGjKnydqZpyjCMKo/feuutmjhxYmg/Ly9PrVu31rBhww75YtV1Ho9HCxYs0NChQ2W322NdDqKIvo9f9H18ot/jF30fv+j7+EXfxy/6/ug8sHqhVOLWwNNPU9eW9et7fkPo++CMtMOp06HUwZo3b67s7Gz99ttvkqSsrCyVlpYqJydH6enpofN27dqlU089tcr7cTqdcjqdFdrtdnu97fDyGsrzQOTo+/hF38cn+j1+0ffxi76PX/R9/KLvj0ypLzApLCnBUW9fv/rc99Wtu16t+LV3715t3rxZzZs3lyT16tVLdrtdCxYsCJ2zfft2rVq16pChFAAAAAAAaJhM09S+wlJJktNWr2KPuBPxSCmfz6eZM2fq008/1a5du+T3+8OOf/bZZ9W+r4KCAq1duza0v379ev3www/KyMhQRkaGJk+erPPPP1/NmzfXhg0bdNttt6lJkyYaPXq0JCktLU1XXHGFbrjhBjVu3FgZGRmaNGmSunXrFroaHwAAAAAAiB+zv90U2nbZrTGsBIcTcSh13XXXaebMmTrrrLPUtWvXQ67ddDjfffedBg4cGNoPrvM0btw4Pfnkk1q5cqVeeukl7d+/X82bN9fAgQP1+uuvKyUlJXSbf/7zn7LZbLrwwgtVXFyswYMHa+bMmbJaeeMBAAAAABBv1u4qCG03Sqyf09/iRcSh1GuvvaY33nhDI0eOPOoHHzBggA518b+PPvrosPfhcrn06KOP6tFHHz3qegAAAAAAQP1WXOqTJP35jGPktDFgpS6LeHKlw+HQscceWxu1AAAAAAAAHLF9haX65OedkqTmaa4YV4PDiTiUuuGGG/Svf/3rkCOcAAAAAAAAou3Oeau0pyCwyDmhVN0X8fS9r776Sp9//rk++OADdenSpcJl/ubMmVNjxQEAAAAAAFTX9txiSVKXFqka2jkrxtXgcCIOpRo1ahS6+h0AAAAAAEBdUeLxS5JuOrOTrJYjvzAboiOiUMrr9WrAgAEaPny4srJIHAEAAAAAQN1R4gkscp5gZ4Hz+iCiNaVsNpv++te/yu1211Y9AAAAAAAARyQYSrnsES+hjRiIuJdOOeUUff/997VRCwAAAAAAwBHLL/FKkhIdEa9WhBiIuJcmTJigG264QVu2bFGvXr2UlJQUdrx79+41VhwAAAAAAEB1FLi9yncHQimuvFc/RBxKXXTRRZKkv//976E2wzBkmqYMw5DP56u56gAAAAAAAA7D4/Pr9Ac/kyTZrYaSnIyUqg8i7qX169fXRh0AAAAAAABH5MfN+5VT5JEkuWwscl5fRBxKZWdn10YdAAAAAAAAR8RmZWHz+ijiUOqll1465PFLL730iIsBAAAAAACIlN1qhLY9fn8MK0EkIg6lrrvuurB9j8ejoqIiORwOJSYmEkoBAAAAAICo8vnN0HaJh1Cqvoh4fFtOTk7YT0FBgdasWaPTTjtNr776am3UCAAAAAAAUCWPzzz8SahzamTSZYcOHTRt2rQKo6gAAAAAAABqm9fH6Kj6qMZWArNardq2bVtN3R0AAAAAAEC1lB8pdUGvVjGsBJGIeE2pd955J2zfNE1t375djz32mPr161djhQEAAAAAAFRH+cXN7xvVNYaVIBIRh1KjRo0K2zcMQ02bNtWgQYP08MMP11RdAAAAAAAA1eLxBkKpnm0ayWW3xrgaVFfEoZSfSysCAAAAAIA6xFt29T27pcZWKUIURNxb99xzj4qKiiq0FxcX65577qmRogAAAAAAAKrLU7bQud1mxLgSRCLiUGrKlCkqKCio0F5UVKQpU6bUSFEAAAAAAADVFVzo3MZIqXol4t4yTVOGUTF5/PHHH5WRkVEjRQEAAAAAAFSXNzhSyspIqfqk2mtKpaenyzAMGYahjh07hgVTPp9PBQUF+stf/lIrRQIAAAAAAFQlNH3Pykip+qTaodSMGTNkmqYuv/xyTZkyRWlpaaFjDodDbdu2Vd++fWulSAAAAAAAgKqEpu8RStUr1Q6lxo0bJ0lq166d+vXrJ5st4gv3AQAAAAAA1LgNewslMX2vvok4Quzfv782btyoO+64QxdffLF27dolSfrwww+1evXqGi8QAAAAAADgUH7cvF+S5LJbY1sIIhJxKLVw4UJ169ZN33zzjebMmRO6Et+KFSt0991313iBAAAAAAAAVfH6/Pp9T2Ck1ICOTWNcDSIRcSh1yy236L777tOCBQvkcDhC7QMHDtSSJUtqtDgAAAAAAIBD2bC3UPklXiU5rBp8fLNYl4MIRBxKrVy5UqNHj67Q3rRpU+3du7dGigIAAAAAAKiOvBKvJCkj2SGrhTWl6pOIQ6lGjRpp+/btFdq///57tWzZskaKAgAAAAAAqI7d+W5Jkq/sCnyoPyIOpcaOHaubb75ZO3bskGEY8vv9+vrrrzVp0iRdeumltVEjAAAAAABApe6b/5MkaVtuSYwrQaQiDqXuv/9+tWnTRi1btlRBQYE6d+6sM844Q6eeeqpuv/322qgRAAAAAACgArfXp837imNdBo6QLdIb2O12vfLKK7rnnnv0/fffy+/3q2fPnurQoUNt1AcAAAAAAFCpD1ftCG2f2KZR7ArBEYk4lApq37692rdvH9qfM2eOJk+erBUrVtRIYQAAAAAAAIeSV+wJbTdKdMSwEhyJiKbv/ec//9Ef/vAHjR07Vt98840k6bPPPlPPnj31pz/9SX379q2VIgEAAAAAAA7m9vpD27eN7BTDSnAkqh1K/d///Z/+9re/af369Xr77bc1aNAgTZ06VRdeeKFGjRqlTZs26emnn67NWgEAAAAAAEI8ZVfcu6BXKx2bmRLjahCpak/fe+655/TUU0/p8ssv1xdffKFBgwbps88+09q1a9WoUaNaLBEAAAAAAKCi0rKRUg5bxNdxQx1Q7VBq48aNGjJkiCRpwIABstvtuv/++wmkAAAAAABAVL25fIv2F5Wq1OeTJDmshFL1UbVDqZKSErlcrtC+w+FQ06ZNa6UoAAAAAACAyri9Pk3674+SpDO7ZEmSnIyUqpciuvres88+q+TkZEmS1+vVzJkz1aRJk7Bz/v73v9dcdQAAAAAAAOXsyC0JbS/flCNJSnFFFG+gjqh2r7Vp00b/+c9/QvtZWVl6+eWXw84xDINQCgAAAAAA1JoCtze0vTvfLUnKTHVVdTrqsGqHUhs2bKjFMgAAAAAAAA4vuLh5ee2aJMWgEhwtJl0CAAAAAIB6o7JQ6timyTGoBEeLUAoAAAAAANQbpb6KoVR6kiMGleBoEUoBAAAAAIB6o7KRUqifCKUAAAAAAECd5T1oZBShVMNBKAUAAAAAAOqcZ75cp7a3zNep0z7TLzvyQu25xZ7QtsNm0czxvWNRHmrAEYVS69at0x133KGLL75Yu3btkiR9+OGHWr16dY0WBwAAAAAA4s/OvBJNff8XSdKufLfOnLFIve5doJ+35+ndFdskSX/s3Vo/TRmuAcdlxrJUHIWIQ6mFCxeqW7du+uabbzRnzhwVFBRIklasWKG77767xgsEAAAAAADx5b0V2yu07S0s1Yh/LdLXa/dKks7v1Uo2KxPA6rOIe++WW27RfffdpwULFsjhOLC6/cCBA7VkyZIaLQ4AAAAAAMSfe9/76bDn9G6bEYVKUJsiDqVWrlyp0aNHV2hv2rSp9u7dWyNFAQAAAACA+HVim0axLgFREHEo1ahRI23fXnEY3ffff6+WLVvWSFEAAAAAACA+maapTfuKD3lOs1RnlKpBbYo4lBo7dqxuvvlm7dixQ4ZhyO/36+uvv9akSZN06aWX1kaNAAAAAAAgTqzdVaA9BW45bRa9//fT9djYnrp+SIewc+b//fQYVYeaFHEodf/996tNmzZq2bKlCgoK1LlzZ51xxhk69dRTdccdd9RGjQAAAAAAIE78vCNfktStZZo6t0jV2d1b6PohHUPH2zdNUpNkRko1BLZIb2C32/XKK6/onnvu0ffffy+/36+ePXuqQ4cOh78xAAAAAADAIfz3u82SpMyDpui9elUfPbJgje45r2ssykItiDiUWrhwofr376/27durffv2tVETAAAAAACIQzmFpVr02x5JktNmDTvWt31j/bf9qbEoC7Uk4ul7Q4cOVZs2bXTLLbdo1apVtVETAAAAAACIQ9+s3xvatluNGFaCaIg4lNq2bZtuuukmLVq0SN27d1f37t01ffp0bdmypTbqAwAAAAAAceKHzbmh7QS79RBnoiGIOJRq0qSJrrnmGn399ddat26dLrroIr300ktq27atBg0aVBs1AgAAAACABi6vxKMv1uwK7bschFINXcShVHnt2rXTLbfcomnTpqlbt25auHBhTdUFAAAAAADiyN9e+Z9+KbvyniSluuwxrAbRcMSh1Ndff60JEyaoefPmGjt2rLp06aL33nuvJmsDAAAAAABxIrjAedCfTsmOUSWIloivvnfbbbfp1Vdf1bZt2zRkyBDNmDFDo0aNUmJiYm3UBwAAAAAA4szjY09UWiIjpRq6iEOpL774QpMmTdJFF12kJk2a1EZNAAAAAAAgjiU5WU8qHkQcSi1evLg26gAAAAAAAHHMMCTTDGynuCKOK1APVauX33nnHY0YMUJ2u13vvPPOIc8999xza6QwAAAAAAAQP1w2q4o9PklSZoorxtUgGqoVSo0aNUo7duxQZmamRo0aVeV5hmHI5/PVVG0AAAAAACBOpLhsKvb41CkrRa3SE2JdDqKgWqGU3++vdBsAAAAAAKAmuL2BvOHfF/eUYRgxrgbRYIn0Bi+99JLcbneF9tLSUr300ks1UhQAAAAAAGj4TNPUtv3F2p3vVm6xRxZDap7G1L14EXEoNX78eOXm5lZoz8/P1/jx42ukKAAAAAAA0PC9tGSjTp32mR7+eI0kKcVlV4rLHuOqEC0Rh1KmaVY6jG7Lli1KS0urkaIAAAAAAEDDd/c7qyVJry3bLElKdnLVvXhS7d7u2TMwp9MwDA0ePFg224Gb+nw+rV+/XmeeeWatFAkAAAAAABq+JKc11iUgiqodSgWvuvfDDz9o+PDhSk5ODh1zOBxq27atzj///BovEAAAAAAA1H9L1u1VuyZJykpz6fHP16pVeoIcNotKvQcuqNYqPTGGFSLaqh1K3X333ZKktm3b6qKLLpLLxcJjAAAAAADg8JZv3KeL/7NUiQ6rXvtzHz300ZpKz+vakmWB4knEkzXHjRtXG3UAAAAAAIAGatmGHElSUalPW3KKqzyva4vUaJWEOiDihc59Pp/+7//+TyeffLKysrKUkZER9gMAAAAAAFBegv3AWlGrt+WGHevR6sDoKEZKxZeIQ6kpU6bokUce0YUXXqjc3FxNnDhRY8aMkcVi0eTJk2uhRAAAAAAAUJ/tLSwNbT/++bqwY09fclJou3kaSwXFk4in773yyiv6z3/+o7POOktTpkzRxRdfrPbt26t79+5aunSp/v73v9dGnQAAAAAAoJ7aU+CutH3i0I7KSnPpo+vPUGqCTYZhRLkyxFLEI6V27Nihbt26SZKSk5OVmxsYdnf22Wdr/vz5NVsdAAAAAACo9ypbR+qZS3rp74M7SJKOy0pR87SEaJeFGIs4lGrVqpW2b98uSTr22GP18ccfS5KWLVsmp9NZs9UBAAAAAIB6b8OewrD9FmkuDeyUGaNqUFdEHEqNHj1an376qSTpuuuu05133qkOHTro0ksv1eWXX17jBQIAAAAAgPprd75bm3OKwtrevfY02a0RRxJoYCJeU2ratGmh7QsuuECtWrXS4sWLdeyxx+rcc8+t0eIAAAAAAED99vFPO2Sa4W2Nk5lphSMIpQ7Wp08f9enTpyZqAQAAAAAADczCNbslSX8+4xi9/cNWDejItD0EVCuUeuedd6p9h4yWAgAAAAAAQZv2Babu9W3fWLec2UkWC1fYQ0C1QqlRo0ZV684Mw5DP5zuaegAAAAAAQAPh85v6ZUe+JKl1eiKBFMJUK5Ty+/21XQcAAAAAAGhgbvzvj6HtVukJMawEdRFL3QMAAAAAgFrxw+b9oW2X3Rq7QlAnRbzQ+T333HPI43fdddcRFwMAAAAAAOo30zS1r7BUjZOdSnAEgqgHxnSLcVWoiyIOpebOnRu27/F4tH79etlsNrVv355QCgAAAACAOPbvT9fqn5/8qmcu6aW8Eo8kqWOzlBhXhboo4lDq+++/r9CWl5enyy67TKNHj66RogAAAAAAQP3g9vpkyJDDZtGnP+/UPz/5VZJ081sr5DcD56QlRBw/IA7UyJpSqampuueee3TnnXdGdLsvv/xS55xzjlq0aCHDMDRv3ryw46ZpavLkyWrRooUSEhI0YMAArV69Ouwct9uta6+9Vk2aNFFSUpLOPfdcbdmy5WifEgAAAAAAOIzcIo/6TftMHe/4QF+v3aMrXvwudCy/xKv8spFSqS57rEpEHVZjC53v379fubm5Ed2msLBQPXr00GOPPVbp8enTp+uRRx7RY489pmXLlikrK0tDhw5Vfn5+6Jzrr79ec+fO1WuvvaavvvpKBQUFOvvss+Xz+Y7q+QAAAAAAgENbtmGf9hSUSpL+37PfhB2zWgz5TcliSKkJhFKoKOLxc//+97/D9k3T1Pbt2/Xyyy/rzDPPjOi+RowYoREjRlR6zDRNzZgxQ7fffrvGjBkjSXrxxRfVrFkzzZ49W1dffbVyc3P13HPP6eWXX9aQIUMkSbNmzVLr1q31ySefaPjw4ZE+PQAAAAAAUA3bc4t169yVVR53e/2SpA6ZKVx5D5WKOJT65z//GbZvsVjUtGlTjRs3TrfeemuNFbZ+/Xrt2LFDw4YNC7U5nU71799fixcv1tVXX63ly5fL4/GEndOiRQt17dpVixcvrjKUcrvdcrvdof28vDxJgUXbPR5PjT2HaAvWXp+fA44MfR+/6Pv4RL/HL/o+ftH38Yu+j191ve+35BRr4COLKj12ySmt9fI3m0P7p3doXGefR11U1/u+Oqpbe8Sh1Pr16yMu5kjs2LFDktSsWbOw9mbNmmnjxo2hcxwOh9LT0yucE7x9ZR544AFNmTKlQvvHH3+sxMTEoy095hYsWBDrEhAj9H38ou/jE/0ev+j7+EXfxy/6Pn7V1b5/43eLyq8I1DXdr1U5gf1mRetVPm441r1W77+/NsoV1n91te+ro6ioqFrn1fnl7w3DCNs3TbNC28EOd86tt96qiRMnhvbz8vLUunVrDRs2TKmpqUdXcAx5PB4tWLBAQ4cOld3OfN14Qt/HL/o+PtHv8Yu+j1/0ffyi7+NXXe17n9/U+6t2qGTrZkn7Q+3n9jlez3TL0r7CUh2XlaL8Rr/p6UXrNaBjE51/7okxq7c+qqt9H4ngjLTDiTiUKikp0aOPPqrPP/9cu3btkt/vDzv+v//9L9K7rFRWVpakwGio5s2bh9p37doVGj2VlZWl0tJS5eTkhI2W2rVrl0499dQq79vpdMrpdFZot9vt9bbDy2sozwORo+/jF30fn+j3+EXfxy/6Pn7R9/GrLvW9aZrqdteHKvH4Kxw7oU2GWmQkq0VGYP+mEcerZ3a6+rZvUmfqr2/qUt9Hqrp1RxxKXX755VqwYIEuuOACnXzyyYcdtXSk2rVrp6ysLC1YsEA9e/aUJJWWlmrhwoV68MEHJUm9evWS3W7XggULdOGFF0qStm/frlWrVmn69Om1UhcAAAAAAPGo2OOrNJCSpJOyw5fVsVoMndm1eaXnAkERh1Lz58/X+++/r379+h31gxcUFGjt2gPzStevX68ffvhBGRkZatOmja6//npNnTpVHTp0UIcOHTR16lQlJiZq7NixkqS0tDRdccUVuuGGG9S4cWNlZGRo0qRJ6tatW+hqfAAAAAAA4Oh5vGal7dPP7y6LpXYGrKBhiziUatmypVJSUmrkwb/77jsNHDgwtB9c52ncuHGaOXOmbrrpJhUXF2vChAnKycnRKaecoo8//jjs8f/5z3/KZrPpwgsvVHFxsQYPHqyZM2fKauVykwAAAAAA1BS311eh7dMb+qt90+QYVIOGIOJQ6uGHH9bNN9+sp556StnZ2Uf14AMGDJBpVp60SoFFzidPnqzJkydXeY7L5dKjjz6qRx999KhqAQAAAAAAVcsr8VZoy86o/1ewR+xEHEqddNJJKikp0THHHKPExMQKi1ft27evxooDAAAAAAB1wxNfrA3bv/K0drJZLTGqBg1BxKHUxRdfrK1bt2rq1Klq1qxZrS10DgAAAAAA6o7Fa/eGtt/+Wz91b5UWw2rQEEQcSi1evFhLlixRjx49aqMeAAAAAABQBw3pnKlZSzdJknq0bhTbYtAgRDzOrlOnTiouLq6NWgAAAAAAQB2VWxxYU+q2kZ1iXAkaiohDqWnTpumGG27QF198ob179yovLy/sBwAAAAAANDyb9hVJktpkJMW4EjQUEU/fO/PMMyVJgwcPDms3TVOGYcjnq3iJSAAAAAAAUH/tznfrx837JUltuOIeakjEodTnn39eG3UAAAAAAIA6asBDB7KANo0JpVAzIg6l+vfvXxt1AAAAAACAOmhnXokKSw/Mikp2RhwlAJWK+J305ZdfHvL4GWecccTFAAAAAACAumXlltxYl4AGKuJQasCAARXaDMMIbbOmFAAAAAAADcf+Yk9o++KTW8ewEjQ0EV99LycnJ+xn165d+vDDD9W7d299/PHHtVEjAAAAAACIgc37ivTwx2skSV1bpuqe87rGuCI0JBGPlEpLS6vQNnToUDmdTv3jH//Q8uXLa6QwAAAAAAAQOzmFpfrjM0u1PbdEknRGh6ayWyMe2wJUqcZWJ2vatKnWrFlTU3cHAAAAAABipKjUq573Lghr69kmPUbVoKGKOJRasWJF2L5pmtq+fbumTZumHj161FhhAAAAAAAgNlZtzavQ1q5JUgwqQUMWcSh1wgknyDAMmaYZ1t6nTx89//zzNVYYAAAAAACIjUK3N2w/I8lBKIUaF3EotX79+rB9i8Wipk2byuVy1VhRAAAAAAAgdvJKPGH7r/25j6wWI0bVoKGKOJTKzs6ujToAAAAAAEAdsGTdXl332g9hbakue2yKQYNW7WXzP/vsM3Xu3Fl5eRXnlebm5qpLly5atGhRjRYHAAAAAACi6+L/LA3bd1gtapzsiFE1aMiqHUrNmDFDV111lVJTUyscS0tL09VXX61HHnmkRosDAAAAAACxM+qEFlp2xxDZrdWOD4Bqq/a76scff9SZZ55Z5fFhw4Zp+fLlNVIUAAAAAACIPq/PH7b/z4tOUFoCU/dQO6odSu3cuVN2e9VvRJvNpt27d9dIUQAAAAAAIPrKryW15r4zZRgsbo7aU+2Fzlu2bKmVK1fq2GOPrfT4ihUr1Lx58xorDAAAAAAA1L4PV+3Qpz/vVNsmSZq/cnuo3WmzxrAqxINqh1IjR47UXXfdpREjRsjlcoUdKy4u1t13362zzz67xgsEAAAAAAC1Y19hqf4yq+JSPCO6ZsWgGsSbaodSd9xxh+bMmaOOHTvqmmuu0XHHHSfDMPTzzz/r8ccfl8/n0+23316btQIAAAAAgBr08/a8Cm3ZjRP1t4GVz5ICalK1Q6lmzZpp8eLF+utf/6pbb71VpmlKkgzD0PDhw/XEE0+oWbNmtVYoAAAAAACoWb/vKQzb/2LSALVtkhSjahBvqh1KSVJ2drbef/995eTkaO3atTJNUx06dFB6enpt1QcAAAAAAGrJ77sLQtudm6cqu3FiDKtBvIkolApKT09X7969a7oWAAAAAAAQRb/vDoyUmnJuF/2pTzZX20NUWWJdAAAAAAAAiI31ZdP3OmWlyGohkEJ0EUoBAAAAABCHfH5TW3KKJIl1pBAThFIAAAAAAMSh/BKP/IFrmCk90RHbYhCXCKUAAAAAAIhD+SVeSVKC3SqHjXgA0ce7DgAAAACAOJRb7JEkpSYc0TXQgKNGKAUAAAAAQBzKKykLpVz2GFeCeEUoBQAAAABAHMorDkzfS00glEJsEEoBAAAAABCHdhe4JbHIOWKHUAoAAAAAgDj03YZ9kqRW6QkxrgTxilAKAAAAAIA48+36fXr7h22SpOFdsmJcDeIVoRQAAAAAAHHmp225kqSBxzVV3/aNY1wN4hWhFAAAAAAAcSa/JLDIebNUV4wrQTwjlAIAAAAAIM7kuwOhVLLTFuNKEM8IpQAAAAAAiDPBkVIpLnuMK0E8I5QCAAAAACDO5Jd4JEnJLkZKIXYIpQAAAAAAiCOmaeq9FdslSSmEUoghQikAAAAAAOLIwl93h7a7tUyLYSWId4RSAAAAAADEkV925EuShndppuObp8a4GsQzQikAAAAAAOJIYdmV97JSXTGuBPGOUAoAAAAAgDhSUBZKJTlZTwqxRSgFAAAAAEAc2VtQKklKTbDHuBLEO0IpAAAAAADiyMqtuZLEelKIOUIpAAAAAADiRG6RR+v3FEqSunPlPcQYoRQAAAAAAHFixdb9kqTsxolKT3LEthjEPUIpAAAAAADixIotgal73Vs1im0hgAilAAAAAACIGz9ty5MkdWvJelKIPUIpAAAAAADixOacIklS28ZJMa4EIJQCAAAAACBu7Ml3S5KapbpiXAkg2WJdAAAAAAAAqF2maWrTviLtLSyVJGWwyDnqAEIpAAAAAAAauGkf/KKnv/w9tM+V91AXMH0PAAAAAIAG7JOfdoYFUpKU5LDGqBrgAEIpAAAAAAAaqFVbc3XlS9+FtfVumy7DMGJUEXAA0/cAAAAAAGigrn55eWj7xuHH6cKTWivJySgp1A2EUgAAAAAANECrtuZq6/7i0P4fe7dW42RnDCsCwjF9DwAAAACABqbU69dFTy8J7X9722ACKdQ5hFIAAAAAADQw81duU2GpTw6bRV/fMkiZqa5YlwRUQCgFAAAAAEADYpqmHvpwjSSpUYJdLRslxLgioHKEUgAAAAAANCDv/LhN23JLJEm3jOgU42qAqhFKAQAAAADQgPzj9R9C29mNk2JXCHAYhFIAAAAAADQgfvPA9vHNU2JXCHAYhFIAAAAAADQgaQl2SdKD53dTosMW42qAqhFKAQAAAADQQJimqbwSjyRpYKfMGFcDHBqhFAAAAAAADUResVdm2fS9ZCejpFC38Q4FAAAAAKAee3HxBqUm2DSsc5b+u3xzqD3Bbo1hVcDhEUoBAAAAAFBPbdhTqLvfWV2292PYMcMwol8QEAGm7wEAAAAAUE/9vD2v0vY/9GoV5UqAyBFKAQAAAABQT/2yI7/S9itObxflSoDIEUoBAAAAAFBPrakklHrqTyeqU1ZqDKoBIsOaUgAAAAAA1FNrdoaHUjPH99aA4zJjVA0QGUIpAAAAAADqIdM0tXFvoSSpZ5tG6pSVSiCFeoVQCgAAAACAeqiw1Ce/GdiefWUfJTissS0IiBBrSgEAAAAAUA8VlHglSTaLIZedr/eof3jXAgAAAABQD+3KL5EkNUp0yDCMGFcDRI5QCgAAAACAeuinbXmSpE5ZKTGuBDgyhFIAAAAAANRhu/JL9K9PftP+otKw9p+2B0Kpzi1SY1EWcNRY6BwAAAAAgDrKNE2dfP+nkqR/fvKrTm3fWLOuOEUWi6HVZSOluhBKoZ5ipBQAAAAAAHXQlkLpkU/WhrUtXrdXt89bKdM09XNwpFRzQinUT4yUAgAAAACgjil0e/XQCpuk9RWOvfrtZh3TJFlFpT5JUqv0xChXB9QMQikAAAAAAOqIxz9fq017i2Q7aF7TJX2y1a1Vmm56c4Uk6f73fw4dc9mZBIX6iVAKAAAAAIA6wDRNPfTRmkqPXXl6O2U3TgqFUuUZhlHbpQG1gjgVAAAAAIA6IK/YW2n7Ped1UXbjJEnSN7cNjmZJQK2q06HU5MmTZRhG2E9WVlbouGmamjx5slq0aKGEhAQNGDBAq1evjmHFAAAAAAAcma37i8P22ySZ+t/tg3RJn+xQW7NUl164rLd6tG6kQZ0yNXN872iXCdSYOj99r0uXLvrkk09C+1arNbQ9ffp0PfLII5o5c6Y6duyo++67T0OHDtWaNWuUkpISi3IBAAAAAIjYy0s26M63DwyyeHn8Sdrz81KluGwVpucN7JSpgZ0yo10iUOPq9EgpSbLZbMrKygr9NG3aVFJglNSMGTN0++23a8yYMeratatefPFFFRUVafbs2TGuGgAAAACA6isfSElSn2MyZGGpKDRwdT6U+u2339SiRQu1a9dOf/zjH/X7779LktavX68dO3Zo2LBhoXOdTqf69++vxYsXx6pcAAAAAACq7Y3vNuuyF74Na5sz4dQYVQNEV52evnfKKafopZdeUseOHbVz507dd999OvXUU7V69Wrt2LFDktSsWbOw2zRr1kwbN2485P263W653e7Qfl5eniTJ4/HI4/HU8LOInmDt9fk54MjQ9/GLvo9P9Hv8ou/jF30fv+j7hi2/xFPhanoPjO6ibs2T6fs41hD6vrq1G6ZpmrVcS40pLCxU+/btddNNN6lPnz7q16+ftm3bpubNm4fOueqqq7R582Z9+OGHVd7P5MmTNWXKlArts2fPVmJiYq3UDgAAAABAedsKpQdXHBgrckyKqeu6+mJYEVAzioqKNHbsWOXm5io1NbXK8+r0SKmDJSUlqVu3bvrtt980atQoSdKOHTvCQqldu3ZVGD11sFtvvVUTJ04M7efl5al169YaNmzYIV+sus7j8WjBggUaOnSo7HZ7rMtBFNH38Yu+j0/0e/yi7+MXfR+/6PuGYe2uAtmtFmU3Dh8E8e2GfdKK70L7mU0yNHJk4Gp69H38agh9H5yRdjj1KpRyu936+eefdfrpp6tdu3bKysrSggUL1LNnT0lSaWmpFi5cqAcffPCQ9+N0OuV0Oiu02+32etvh5TWU54HI0ffxi76PT/R7/KLv4xd9H7/o+/prT4FbIx5dLMOQfrtvhGzWA0s7r99bEtrOSHLo3lHdKvQzfR+/6nPfV7fuOr3Q+aRJk7Rw4UKtX79e33zzjS644ALl5eVp3LhxMgxD119/vaZOnaq5c+dq1apVuuyyy5SYmKixY8fGunQAAAAAQJzbkVuiM2d8KUkyTWnCK//T2z9sLds3dce8VZKk20cer//dOVQdmqXErFYgFur0SKktW7bo4osv1p49e9S0aVP16dNHS5cuVXZ2tiTppptuUnFxsSZMmKCcnBydcsop+vjjj5WSwgcZAAAAABBbj33+m/YUlIb2P/5pp778bbfOO6Glvl2/L9Te/7imsSgPiLk6HUq99tprhzxuGIYmT56syZMnR6cgAAAAAACqYe2ufM1auqlCe4nHr6cXrtMDH/wSaju2aXI0SwPqjDo9fQ8AAAAAgPpm2/5iDXnky9D+5f3aqXurtNB++UDq+iEdZLEYUa0PqCsIpQAAAAAAqCGFbq/O+vei0P5pxzbRXed01tt/66e0hIqLP489uU00ywPqFEIpAAAAAABqyKqtucop8oT2p53fTVJg+ZkmyY6wc+8f3VWZqa6o1gfUJYRSAAAAAADUkJVbc0Pbr1x5ilqlJ4b2m6clhLanju6m/3dKdlRrA+oaQikAAAAAAGrIii2BUGrSsI7qd2yTsGMntml0YDu7kYB4V6evvgcAAAAAQH3w/srtuufdn7Qjr0SS1L1VowrnDOiUqbf+t1XnntBCnbJSo1whUPcQSgEAAAAAcBS27S/WhFf+F9bWrWVahfNObJOur28ZFK2ygDqP6XsAAAAAAByF91duD9vv2jJV6UmOKs4GEEQoBQAAAADAUVhVbnFzSfpDr9YxqgSoXwilAAAAAAA4Chv2FoW2O2Qm6/xerWJYDVB/sKYUAAAAAABHqNDt1S878iRJH//jDHXITJZhGDGuCqgfGCkFAAAAAMARenP5FpV4/MpunEggBUSIUAoAAAAAgCPg8fl19zurJUmpLjuBFBAhQikAAAAAAI7AgIe+CG33bd84doUA9RShFAAAAAAAEcov8Wjr/uLQ/t8Hd4hhNUD9RCgFAAAAAECEVm3NC21fdXo7JTu5jhgQKUIpAAAAAAAi9MWaXaHtScOPi2ElQP1FKAUAAAAAQIQW/bZHkvTvi3vKabPGuBqgfiKUAgAAAAAgAj6/qQ17CyVJXVukxrgaoP4ilAIAAAAAIAIrt+aqqNSnVJdNrTMSY10OUG8RSgEAAAAAEIHvN+VIkrq3aiS7la/VwJHi0wMAAAAAQDXtzCvRlHd/kiR1ykqJcTVA/UYoBQAAAABANb327ebQdr9jm8SwEqD+I5QCAAAAAKCa8ks8oe0+xzSOYSVA/UcoBQAAAABANZimqc/X7JIk3XTmcUpwWGNcEVC/EUoBAAAAAFANP2/P17rdhXLaLLqkT3asywHqPUIpAAAAAAAOY39RqR744GdJ0klt05Xisse4IqD+s8W6AAAAAAAA6rLXl23SzW+tDO23a5IUw2qAhoORUgAAAAAAHMJb/9satt8rOz1GlQANCyOlAAAAAAA4hD35bklSeqJdr1/dVx0yk2NcEdAwEEoBAAAAAOLSzK/X67Vlm3VcVopuGHqc2jROrPS83QWBUOq/f+mrYzNTolki0KARSgEAAAAA4tJDH61RYalPv+zI17fr92nJrYMrnFPi8Sm/xCtJapriinaJQIPGmlIAAAAAgLizbneBCkt9of3tuSX6fXdBpedJktViKNXFuA6gJhFKAQAAAADizpR3f5IkZaUeGP300eqdFc575svfJUntmybJMIzoFAfECUIpAAAAAECD8tTCdWp7y3w9+OEvFY7lFnk0/cNf9OWvuyVJT/7pRF3d/xhJ0vNfr9eO3JLQuT6/qU9+CgRVY09uE4XKgfhCKAUAAAAAqNf8flPvrdimdbsL9PTCdZr2QSCMevKLdTJNM3Te/320Rj3u+VhPfLEu1NYmI1Gje7aUJO3Od6vPA5/qtW83SZIW/bZbhaU+pbhsuqRv2+g9ISBOEEoBAAAAAOq1+Su365rZ32vwwwv1wAfho6OG/vNLSdJvO/P12Odrw46NPaWNGic71SkrVdcMPDbUfsucldqVX6LLXlgmSerZJl1WC1P3gJrGKm0AAAAAgHptwU8V14IKWrurQG1vmV+h/dYRnfTnM44J7U8afpxapifo1jkrJUkn3/9p6Ngp7TJqsFoAQYyUAgAAAADUWev3FIbWfypvT4Fbs5Zu1O58t975cVvYsT/0aqVFNw2s9P76HdtYb/6lr67u377CwuUXn9xGLRslVLjNJX2zj+IZAKgKI6UAAAAAAHXSrKUbdce8VZKkt/7aV02Snfp/z36j7bkl8vkDa0UFjwddN7iD/jG0oyTpjav76sKnl4Qdv+K0djqpbdUjn+ZOOFUnTw2Mkrp3VFf96ZQ2XHUPqCWEUgAAAACAOmd3vjsscDr/ySWHOFvq1jJN7157Wljbye0y9NXNA/XUwnWatXSTkp029Wydfsj7yUx16fepI1Xq88tltx75EwBwWIRSAAAAAIA65/tNOYc8/tjYnrpm9veh/ZPaVh42tUpP1H2juumK046RISk9yXHYx7ZYDLksBFJAbSOUAgAAAADUCet2F+jG//6o/23aH2ob3ClTHZql6KmF6yRJ3Vulac5fT5XNagkLpQYcl3nI+27XJKlWagZw5AilAAAAAAB1wsyvN4QFUpJ068hOOjYzRTefeZx+3JKr7IxE2ayBa3Z9f+dQ3fjmjxreJUv9OzaNQcUAjgahFAAAAACgTlixZX/Y/vVDOujYzBRJkmEYOqF1o7Dj6UkOPTuud5SqA1DTCKUAAAAAADH3x2eW6MctuZKkLyYNUFum2wENniXWBQAAAAAA4tuzi37X0t/3hfbbZCTGsBoA0UIoBQAAAACImU9+2qn75v8c2l89ZbgsFiOGFQGIFkIpAAAAAEBMbM8t1pUvfRfav3H4cUpyssoMEC8IpQAAAAAAUbd47R71feCz0P4JrRvpbwOPjWFFAKKNCBoAAAAAUOvW7ynUwP/7Qq0zEjTouEy9uGRj6NiD53fT2d1bxLA6ALFAKAUAAAAAqHE+v6mv1+7RvB+2avHavdqRVyJJ2ryvOCyQ+uuA9rqod5tYlQkghgilAAAAAAA1au2ufA155MvDnvfj3cOUlmCPQkUA6iJCKQAAAABAjSlwe6sMpN76a1+9/cM2fbchR3ed05lACohzhFIAAAAAgBqzZkd+2P5J2ekac2Irtc5IUK/sDPXKzohRZQDqGkIpAAAAAECN2bq/OLR95WntdN2QDkpxMSIKQEWEUgAAAACAo+L2+vT5L7uUlZagv7/6vSRpdM+WuuPszjGuDEBdRigFAAAAADgq0z9co+e+Wh/W1r9j0xhVA6C+sMS6AAAAAABA/XXvez9VCKQk6bwTWsSgGgD1CaEUAAAAAOCIlHh8ennpxgrt7117mgzDiEFFAOoTpu8BAAAAAI7IW//bolKvX5L08z1nKsFhjXFFAOoTRkoBAAAAACK29Pe9un3uKknSVae3I5ACEDFGSgEAAAAAquXDVdu18NfdevXbzaG2E1o30j+GdoxhVQDqK0IpAAAAAECVduWVaMWWXC39fa+erWRB8wfP765EB18tAUSO3xwAAAAAgJAtOUV67LO1em3Z5kOe9/9OaaN7zusqq4UFzQEcGUIpAAAAAIByizy66qXv9O2GfRWOGYZ02rFNNKhTprq0SFPHZslqlOiIQZUAGhJCKQAAAACIU7/vLtDryzbLYjE0939btSOvpMI5D/+hh8ac2FKGwYgoADWLUAoAAAAA4tCeArdGP7FYucWesPZuLdP0/GW9leKyyWXninoAag+hFAAAAADEGa/Prxve+DEskDopO11Tx3RTx2YpMawMQDwhlAIAAACAOFHg9uqDldt145srJEkuu0X/vfpUZaW51CTZwRQ9AFFFKAUAAAAADcCi33ZrV55bQzo3U1qCPdT+3optevDDX5Rgt+rXnQVht/n3H3uqW6u0aJcKAJIIpQAAAACg3jBNU0vW7dXsbzfprG7NNaJbc725fIsm/ffH0DnN01zq0iJVX6/dq2KPr9L7OaNjU103uIN6ZadHq3QAqIBQCgAAAABiZEduiT79ZaeKS326b/7PYce+vHGgmqceGPG0JadIo59YrN35bknSeyu2V3qf23NLtD234lX0Lu2brY7NUjT4+Ew1T0uowWcBAEeGUAoAAAAAoujXnfl68ot1+mlbntbuLpDPb1Z63mUvfKsUl00nJBhKW7dXk95cpT0F7irv9//+0EPHNE3SpDd+1Nb9xWqTkaiLT26jE7PT1aNVGutFAahzCKUAAAAA1GsfrNyuVumJdWptJNM09eq3m/Xj5v3aX1yq7bkl2ryvSDlFnsPfuMzvewolST/Kqhd/Wx5qv+e8Lhp7chs9s+h3bckp1sW924Q9909v6E8ABaBeIJQCAAAAUG998tNO/fWV/0mSpo7upiGdM/XN7/tUXOrT2T2aK9FR+195TNNUbrFHaQl2GYahb9fv011vr9IvO/IPeTubxdC1gzpo/GlttTWnWJ2yUmQYhnx+U2c/+pV+3p4nScpwmkpJSlK7pkmaNOw4dW0ZCKAmDDi20vslkAJQXxBKAQAAAKg33F6fJr7xo+ZXsp7SbXNX6ra5B/ZvemuFbhnRSZed2lYuuzXixyrx+LR2V4FsVkNL1+1VktMmt9ev1dvyVOLxadmGfdqSU6zGSQ7tLSyVw2aRIcnt9Yfuo0myQ+f2aKnvN+do7a4CnX9iKw3vkqWT2qbLbrWEzkttfmDtKKvF0PxrT9OWnGJlpdj0wQcfaOTI02S32wUADQmhFAAAAICYyCvx6OPVO9WlRaqap7lCI40Oll/iUVGpT3arRZfPXKYfNu8PO+6wWmS1GJVeaW7aB7/oua/W68+nH6OdeSVKS7DrqjOOkddval9Bqb7buE9WiyG71aJmqU7ZrRa98d1mrdiSqzU78sMCpqrsLSyVJJWWO3fI8ZmaNPw4dcpKjfBVCbBYDLVpnCiPp/rT/QCgviGUAgAAABBV//1usx5Z8KtyiwNhU1DzNJcu7dtWVov0+S+7tXFvoaxWQ5v3FVe4j8ZJDp3RsalGdM3S6R2aKsFhlc9v6ufteeqUlaKd+W6d/e9FyinyaHe+W/e/f+DKdv/69Df5TFNm5euLV2AYUvumyUpLsCvFZZPFMNQmI1Euu1V7C9wa2b25emWna0++WzvyStS2cZJaNOLqdgBwOIRSAAAAAGqM32/KYjkw2sk0Ta3amqdnv/pda3bka9O+orAgqrztuSV68MNfDnn/jZMcuue8rjqre/MKx6wWI7TeUstGCfr+rmHaW+DWo5+t1RvfbQ49rvegq931yk7XvsJS7cwrUVGpT72y03Vp32w1TnKqW6s0+f2m0pMch33uqS67jmmafNjzAAABhFIAAAAAIlbo9spltyq32KOFv+7SByt3qLDUqx8358pqMeTx+WWaqnRKXdC953XRmBNbSQqsw/Teim167dvN2ri3UIlOm45tmqz0JLuGHN9M2Y0T1a5JslJdNtnKrcV0OI2TnZp8bhfddXZnWSyGcgpL9f3mHHXITJHVYqh5mis0ZdDvN1VQ6lWqi7WbACAaCKUAAAAAVJtpmnpq4e+a/tEv1Z7+ZjGkjs1S5LBZ1LFZik7v0ERndWseFi4lOaVL+7bVpX3b1krdwdFb6UkODerUrMpzCKQAIHoIpQAAAABUye839dqyzbpt7srDnnvV6e2UlmDXut2F8vpNtWjkUq826eqVna7Gyc4oVAsAqE8IpQAAAABoS06R9hd5tLvArUK3VztyS/Tt+n36+KedlZ7/h16tdFHv1urQLEVpCYwuAgBEjlAKAAAAqOd8flO5xR59vylHGUkOtUpP1J4Ct9o1SZLLbg2d5/H5lVNYqt0Fbn24aoe25hTL4ze1cst+bdhbVOX9O6wW9W6Xrt5tMzSoU6bSEx1qnZEYjacGAGjACKUAAACAOii/xCPDMJTstMlf7mpx2/YXa8m6vVq7u0CJdqt25pdo7v+2qrCKK9pZLYaaJDtkNQztzHfL5698ISibxVCKy6astASlumxKS7Crc4tUNUt1aVCnTDVLddXK8wQAxC9CKQAAAKCGmGUrfxeW+pRb7NH+olI5bVZJpopL/TIMyWIYKvH65PH6leCwKj3RoRKPT7/uLNDyjTn6ZUeecoo8+nVnvnx+Uw6rRaU+v5xWq+78/jPllXgjqsnnN7Uzzx3W5rBalJXmUnqSQ63TEzTwuEwN75qlZCdfDwAA0cN/dQAAAFBn7C8qlWEYslkMmQpctc1iBK6a5vWbKvX6ZUgyDKnU69e+olIVl/pU4vGr1OdXstOmRIdVdmvgNltyilXg9iq/xCu/aapJslOJDqtcdqsshrQ7v1S780tks1qUV+xRYalPGYn20PS3bbklyiv2yGoxtH5PoSyG1D4zWakuu1x2q3KLSrV8U45+312oQrdXRaU+easYiXSkSn1+SZLbZ8jt88piSN1bNQpNn0t22tTv2MY6uW2GGic75fH5VeIJ1LF6W55257vl95tq0zhR7ZokqUnZguPWsqvRAQAQK4RSAAAAMeTx+VXk9slnmnJ7ffL5TRW6fSr1+lXs8amo1KtCt08pLpushl9rc6Vv1u+TxWqVyrIPU4GQJtVlD03NMsqFOSUen/63KUfFpX6V+nzKSnXJ5zfl9Zvy+Ex5fX55/IH/DbT5tSvfLUNSeqJD6UkO5RaVKqfIo/1lo3/2F3lktxpKTbAr2WnT/iKPEh1WZaW5ZLdalGC3ymW3yGGzKMkZmArm8frl9vqVU+RRTmGpCku9Ki1rK3B7tWlfkXbnuyt/oeqQT37eVa3zHFaLUhPsKir1yjSlRomB/vGbCr02+4s8Ki71yev3q01Gok7KzlCn5ik6pmmymiY71bJRgjbnFMn0+/T1V4t0xulnKLtpipIOMaLJarGG1pHq37FpjTxnAABqQ4MJpZ544gk99NBD2r59u7p06aIZM2bo9NNPj3VZ9U6p16/8Eo8kyW8G/hFb6vMrPdEhl90im8Uiq8WQxZAMg7+uAUBDZZqmfH5TPtOU3y95/X75/ZLPNEPb5dukwHo0FktghEuy0yaLYciUKavF0P4ij9yeQCDi8Zly2iyyWy2hx3PaLLKV7ZumKVOSaUqmTJX9X9mxQJtZ1hacKhU85vWb8vn98vklvxk4r9gTCHisFkNWSyCo8ZuBKU2mGQgIHDaLPL5AOBIISQ7cptTrl8cXCGo8vsBoHI/XDD2XUm+gLa/Yo6JSX2i0TGGpV0Vun4o9vrA6pcB/Q4OvcVXrAFXNpkd/+i7C2zRcGUmOUAAWfM8Wlwb6xjRNtWiUoFSXXaU+v1IT7Mot9sjt8cnt9cvr96tJslPpiQ75/KYaJdqVYLdqc06R8oq9apLsUJNkp1x2ayhwM01p495ClXgCoWGiw6oOzVJ0fPMUZaa4yt77UorLLpfdEupr6cj/7ZSWmCaPx6PfE6UOzZJltzeYf8IDAOJcg/gv2uuvv67rr79eTzzxhPr166enn35aI0aM0E8//aQ2bdrEuryomffDNj33k0Uvbf1WJd7AsO0Sz4Hh28EwKfiPdq8v8I9sr98fuo9IRpu77JayIfI2JTltctgsMk1TFsNQosOqJKctbF0Cm8WQzWqR3WrIajFU4vHLYkh2qyV0zGEN/K/NashuCfyvzWqR3WLIXfYXY79pKslhU4H7wHoKhiEZMsr+N3zfajFUVOpTXrFHbq+/7HkeeKLBv0S7PWVfQnyBL1k2qyG/GfgL8q68ktAQd4/PDE0lCP4VOmzbEjxmyNCBaQflzzEMhf4S7Sn7chP8MlTs8cnj84f+gq3yfWJICfbAlARL2dQGwwjUWVxs1dRVC2Uq8OXK5zdDfW8o0O8qez2C9VgtkrWsVqvFkMMW6IvKlPr88vrM0JQHh9Uiu82QzRL4S6+jrN/CX5cDr0Xwi2CF42WP5/YEvzCWP6dcv4Zez2AoWvEf98HdwJnl9ys/Xr7twL4RdhtTkt9vyuOv+CXUUzadwmIY8pmmfL7Al6Fg3/n8gdfswL4pm9VQWoJdNkvwfW+EPgPWsvd98HWwWgw5rBa5HNayPjRDf2H3m6b8pqlSj0+/bDW0/ovfZRgW+Uwz9Dm0WQJrlgS/JBe4A3+pd9osctmtYf/rLHtfBb/oB7/M+/1maN9ftu83TTnKAoXyfXngd0vgeTrKPu/B17F8iODxmTKMQChQ/vXy+SWf3y+/KaW4bHLarIH3d6lPRtljBD6jgduUlH2xdHuDn2F/6Hda8GNuhv5fWcBRrhbpQABycLvKtTusFiWWfdE88B40Kny+7VaLGiXaZTEMFbq9Kvb4Qu8nU4Hna7OU9Xklv/PswW1r4LNlKjCKpvzv61KvX8WlXq1bb9Gn/12pgtLA7wxL2e+CfYWlKiprC/4O9puB1yv4uvn9B96rYT/l2mp49hGqKfg72Gox1CjRrkSHTQl2q5KdNuUWe+Tx+VVYWKDk5OTQKKjgf/N8pqm8Yk/Z73cj9DkOhnjHZaWoVXqC8kq88vr8of++lv9vs80S2LZZLUpPDPyu2pJTrBKvT+mJdqUnOtQo0aH0RLsaJdrl8QUes8Dtld+UCko8gQDP71dJqU8lXr/cHp8K3D7tK3QrwWGV0xZYQyk90a7kss+5w2aR02ZR4ySHurduFJi6Zwaem7/sfWkYhqyGIafNEhZI2sqFm3UVf8gDAKByDSKUeuSRR3TFFVfoyiuvlCTNmDFDH330kZ588kk98MADMa4uejbnFOuXXIuUu7/G7jOhbL2Fyv6KGwi8SiWV1tjj4fBKvf4qjhhSad2f8oDaYJU2rY11EYg6i7Rre0we2TDKRkUZBwJUhUYplY2kOijUshiS02aVs2zUbSA0PxAglvr8oSDx4McK/LHBCAuYDQUOBP8QYZoK1WILhduB4DAYeARHR/nK/lBjtRz4Y4bb65fTZpHDVhbUlgWvXr9fLrtVduuBAN5eFiYH24L7qa7ANLZEp1VJDlvoDzTB0TIHM80DVztLcdlDI80OxePx6P3339fIkf1kt9sj7ruGhaAHAID6rt6HUqWlpVq+fLluueWWsPZhw4Zp8eLFld7G7XbL7T7w5T0vL09S4B96Ho+n9oqtZQOOzdDeTb+qd8/uSklwhkZBuMqmRARHOARGDwX/Mn9gZIoUGLWSkXjgH7nBf0SXH3XjK7ufYo9PhW5faIqCx2eqyO2V02ZVscengrLpC0G+spFBwfsIfqnx+syD1rEIfKHx+gIjLkrLRg05bBYlOMpCMndguHxwakhodINZfkpH4HE9Pr+SnDalumxy2gJfDILfDQ6MGgmMFHGWfeEwDIVGe1gNQ42THaFRIElOa2AESdlIlQPbB0aXmAftB4+Xb7eVjYKx28K/4CTarYHHtRwYCRXkN02VePyBETh+MzRtxu/z6ttvvlGfPn1kt9vk9vpltwS+VFnLFoq1WgLPNzBdRaEREeVHwLi9/tA0nIO/HAZrLCr1qaRsNFdwwdny/3vwcw8+RlWvg69sJI7LZilX04HRK6HtcrdXWZ8HthRWb/mRMOWPq5LnVZ3bGgp80bWX+yIa+hJqsYT6JThlKfSFuNy+1TDK+tSi0rJ1UzxlI89C7/WyESzBz0HgtSlba6bscxQalVN2n4Hvrqa2b9umNq1bymq1htqD95dgtyrBblWSM/Dl2GoEvnyXlI0qcnuDI4388nj9oRFoB49IKz/qzVK2uLC33PvHLEsg7DZLYORY2ec9GKKGjWY0DoxssBoHXrPy/2sYUk6RJxQeuGyWUPLgsB0YTeYqCzkCIUJgtIW9bITIwSGGQttGKMiQDtSlsv5WuVF4wfOCiyibqvgeLr9f6vUrpygQ1AdGuISHERYj+LswOFLywHvAE/wdWW59H0vZa2UvG1VnK/tc2wxTmzb8rs6dOqpRojM0OtJmCazvk+KyyWoxVFDiDRupWP69WT5QshqBkXrWsLbAfyusFoXOsZT730MxTVNFpYG1kexlVw1LdtoOuahy8HL3ob6It5Elpk8+n+Q7zEy+4L9T6vO/V3Bk6Pv4Rd/HL/o+fjWEvq9u7YZ58CIH9cy2bdvUsmVLff311zr11FND7VOnTtWLL76oNWvWVLjN5MmTNWXKlArts2fPVmJiYq3WCwAAAAAA0JAVFRVp7Nixys3NVWpqapXn1fuRUkEH/0XVLPsreWVuvfVWTZw4MbSfl5en1q1ba9iwYYd8seo6j8ejBQsWaOjQoQzpjzP0ffyi7+MT/R6/6Pv4Rd/HL/o+ftH38ash9H1wRtrh1PtQqkmTJrJardqxY0dY+65du9SsWbNKb+N0OuV0Oiu02+32etvh5TWU54HI0ffxi76PT/R7/KLv4xd9H7/o+/hF38ev+tz31a277l+u5DAcDod69eqlBQsWhLUvWLAgbDofAAAAAAAA6o56P1JKkiZOnKhLLrlEJ510kvr27atnnnlGmzZt0l/+8pdYlwYAAAAAAIBKNIhQ6qKLLtLevXt1zz33aPv27eratavef/99ZWdnx7o0AAAAAAAAVKJBhFKSNGHCBE2YMCHWZQAAAAAAAKAa6v2aUgAAAAAAAKh/CKUAAAAAAAAQdYRSAAAAAAAAiDpCKQAAAAAAAEQdoRQAAAAAAACijlAKAAAAAAAAUUcoBQAAAAAAgKgjlAIAAAAAAEDUEUoBAAAAAAAg6gilAAAAAAAAEHWEUgAAAAAAAIg6QikAAAAAAABEHaEUAAAAAAAAoo5QCgAAAAAAAFFni3UBdYFpmpKkvLy8GFdydDwej4qKipSXlye73R7rchBF9H38ou/jE/0ev+j7+EXfxy/6Pn7R9/GrIfR9MF8J5i1VIZSSlJ+fL0lq3bp1jCsBAAAAAABoGPLz85WWllblccM8XGwVB/x+v7Zt26aUlBQZhhHrco5YXl6eWrdurc2bNys1NTXW5SCK6Pv4Rd/HJ/o9ftH38Yu+j1/0ffyi7+NXQ+h70zSVn5+vFi1ayGKpeuUoRkpJslgsatWqVazLqDGpqan19o2Lo0Pfxy/6Pj7R7/GLvo9f9H38ou/jF30fv+p73x9qhFQQC50DAAAAAAAg6gilAAAAAAAAEHWEUg2I0+nU3XffLafTGetSEGX0ffyi7+MT/R6/6Pv4Rd/HL/o+ftH38Sue+p6FzgEAAAAAABB1jJQCAAAAAABA1BFKAQAAAAAAIOoIpQAAAAAAABB1hFJ1yAMPPKDevf9/e3caG1XVx3H8N2UZCrSDgO2UglJFUEJlfSyLyhJoRqhLMESFFCHVWBBEhZCIJm1CBCQCpjUGkFjQmCBEFIJQg7agYEGEDhQQVAQNtGUp0GEJtEPP88J0ZCxFCnPvDPj9JH3BmdNzz8mP2/z5czvzP8XExCguLk5PPfWUDhw4EDTHGKPs7Gy1a9dO0dHRGjRokPbu3Rs0Z/HixRo0aJBiY2PlcDh05syZOtc6ffq00tPT5XK55HK5lJ6eftV5sIdd2R8+fFgZGRlKSkpSdHS07r33XmVlZamqqsrqI6Iedt73tS5duqQePXrI4XDI6/VacCpcD7uz/+qrr5SSkqLo6Gi1bdtWI0eOtOpo+Bd2Zv/LL7/oySefVNu2bRUbG6sBAwaosLDQyuOhHqHI/dSpU5o8ebK6dOmi5s2b66677tIrr7yiysrKoHWo8yKLXdlT50UeO+/7WtR5kcHu7G/lOo+mVATZtGmTXn75ZW3dulUbNmyQ3+9Xamqqzp8/H5gzd+5czZ8/X++//762b98ut9utYcOG6ezZs4E5Fy5ckMfj0YwZM+q91ujRo+X1epWfn6/8/Hx5vV6lp6dbej7Uz67s9+/fr5qaGi1atEh79+7VggULtHDhwmv+XYG17Lzva02fPl3t2rWz5Dy4fnZm//nnnys9PV3jx4/Xrl27tGXLFo0ePdrS86F+dmY/YsQI+f1+FRQUaMeOHerRo4fS0tJUXl5u6RlRVyhyLy0tVWlpqd59912VlJRo6dKlys/PV0ZGRtC1qPMii13ZU+dFHjvv+1rUeZHBzuxv+TrPIGIdP37cSDKbNm0yxhhTU1Nj3G63mTNnTmDOxYsXjcvlMgsXLqzz/YWFhUaSOX36dND4vn37jCSzdevWwFhRUZGRZPbv32/NYdAgVmV/NXPnzjVJSUkh2ztujtXZr1u3ztx///1m7969RpIpLi624hi4AVZlX11dbRITE82SJUss3T9unFXZnzhxwkgy3333XWDM5/MZSeabb76x5jC4bjebe60VK1aYpk2bmurqamMMdd6twKrsr4Y6L7JYnT11XuSyKvvboc7jSakIVvtYXuvWrSVJhw4dUnl5uVJTUwNznE6nBg4cqB9++OG61y0qKpLL5VJKSkpgrG/fvnK5XA1aB9axKvv6rlV7HYSfldkfO3ZML774oj755BM1b948dJtGSFiV/c6dO3X06FFFRUWpZ8+eSkhI0GOPPVbnV8EQPlZl36ZNGz3wwAP6+OOPdf78efn9fi1atEjx8fHq3bt3aA+BBgtV7pWVlYqNjVXjxo0lUefdCqzKvr451HmRw8rsqfMim1XZ3w51Hk2pCGWM0euvv66HH35Y3bp1k6TAo/bx8fFBc+Pj4xv0GH55ebni4uLqjMfFxfE4fwSwMvt/OnjwoHJzc5WZmXnjG0bIWJm9MUbjxo1TZmam+vTpE7pNIySszP7333+XJGVnZ+utt97S2rVrdccdd2jgwIE6depUiE6AG2Vl9g6HQxs2bFBxcbFiYmLUrFkzLViwQPn5+WrVqlXIzoCGC1XuFRUVmjlzpl566aXAGHVeZLMy+3+izossVmZPnRfZrMz+dqjz6m+rI6wmTZqk3bt3a/PmzXVeczgcQX82xtQZ+zdXm38j6yD0rM6+VmlpqTwej0aNGqUXXnjhhtZAaFmZfW5urnw+n954442b3idCz8rsa2pqJElvvvmmnn76aUlSXl6e2rdvr5UrV17zHzSwnpXZG2M0ceJExcXF6fvvv1d0dLSWLFmitLQ0bd++XQkJCTe9f9yYUOTu8/k0YsQIde3aVVlZWddc41rrwF5WZ1+LOi/yWJk9dV5kszL726HO40mpCDR58mStWbNGhYWFat++fWDc7XZLUp3O6fHjx+t0WK/F7Xbr2LFjdcZPnDjRoHUQelZnX6u0tFSDBw9Wv379tHjx4pvbNELC6uwLCgq0detWOZ1ONW7cWJ06dZIk9enTR88//3wIToAbZXX2tY2Hrl27BsacTqfuuece/fnnnzezddwkO+77tWvXavny5RowYIB69eqlDz74QNHR0Vq2bFloDoEGC0XuZ8+elcfjUcuWLfXFF1+oSZMmQetQ50Umq7OvRZ0XeazOnjovclmd/e1Q59GUiiDGGE2aNEmrVq1SQUGBkpKSgl5PSkqS2+3Whg0bAmNVVVXatGmT+vfvf93X6devnyorK/Xjjz8GxrZt26bKysoGrYPQsSt7STp69KgGDRqkXr16KS8vT1FR/BgIJ7uyz8nJ0a5du+T1euX1erVu3TpJ0meffaa33347NIdBg9iVfe/eveV0OoM+hri6ulqHDx/W3XffffMHQYPZlf2FCxckqc7P+aioqMD/rMI+ocrd5/MpNTVVTZs21Zo1a9SsWbOgdajzIo9d2UvUeZHGruyp8yKPXdnfFnWe9e+ljus1YcIE43K5zMaNG01ZWVng68KFC4E5c+bMMS6Xy6xatcqUlJSY5557ziQkJBifzxeYU1ZWZoqLi82HH34Y+NSd4uJiU1FREZjj8XjMgw8+aIqKikxRUZFJTk42aWlptp4Xf7Mr+6NHj5pOnTqZIUOGmCNHjgRdC+Fh531/pUOHDvGpLGFmZ/ZTpkwxiYmJ5uuvvzb79+83GRkZJi4uzpw6dcrWM+MvdmV/4sQJ06ZNGzNy5Ejj9XrNgQMHzLRp00yTJk2M1+u1/dz/daHI3efzmZSUFJOcnGx+++23oHX8fn9gHeq8yGJX9tR5kcfO+/5K1HnhZ2f2t3qdR1Mqgki66ldeXl5gTk1NjcnKyjJut9s4nU7z6KOPmpKSkqB1srKy/nWdiooKM2bMGBMTE2NiYmLMmDFj6v0IeVjPruzz8vLqvRbCw877/koUK+FnZ/ZVVVVm6tSpJi4uzsTExJihQ4eaPXv22HRS/JOd2W/fvt2kpqaa1q1bm5iYGNO3b1+zbt06m06KK4Ui98LCwnrXOXToUGAedV5ksSt76rzIY+d9fyXqvPCzM/tbvc5zGGOMAAAAAAAAABvxS8YAAAAAAACwHU0pAAAAAAAA2I6mFAAAAAAAAGxHUwoAAAAAAAC2oykFAAAAAAAA29GUAgAAAAAAgO1oSgEAAAAAAMB2NKUAAAAAAABgO5pSAAAAAAAAsB1NKQAAAJuNGzdODodDDodDTZo0UXx8vIYNG6aPPvpINTU1173O0qVL1apVK+s2CgAAYCGaUgAAAGHg8XhUVlamw4cPa/369Ro8eLCmTJmitLQ0+f3+cG8PAADAcjSlAAAAwsDpdMrtdisxMVG9evXSjBkztHr1aq1fv15Lly6VJM2fP1/Jyclq0aKFOnTooIkTJ+rcuXOSpI0bN2r8+PGqrKwMPHWVnZ0tSaqqqtL06dOVmJioFi1aKCUlRRs3bgzPQQEAAOpBUwoAACBCDBkyRN27d9eqVaskSVFRUcrJydGePXu0bNkyFRQUaPr06ZKk/v3767333lNsbKzKyspUVlamadOmSZLGjx+vLVu2aPny5dq9e7dGjRolj8ejX3/9NWxnAwAA+CeHMcaEexMAAAD/JePGjdOZM2f05Zdf1nnt2Wef1e7du7Vv3746r61cuVITJkzQyZMnJf31nlKvvvqqzpw5E5hz8OBB3XfffTpy5IjatWsXGB86dKgeeughzZo1K+TnAQAAuBGNw70BAAAA/M0YI4fDIUkqLCzUrFmztG/fPvl8Pvn9fl28eFHnz59XixYtrvr9O3fulDFGnTt3Dhq/dOmS2rRpY/n+AQAArhdNKQAAgAjy888/KykpSX/88YeGDx+uzMxMzZw5U61bt9bmzZuVkZGh6urqer+/pqZGjRo10o4dO9SoUaOg11q2bGn19gEAAK4bTSkAAIAIUVBQoJKSEr322mv66aef5Pf7NW/ePEVF/fU2oCtWrAia37RpU12+fDlorGfPnrp8+bKOHz+uRx55xLa9AwAANBRNKQAAgDC4dOmSysvLdfnyZR07dkz5+fmaPXu20tLSNHbsWJWUlMjv9ys3N1ePP/64tmzZooULFwat0bFjR507d07ffvutunfvrubNm6tz584aM2aMxo4dq3nz5qlnz546efKkCgoKlJycrOHDh4fpxAAAAMH49D0AAIAwyM/PV0JCgjp27CiPx6PCwkLl5ORo9erVatSokXr06KH58+frnXfeUbdu3fTpp59q9uzZQWv0799fmZmZeuaZZ3TnnXdq7ty5kqS8vDyNHTtWU6dOVZcuXfTEE09o27Zt6tChQziOCgAAcFV8+h4AAAAAAABsx5NSAAAAAAAAsB1NKQAAAAAAANiOphQAAAAAAABsR1MKAAAAAAAAtqMpBQAAAAAAANvRlAIAAAAAAIDtaEoBAAAAAADAdjSlAAAAAAAAYDuaUgAAAAAAALAdTSkAAAAAAADYjqYUAAAAAAAAbEdTCgAAAAAAALb7PyLXs4tZCYFrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LONG–SHORT PERFORMANCE STATS\n",
      "Mean daily LS return: 0.1397%\n",
      "Daily volatility:     1.1293%\n",
      "Annualized Sharpe:    1.96\n",
      "\n",
      "============================================================\n",
      "✓ TEST COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "  2. Adjust forward_days for different holding periods\n",
      "  3. Use meta_alpha for portfolio construction\n",
      "  4. Backtest the meta-alpha strategy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MetaAlphaCreator:\n",
    "    \"\"\"\n",
    "    Creates a meta-alpha by combining multiple Alpha101 factors using Lasso regression.\n",
    "    Handles look-ahead bias, proper cross-validation, and normalization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha_list=None, lookback_days=252, forward_days=1):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        alpha_list : list, optional\n",
    "            List of alpha numbers to use (1-126). If None, uses all compatible alphas.\n",
    "        lookback_days : int\n",
    "            Training window size in days\n",
    "        forward_days : int\n",
    "            Forward return period (default: 1 day)\n",
    "        \"\"\"\n",
    "        self.alpha_list = alpha_list or list(range(1, 127))\n",
    "        self.lookback_days = lookback_days\n",
    "        self.forward_days = forward_days\n",
    "        self.coef_ = None\n",
    "        self.selected_alphas_ = None\n",
    "        \n",
    "        # Alphas known to have issues\n",
    "        self.incompatible_alphas = []\n",
    "        #self.incompatible_alphas = [4, 13, 15, 16, 22, 23, 26, 33, 40, 44, 46, \n",
    "        #                             55, 60, 116, 124, 125, 126]\n",
    "        \n",
    "    def compute_alpha(self, alpha_calc, alpha_num):\n",
    "        \"\"\"\n",
    "        Safely compute a single alpha factor.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        alpha_calc : Alpha101 instance\n",
    "        alpha_num : int\n",
    "            Alpha number (1-126)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.Series or None if alpha fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Your Alpha101 uses alpha_001, alpha_002, etc. format\n",
    "            method_name = f'alpha_{str(alpha_num).zfill(3)}'\n",
    "            alpha_func = getattr(alpha_calc, method_name, None)\n",
    "            \n",
    "            if alpha_func is None:\n",
    "                print(f\"  ✗ Alpha {alpha_num}: method not found\")\n",
    "                return None\n",
    "            \n",
    "            result = alpha_func()\n",
    "            \n",
    "            if result is None or len(result) == 0:\n",
    "                print(f\"  ✗ Alpha {alpha_num}: returned None/empty\")\n",
    "                return None\n",
    "            \n",
    "            # Convert to Series if DataFrame\n",
    "            if isinstance(result, pd.DataFrame):\n",
    "                if result.shape[1] == 1:\n",
    "                    result = result.iloc[:, 0]\n",
    "                else:\n",
    "                    print(f\"  ✗ Alpha {alpha_num}: returned multi-column DataFrame\")\n",
    "                    return None\n",
    "            \n",
    "            # Ensure it's a Series\n",
    "            if not isinstance(result, pd.Series):\n",
    "                result = pd.Series(result)\n",
    "            \n",
    "            print(f\"  ✓ Alpha {alpha_num}: computed successfully\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Alpha {alpha_num}: {str(e)[:80]}\")\n",
    "            return None\n",
    "    \n",
    "    def build_alpha_matrix(self, df, alpha_calc):\n",
    "        \"\"\"\n",
    "        Build matrix of alpha factors.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            Stock data with columns: date, symbol, open, high, low, close, volume\n",
    "        alpha_calc : Alpha101 instance\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame with alpha values\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Building Alpha Matrix\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        alpha_matrix = pd.DataFrame(index=df.index)\n",
    "        successful_alphas = []\n",
    "        \n",
    "        for alpha_num in self.alpha_list:\n",
    "            if alpha_num in self.incompatible_alphas:\n",
    "                print(f\"  ⊗ Alpha {alpha_num}: skipped (known incompatible)\")\n",
    "                continue\n",
    "            \n",
    "            alpha_series = self.compute_alpha(alpha_calc, alpha_num)\n",
    "            \n",
    "            if alpha_series is None:\n",
    "                continue\n",
    "            \n",
    "            alpha_series_aligned = pd.Series(alpha_series.values, index=alpha_matrix.index)\n",
    "    \n",
    "            # Replace inf → NaN\n",
    "            alpha_series_aligned.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            \n",
    "            # Skip alpha if too sparse\n",
    "            nan_ratio = alpha_series_aligned.isna().mean()\n",
    "            if nan_ratio > 0.3:\n",
    "                print(f\"  ✗ Alpha {alpha_num}: dropped (NaN ratio {nan_ratio:.2f})\")\n",
    "                continue\n",
    "            \n",
    "            # Winsorize safely\n",
    "            std = alpha_series_aligned.std(skipna=True)\n",
    "            mean = alpha_series_aligned.mean(skipna=True)\n",
    "            \n",
    "            if std > 0:\n",
    "                alpha_series_aligned = alpha_series_aligned.clip(\n",
    "                    mean - 10 * std,\n",
    "                    mean + 10 * std\n",
    "                )\n",
    "            \n",
    "            alpha_matrix[f'alpha{alpha_num}'] = alpha_series_aligned\n",
    "            successful_alphas.append(alpha_num)\n",
    "        \n",
    "        # Drop columns that are entirely NaN\n",
    "        alpha_matrix = alpha_matrix.dropna(axis=1, how='all')\n",
    "        \n",
    "        print(f\"\\n✓ Successfully computed {len(successful_alphas)} alphas\")\n",
    "        print(f\"  Alphas: {successful_alphas}\")\n",
    "        print(f\"  Matrix shape: {alpha_matrix.shape}\")\n",
    "        \n",
    "        return alpha_matrix, successful_alphas\n",
    "    \n",
    "    def prepare_data(self, df, alpha_matrix):\n",
    "        \"\"\"\n",
    "        Prepare X (features) and y (target) with proper alignment.\n",
    "        CRITICAL: Prevents look-ahead bias.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            Original stock data\n",
    "        alpha_matrix : pd.DataFrame\n",
    "            Computed alpha values\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X, y, dates, symbols aligned properly\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Preparing Training Data\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Compute FUTURE return (target)\n",
    "        # CRITICAL: Use forward_days periods ahead\n",
    "        df_copy = df.copy()\n",
    "        df_copy['future_ret'] = df_copy.groupby('symbol')['close'].shift(-self.forward_days) / df_copy['close'] - 1\n",
    "        \n",
    "        # Extract target\n",
    "        y = df_copy['future_ret']\n",
    "        \n",
    "        # Extract dates and symbols for later analysis\n",
    "        dates = df_copy['date'] if 'date' in df_copy.columns else df_copy.index\n",
    "        symbols = df_copy['symbol'] if 'symbol' in df_copy.columns else None\n",
    "        \n",
    "        # Build X from alpha_matrix\n",
    "        X = alpha_matrix.copy()\n",
    "        \n",
    "        # Step 1: Drop rows where ALL alphas are NaN\n",
    "        mask_X = ~X.isna().all(axis=1)\n",
    "        X = X[mask_X]\n",
    "        y = y[mask_X]\n",
    "        dates = dates[mask_X]\n",
    "        if symbols is not None:\n",
    "            symbols = symbols[mask_X]\n",
    "        \n",
    "        # Step 2: Drop rows where target y is NaN (last forward_days periods per stock)\n",
    "        mask_y = ~y.isna()\n",
    "        X = X[mask_y]\n",
    "        y = y[mask_y]\n",
    "        dates = dates[mask_y]\n",
    "        if symbols is not None:\n",
    "            symbols = symbols[mask_y]\n",
    "        \n",
    "        print(f\"  Original data points: {len(df)}\")\n",
    "        print(f\"  After removing NaN alphas: {mask_X.sum()}\")\n",
    "        print(f\"  After removing NaN targets: {mask_y.sum()}\")\n",
    "        print(f\"  Final training samples: {len(X)}\")\n",
    "        \n",
    "        return X, y, dates, symbols\n",
    "    \n",
    "    def fit(self, df, alpha_calc, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Fit Lasso model to select best alphas.\n",
    "        Uses TimeSeriesSplit for proper cross-validation.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            Stock data\n",
    "        alpha_calc : Alpha101 instance\n",
    "        cv_folds : int\n",
    "            Number of time-series CV folds\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FITTING META-ALPHA MODEL\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Build alpha matrix\n",
    "        alpha_matrix, successful_alphas = self.build_alpha_matrix(df, alpha_calc)\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y, dates, symbols = self.prepare_data(df, alpha_matrix)\n",
    "        \n",
    "        # Normalize features (critical for Lasso)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Normalizing Features\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "                # ================= INF CHECK =================\n",
    "        inf_count = np.isinf(X.values).sum()\n",
    "        print(f\"  Infinite values in X: {inf_count}\")\n",
    "        \n",
    "        if inf_count > 0:\n",
    "            bad_cols = X.columns[np.isinf(X).any()]\n",
    "            print(\"  Columns with inf:\", bad_cols.tolist())\n",
    "        \n",
    "        # Replace infinities safely\n",
    "        X = X.replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(X.fillna(X.mean())),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        print(\"  ✓ Features normalized (mean=0, std=1)\")\n",
    "        \n",
    "        # Time-series cross-validation\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Training with Time-Series Cross-Validation\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits=cv_folds)\n",
    "        \n",
    "        # Fit LassoCV with time-series splits\n",
    "        lasso = LassoCV(\n",
    "            cv=tscv,\n",
    "            random_state=42,\n",
    "            max_iter=10000,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        lasso.fit(X_scaled, y)\n",
    "        \n",
    "        print(f\"  ✓ Optimal alpha (regularization): {lasso.alpha_:.6f}\")\n",
    "        print(f\"  ✓ Cross-validated R²: {lasso.score(X_scaled, y):.4f}\")\n",
    "        \n",
    "        # Extract coefficients\n",
    "        self.coef_ = pd.Series(lasso.coef_, index=X_scaled.columns)\n",
    "        self.selected_alphas_ = self.coef_[self.coef_ != 0]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SELECTED ALPHAS (Non-Zero Coefficients)\")\n",
    "        print(\"=\"*60)\n",
    "        print(self.selected_alphas_.sort_values(ascending=False))\n",
    "        print(f\"\\nTotal selected: {len(self.selected_alphas_)} / {len(self.coef_)}\")\n",
    "        \n",
    "        # Store scaler and filled X for prediction\n",
    "        self.scaler_ = scaler\n",
    "        self.X_filled_ = X.fillna(X.mean())\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        \"\"\"\n",
    "        Predict using fitted meta-alpha.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_new : pd.DataFrame\n",
    "            New alpha values\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.Series of predicted returns\n",
    "        \"\"\"\n",
    "        if self.coef_ is None:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        # Fill NaN and scale\n",
    "        X_filled = X_new.fillna(X_new.mean())\n",
    "        X_scaled = pd.DataFrame(\n",
    "            self.scaler_.transform(X_filled),\n",
    "            columns=X_filled.columns,\n",
    "            index=X_filled.index\n",
    "        )\n",
    "        \n",
    "        # Predict\n",
    "        meta_alpha = X_scaled.dot(self.coef_)\n",
    "        \n",
    "        return meta_alpha\n",
    "    \n",
    "    def get_meta_alpha(self):\n",
    "        \"\"\"\n",
    "        Get the meta-alpha values for the training data.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.Series of meta-alpha values\n",
    "        \"\"\"\n",
    "        if self.coef_ is None:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        X_scaled = pd.DataFrame(\n",
    "            self.scaler_.transform(self.X_filled_),\n",
    "            columns=self.X_filled_.columns,\n",
    "            index=self.X_filled_.index\n",
    "        )\n",
    "        \n",
    "        meta_alpha = X_scaled.dot(self.coef_)\n",
    "        \n",
    "        return meta_alpha\n",
    "    \n",
    "    def analyze_performance(self, meta_alpha, y):\n",
    "        \"\"\"\n",
    "        Analyze the meta-alpha performance.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        meta_alpha : pd.Series\n",
    "            Meta-alpha values\n",
    "        y : pd.Series\n",
    "            Actual returns\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"META-ALPHA PERFORMANCE ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Align series\n",
    "        aligned = pd.DataFrame({'meta_alpha': meta_alpha, 'return': y}).dropna()\n",
    "        \n",
    "        # Correlation\n",
    "        corr = aligned['meta_alpha'].corr(aligned['return'])\n",
    "        print(f\"Correlation with returns: {corr:.4f}\")\n",
    "        \n",
    "        # Rank correlation (more robust)\n",
    "        rank_corr = aligned['meta_alpha'].corr(aligned['return'], method='spearman')\n",
    "        print(f\"Rank correlation (Spearman): {rank_corr:.4f}\")\n",
    "        \n",
    "        # Quintile analysis\n",
    "        aligned['quintile'] = pd.qcut(aligned['meta_alpha'], 5, labels=[1,2,3,4,5], duplicates='drop')\n",
    "        quintile_returns = aligned.groupby('quintile')['return'].mean()\n",
    "        \n",
    "        print(f\"\\nQuintile Returns (1=lowest, 5=highest meta-alpha):\")\n",
    "        for q, ret in quintile_returns.items():\n",
    "            print(f\"  Q{q}: {ret*100:.3f}%\")\n",
    "        \n",
    "        spread = quintile_returns.iloc[-1] - quintile_returns.iloc[0]\n",
    "        print(f\"\\nLong-Short Spread (Q5-Q1): {spread*100:.3f}%\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# USAGE EXAMPLE WITH BIST100 DATA\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Test with BIST100 data - first 10 alphas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TESTING META-ALPHA WITH BIST100 DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Load structured BIST100 data\n",
    "    print(\"\\n[1/5] Loading BIST100 data...\")\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Try to load from pickle first (fast)\n",
    "    pickle_path = 'bist100_data.pkl'\n",
    "    if Path(pickle_path).exists():\n",
    "        print(f\"  Loading from pickle: {pickle_path}\")\n",
    "        loader = StockDataLoader('dummy')\n",
    "        loader.load_structured_data(pickle_path)\n",
    "    else:\n",
    "        print(f\"  Pickle not found, loading from CSVs...\")\n",
    "        folder_path = r'C:\\Users\\TESLA\\Desktop\\datasets\\bist_100_2010-2025_daily'\n",
    "        loader = StockDataLoader(folder_path)\n",
    "        loader.load_all_files()\n",
    "        loader.structure_data()\n",
    "        loader.save_structured_data(pickle_path)\n",
    "    \n",
    "    # Step 2: Convert to long format for Alpha101\n",
    "    print(\"\\n[2/5] Converting to long format...\")\n",
    "    \n",
    "    # Your Alpha101 expects long format with columns: symbol, date, open, high, low, close, volume\n",
    "    # Stack to long format\n",
    "    close_df = loader.data['close']\n",
    "    open_df = loader.data['open']\n",
    "    high_df = loader.data['high']\n",
    "    low_df = loader.data['low']\n",
    "    volume_df = loader.data['volume']\n",
    "    \n",
    "    data_list = []\n",
    "    for stock in loader.stocks:\n",
    "        stock_data = pd.DataFrame({\n",
    "            'symbol': stock,\n",
    "            'date': close_df.index,\n",
    "            'open': open_df[stock],\n",
    "            'high': high_df[stock],\n",
    "            'low': low_df[stock],\n",
    "            'close': close_df[stock],\n",
    "            'volume': volume_df[stock],\n",
    "            'returns': close_df[stock].pct_change()  # Add returns column that Alpha101 needs\n",
    "        })\n",
    "        data_list.append(stock_data)\n",
    "    \n",
    "    df = pd.concat(data_list, ignore_index=True)\n",
    "    df = df.dropna(subset=['close'])  # Remove rows with no price data\n",
    "    df = df.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
    "\n",
    "    # Typical price\n",
    "    tp = (df['high'] + df['low'] + df['close']) / 3\n",
    "    \n",
    "    df['vwap'] = (\n",
    "        (tp * df['volume'])\n",
    "        .groupby(df['symbol'])\n",
    "        .cumsum()\n",
    "        / df['volume'].groupby(df['symbol']).cumsum()\n",
    "    )\n",
    "\n",
    "    for w in [10, 15, 20, 30, 40, 60, 120, 180]:\n",
    "        df[f'adv{w}'] = (\n",
    "            df.groupby('symbol')['volume']\n",
    "              .transform(lambda x: x.rolling(w, min_periods=w).mean())\n",
    "        )\n",
    "\n",
    "\n",
    "    print(f\"  Long format shape: {df.shape}\")\n",
    "    print(f\"  Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    print(f\"  Unique stocks: {df['symbol'].nunique()}\")\n",
    "    print(f\"  Columns: {df.columns.tolist()}\")\n",
    "    print(f\"\\n  Sample data:\")\n",
    "    print(df.head(10))\n",
    "    \n",
    "    # Step 3: Initialize Alpha101\n",
    "    print(\"\\n[3/5] Initializing Alpha101 calculator...\")\n",
    "    \n",
    "    # Your Alpha101 takes the dataframe directly\n",
    "    try:\n",
    "        # Assuming your Alpha101 class is in a file called alpha101.py\n",
    "        # If it's in a different file, adjust the import\n",
    "        import sys\n",
    "        sys.path.append('.')  # Add current directory to path\n",
    "        \n",
    "        # Try to import\n",
    "        try:\n",
    "            from alpha101 import Alpha101\n",
    "        except ImportError:\n",
    "            # If that fails, try to define it inline (you can paste your Alpha101 class here)\n",
    "            print(\"  ⚠ Could not import Alpha101 from alpha101.py\")\n",
    "            print(\"  Please ensure your Alpha101 class is available\")\n",
    "            print(\"\\n  Expected Alpha101 signature:\")\n",
    "            print(\"    class Alpha101:\")\n",
    "            print(\"        def __init__(self, data):\")\n",
    "            print(\"            self.data = data  # DataFrame with symbol, date, OHLCV, returns\")\n",
    "            print(\"        def alpha_001(self): ...\")\n",
    "            print(\"        def alpha_002(self): ...\")\n",
    "            raise\n",
    "        \n",
    "        # Initialize with your data\n",
    "        alpha_calc = Alpha101(df)\n",
    "        print(\"  ✓ Alpha101 initialized\")\n",
    "        print(f\"  Data shape: {alpha_calc.data.shape}\")\n",
    "        print(f\"  Columns available: {alpha_calc.data.columns.tolist()}\")\n",
    "\n",
    "        df['target'] = (\n",
    "            df.groupby('symbol')['returns']\n",
    "              .shift(-1)\n",
    "        )\n",
    "        \n",
    "        TCOST = 0.0005  # 5 bps transaction cost\n",
    "        df['target_net'] = df['target'] - TCOST\n",
    "        \n",
    "\n",
    "        test_alphas = list(range(1, 51))  \n",
    "        \n",
    "        meta = MetaAlphaCreator(alpha_list=test_alphas, forward_days=5) #was 1\n",
    "        meta.fit(df, alpha_calc, cv_folds=3)\n",
    "        \n",
    "        # Step 5: Analyze results\n",
    "        print(\"\\n[5/5] Analyzing meta-alpha performance...\")\n",
    "        meta_alpha = meta.get_meta_alpha()\n",
    "        \n",
    "        # Get corresponding returns\n",
    "        y = df['target_net']\n",
    "        y = y.loc[meta_alpha.index]\n",
    "\n",
    "        \n",
    "        meta.analyze_performance(meta_alpha, y)\n",
    "\n",
    "\n",
    "        pnl_df = df.loc[meta_alpha.index, ['date', 'symbol', 'target_net']].copy()\n",
    "        pnl_df['meta_alpha'] = meta_alpha.values\n",
    "        \n",
    "        assert pnl_df[['meta_alpha', 'target_net']].notna().all().all()\n",
    "\n",
    "        def compute_long_short_returns(df, q=0.2):\n",
    "            daily_ls = []\n",
    "        \n",
    "            for date, g in df.groupby('date'):\n",
    "                g = g.dropna(subset=['meta_alpha', 'target_net'])\n",
    "                if len(g) < 20:\n",
    "                    continue\n",
    "        \n",
    "                g = g.sort_values('meta_alpha')\n",
    "                n = int(len(g) * q)\n",
    "                if n == 0:\n",
    "                    continue\n",
    "        \n",
    "                short_ret = g.iloc[:n]['target_net'].mean()\n",
    "                long_ret  = g.iloc[-n:]['target_net'].mean()\n",
    "        \n",
    "                daily_ls.append({\n",
    "                    'date': date,\n",
    "                    'long_short_ret': long_ret - short_ret\n",
    "                })\n",
    "\n",
    "            return pd.DataFrame(daily_ls).set_index('date')\n",
    "            \n",
    "        ls_returns = compute_long_short_returns(pnl_df, q=0.2)\n",
    "        \n",
    "        ls_returns['cum_pnl'] = (1 + ls_returns['long_short_ret']).cumprod()\n",
    "            \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(ls_returns.index, ls_returns['cum_pnl'])\n",
    "        plt.title('Meta-Alpha Long–Short Cumulative PnL (5-Day Forward)')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Cumulative Return')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        mean_daily = ls_returns['long_short_ret'].mean()\n",
    "        std_daily  = ls_returns['long_short_ret'].std()\n",
    "        sharpe = mean_daily / std_daily * np.sqrt(252)\n",
    "        \n",
    "        print(\"\\nLONG–SHORT PERFORMANCE STATS\")\n",
    "        print(f\"Mean daily LS return: {mean_daily:.4%}\")\n",
    "        print(f\"Daily volatility:     {std_daily:.4%}\")\n",
    "        print(f\"Annualized Sharpe:    {sharpe:.2f}\")\n",
    "                    \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"✓ TEST COMPLETE!\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"  2. Adjust forward_days for different holding periods\")\n",
    "        print(\"  3. Use meta_alpha for portfolio construction\")\n",
    "        print(\"  4. Backtest the meta-alpha strategy\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"\\n⚠ Alpha101 class not found!\")\n",
    "        print(\"\\nTo use this, you need:\")\n",
    "        print(\"  1. Your Alpha101 class implementation\")\n",
    "        print(\"  2. Import it: from alpha101 import Alpha101\")\n",
    "        print(\"\\nData is ready in 'df' variable:\")\n",
    "        print(f\"  Shape: {df.shape}\")\n",
    "        print(f\"  Columns: {df.columns.tolist()}\")\n",
    "        print(\"\\nYou can now manually test:\")\n",
    "        print(\"  alpha_calc = Alpha101(open=open_df, high=high_df, low=low_df, close=close_df, volume=volume_df)\")\n",
    "        print(\"  meta = MetaAlphaCreator(alpha_list=[1,2,3,4,5])\")\n",
    "        print(\"  meta.fit(df, alpha_calc)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error during testing: {str(e)}\")\n",
    "        print(\"\\nDebug info:\")\n",
    "        print(f\"  df shape: {df.shape}\")\n",
    "        print(f\"  df columns: {df.columns.tolist()}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd813f-1eb8-4131-a13d-7697ed4155d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['return'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6af6762-4038-47f3-a0c7-47c988700074",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha_calc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m alpha_calc\u001b[38;5;241m.\u001b[39malpha_002()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alpha_calc' is not defined"
     ]
    }
   ],
   "source": [
    "alpha_calc.alpha_002()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
