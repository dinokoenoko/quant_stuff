{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f147a2fb-87a2-4264-a580-056a82a56c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "                         \n",
    "def skewness(r):\n",
    "    \"\"\"\n",
    "    Alternative to scipy.stats.skew()\n",
    "    Computes the skewness of the supplied Series or DataFrame\n",
    "    Returns a float or a Series\n",
    "    \"\"\"\n",
    "    demeaned_r = r - r.mean()\n",
    "    # use the population standard deviation, so set dof=0\n",
    "    sigma_r = r.std(ddof=0)\n",
    "    exp = (demeaned_r**3).mean()\n",
    "    return exp/sigma_r**3\n",
    "\n",
    "\n",
    "def kurtosis(r):\n",
    "    \"\"\"\n",
    "    Alternative to scipy.stats.kurtosis()\n",
    "    Computes the kurtosis of the supplied Series or DataFrame\n",
    "    Returns a float or a Series\n",
    "    \"\"\"\n",
    "    demeaned_r = r - r.mean()\n",
    "    # use the population standard deviation, so set dof=0\n",
    "    sigma_r = r.std(ddof=0)\n",
    "    exp = (demeaned_r**4).mean()\n",
    "    return exp/sigma_r**4\n",
    "\n",
    "\n",
    "def compound(r):\n",
    "    \"\"\"\n",
    "    returns the result of compounding the set of returns in r\n",
    "    \"\"\"\n",
    "    return np.expm1(np.log1p(r).sum())\n",
    "\n",
    "                         \n",
    "def annualize_rets(r, periods_per_year):\n",
    "    \"\"\"\n",
    "    Annualizes a set of returns\n",
    "    We should infer the periods per year\n",
    "    but that is currently left as an exercise\n",
    "    to the reader :-)\n",
    "    \"\"\"\n",
    "    compounded_growth = (1+r).prod()\n",
    "    n_periods = r.shape[0]\n",
    "    return compounded_growth**(periods_per_year/n_periods)-1\n",
    "\n",
    "\n",
    "def annualize_vol(r, periods_per_year):\n",
    "    \"\"\"\n",
    "    Annualizes the vol of a set of returns\n",
    "    We should infer the periods per year\n",
    "    but that is currently left as an exercise\n",
    "    to the reader :-)\n",
    "    \"\"\"\n",
    "    return r.std()*(periods_per_year**0.5)\n",
    "\n",
    "\n",
    "def sharpe_ratio(r, riskfree_rate, periods_per_year):\n",
    "    \"\"\"\n",
    "    Computes the annualized sharpe ratio of a set of returns\n",
    "    \"\"\"\n",
    "    # convert the annual riskfree rate to per period\n",
    "    rf_per_period = (1+riskfree_rate)**(1/periods_per_year)-1\n",
    "    excess_ret = r - rf_per_period\n",
    "    ann_ex_ret = annualize_rets(excess_ret, periods_per_year)\n",
    "    ann_vol = annualize_vol(r, periods_per_year)\n",
    "    return ann_ex_ret/ann_vol\n",
    "\n",
    "\n",
    "import scipy.stats\n",
    "def is_normal(r, level=0.01):\n",
    "    \"\"\"\n",
    "    Applies the Jarque-Bera test to determine if a Series is normal or not\n",
    "    Test is applied at the 1% level by default\n",
    "    Returns True if the hypothesis of normality is accepted, False otherwise\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(is_normal)\n",
    "    else:\n",
    "        statistic, p_value = scipy.stats.jarque_bera(r)\n",
    "        return p_value > level\n",
    "\n",
    "\n",
    "def drawdown(return_series: pd.Series):\n",
    "    \"\"\"Takes a time series of asset returns.\n",
    "       returns a DataFrame with columns for\n",
    "       the wealth index, \n",
    "       the previous peaks, and \n",
    "       the percentage drawdown\n",
    "    \"\"\"\n",
    "    wealth_index = 1000*(1+return_series).cumprod()\n",
    "    previous_peaks = wealth_index.cummax()\n",
    "    drawdowns = (wealth_index - previous_peaks)/previous_peaks\n",
    "    return pd.DataFrame({\"Wealth\": wealth_index, \n",
    "                         \"Previous Peak\": previous_peaks, \n",
    "                         \"Drawdown\": drawdowns})\n",
    "\n",
    "\n",
    "def semideviation(r):\n",
    "    \"\"\"\n",
    "    Returns the semideviation aka negative semideviation of r\n",
    "    r must be a Series or a DataFrame, else raises a TypeError\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.Series):\n",
    "        is_negative = r < 0\n",
    "        return r[is_negative].std(ddof=0)\n",
    "    elif isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(semideviation)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "\n",
    "\n",
    "def var_historic(r, level=5):\n",
    "    \"\"\"\n",
    "    Returns the historic Value at Risk at a specified level\n",
    "    i.e. returns the number such that \"level\" percent of the returns\n",
    "    fall below that number, and the (100-level) percent are above\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(var_historic, level=level)\n",
    "    elif isinstance(r, pd.Series):\n",
    "        return -np.percentile(r, level)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "\n",
    "\n",
    "def cvar_historic(r, level=5):\n",
    "    \"\"\"\n",
    "    Computes the Conditional VaR of Series or DataFrame\n",
    "    \"\"\"\n",
    "    if isinstance(r, pd.Series):\n",
    "        is_beyond = r <= -var_historic(r, level=level)\n",
    "        return -r[is_beyond].mean()\n",
    "    elif isinstance(r, pd.DataFrame):\n",
    "        return r.aggregate(cvar_historic, level=level)\n",
    "    else:\n",
    "        raise TypeError(\"Expected r to be a Series or DataFrame\")\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "def var_gaussian(r, level=5, modified=False):\n",
    "    \"\"\"\n",
    "    Returns the Parametric Gauusian VaR of a Series or DataFrame\n",
    "    If \"modified\" is True, then the modified VaR is returned,\n",
    "    using the Cornish-Fisher modification\n",
    "    \"\"\"\n",
    "    # compute the Z score assuming it was Gaussian\n",
    "    z = norm.ppf(level/100)\n",
    "    if modified:\n",
    "        # modify the Z score based on observed skewness and kurtosis\n",
    "        s = skewness(r)\n",
    "        k = kurtosis(r)\n",
    "        z = (z +\n",
    "                (z**2 - 1)*s/6 +\n",
    "                (z**3 -3*z)*(k-3)/24 -\n",
    "                (2*z**3 - 5*z)*(s**2)/36\n",
    "            )\n",
    "    return -(r.mean() + z*r.std(ddof=0))\n",
    "\n",
    "\n",
    "def portfolio_return(weights, returns):\n",
    "    \"\"\"\n",
    "    Computes the return on a portfolio from constituent returns and weights\n",
    "    weights are a numpy array or Nx1 matrix and returns are a numpy array or Nx1 matrix\n",
    "    \"\"\"\n",
    "    return weights.T @ returns\n",
    "\n",
    "\n",
    "def portfolio_vol(weights, covmat):\n",
    "    \"\"\"\n",
    "    Computes the vol of a portfolio from a covariance matrix and constituent weights\n",
    "    weights are a numpy array or N x 1 maxtrix and covmat is an N x N matrix\n",
    "    \"\"\"\n",
    "    return (weights.T @ covmat @ weights)**0.5\n",
    "\n",
    "\n",
    "def plot_ef2(n_points, er, cov):\n",
    "    \"\"\"\n",
    "    Plots the 2-asset efficient frontier\n",
    "    \"\"\"\n",
    "    if er.shape[0] != 2 or er.shape[0] != 2:\n",
    "        raise ValueError(\"plot_ef2 can only plot 2-asset frontiers\")\n",
    "    weights = [np.array([w, 1-w]) for w in np.linspace(0, 1, n_points)]\n",
    "    rets = [portfolio_return(w, er) for w in weights]\n",
    "    vols = [portfolio_vol(w, cov) for w in weights]\n",
    "    ef = pd.DataFrame({\n",
    "        \"Returns\": rets, \n",
    "        \"Volatility\": vols\n",
    "    })\n",
    "    return ef.plot.line(x=\"Volatility\", y=\"Returns\", style=\".-\")\n",
    "\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def minimize_vol(target_return, er, cov):\n",
    "    \"\"\"\n",
    "    Returns the optimal weights that achieve the target return\n",
    "    given a set of expected returns and a covariance matrix\n",
    "    \"\"\"\n",
    "    n = er.shape[0]\n",
    "    init_guess = np.repeat(1/n, n)\n",
    "    bounds = ((0.0, 1.0),) * n # an N-tuple of 2-tuples!\n",
    "    # construct the constraints\n",
    "    weights_sum_to_1 = {'type': 'eq',\n",
    "                        'fun': lambda weights: np.sum(weights) - 1\n",
    "    }\n",
    "    return_is_target = {'type': 'eq',\n",
    "                        'args': (er,),\n",
    "                        'fun': lambda weights, er: target_return - portfolio_return(weights,er)\n",
    "    }\n",
    "    weights = minimize(portfolio_vol, init_guess,\n",
    "                       args=(cov,), method='SLSQP',\n",
    "                       options={'disp': False},\n",
    "                       constraints=(weights_sum_to_1,return_is_target),\n",
    "                       bounds=bounds)\n",
    "    return weights.x\n",
    "\n",
    "\n",
    "\n",
    "def msr(riskfree_rate, er, cov):\n",
    "    \"\"\"\n",
    "    Returns the weights of the portfolio that gives you the maximum sharpe ratio\n",
    "    given the riskfree rate and expected returns and a covariance matrix\n",
    "    \"\"\"\n",
    "    n = er.shape[0]\n",
    "    init_guess = np.repeat(1/n, n)\n",
    "    bounds = ((0.0, 1.0),) * n # an N-tuple of 2-tuples!\n",
    "    # construct the constraints\n",
    "    weights_sum_to_1 = {'type': 'eq',\n",
    "                        'fun': lambda weights: np.sum(weights) - 1\n",
    "    }\n",
    "    def neg_sharpe(weights, riskfree_rate, er, cov):\n",
    "        \"\"\"\n",
    "        Returns the negative of the sharpe ratio\n",
    "        of the given portfolio\n",
    "        \"\"\"\n",
    "        r = portfolio_return(weights, er)\n",
    "        vol = portfolio_vol(weights, cov)\n",
    "        return -(r - riskfree_rate)/vol\n",
    "    \n",
    "    weights = minimize(neg_sharpe, init_guess,\n",
    "                       args=(riskfree_rate, er, cov), method='SLSQP',\n",
    "                       options={'disp': False},\n",
    "                       constraints=(weights_sum_to_1,),\n",
    "                       bounds=bounds)\n",
    "    return weights.x\n",
    "\n",
    "\n",
    "def gmv(cov):\n",
    "    \"\"\"\n",
    "    Returns the weights of the Global Minimum Volatility portfolio\n",
    "    given a covariance matrix\n",
    "    \"\"\"\n",
    "    n = cov.shape[0]\n",
    "    return msr(0, np.repeat(1, n), cov)\n",
    "\n",
    "\n",
    "def optimal_weights(n_points, er, cov):\n",
    "    \"\"\"\n",
    "    Returns a list of weights that represent a grid of n_points on the efficient frontier\n",
    "    \"\"\"\n",
    "    target_rs = np.linspace(er.min(), er.max(), n_points)\n",
    "    weights = [minimize_vol(target_return, er, cov) for target_return in target_rs]\n",
    "    return weights\n",
    "\n",
    "\n",
    "def plot_ef(n_points, er, cov, style='.-', legend=False, show_cml=False, riskfree_rate=0, show_ew=False, show_gmv=False):\n",
    "    \"\"\"\n",
    "    Plots the multi-asset efficient frontier\n",
    "    \"\"\"\n",
    "    weights = optimal_weights(n_points, er, cov)\n",
    "    rets = [portfolio_return(w, er) for w in weights]\n",
    "    vols = [portfolio_vol(w, cov) for w in weights]\n",
    "    ef = pd.DataFrame({\n",
    "        \"Returns\": rets, \n",
    "        \"Volatility\": vols\n",
    "    })\n",
    "    ax = ef.plot.line(x=\"Volatility\", y=\"Returns\", style=style, legend=legend)\n",
    "    if show_cml:\n",
    "        ax.set_xlim(left = 0)\n",
    "        # get MSR\n",
    "        w_msr = msr(riskfree_rate, er, cov)\n",
    "        r_msr = portfolio_return(w_msr, er)\n",
    "        vol_msr = portfolio_vol(w_msr, cov)\n",
    "        # add CML\n",
    "        cml_x = [0, vol_msr]\n",
    "        cml_y = [riskfree_rate, r_msr]\n",
    "        ax.plot(cml_x, cml_y, color='green', marker='o', linestyle='dashed', linewidth=2, markersize=10)\n",
    "    if show_ew:\n",
    "        n = er.shape[0]\n",
    "        w_ew = np.repeat(1/n, n)\n",
    "        r_ew = portfolio_return(w_ew, er)\n",
    "        vol_ew = portfolio_vol(w_ew, cov)\n",
    "        # add EW\n",
    "        ax.plot([vol_ew], [r_ew], color='goldenrod', marker='o', markersize=10)\n",
    "    if show_gmv:\n",
    "        w_gmv = gmv(cov)\n",
    "        r_gmv = portfolio_return(w_gmv, er)\n",
    "        vol_gmv = portfolio_vol(w_gmv, cov)\n",
    "        # add EW\n",
    "        ax.plot([vol_gmv], [r_gmv], color='midnightblue', marker='o', markersize=10)\n",
    "        \n",
    "        return ax\n",
    "\n",
    "                         \n",
    "def run_cppi(risky_r, safe_r=None, m=3, start=1000, floor=0.8, riskfree_rate=0.03, drawdown=None):\n",
    "    \"\"\"\n",
    "    Run a backtest of the CPPI strategy, given a set of returns for the risky asset\n",
    "    Returns a dictionary containing: Asset Value History, Risk Budget History, Risky Weight History\n",
    "    \"\"\"\n",
    "    # set up the CPPI parameters\n",
    "    dates = risky_r.index\n",
    "    n_steps = len(dates)\n",
    "    account_value = start\n",
    "    floor_value = start*floor\n",
    "    peak = account_value\n",
    "    if isinstance(risky_r, pd.Series): \n",
    "        risky_r = pd.DataFrame(risky_r, columns=[\"R\"])\n",
    "\n",
    "    if safe_r is None:\n",
    "        safe_r = pd.DataFrame().reindex_like(risky_r)\n",
    "        safe_r.values[:] = riskfree_rate/12 # fast way to set all values to a number\n",
    "    # set up some DataFrames for saving intermediate values\n",
    "    account_history = pd.DataFrame().reindex_like(risky_r)\n",
    "    risky_w_history = pd.DataFrame().reindex_like(risky_r)\n",
    "    cushion_history = pd.DataFrame().reindex_like(risky_r)\n",
    "    floorval_history = pd.DataFrame().reindex_like(risky_r)\n",
    "    peak_history = pd.DataFrame().reindex_like(risky_r)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        if drawdown is not None:\n",
    "            peak = np.maximum(peak, account_value)\n",
    "            floor_value = peak*(1-drawdown)\n",
    "        cushion = (account_value - floor_value)/account_value\n",
    "        risky_w = m*cushion\n",
    "        risky_w = np.minimum(risky_w, 1)\n",
    "        risky_w = np.maximum(risky_w, 0)\n",
    "        safe_w = 1-risky_w\n",
    "        risky_alloc = account_value*risky_w\n",
    "        safe_alloc = account_value*safe_w\n",
    "        # recompute the new account value at the end of this step\n",
    "        account_value = risky_alloc*(1+risky_r.iloc[step]) + safe_alloc*(1+safe_r.iloc[step])\n",
    "        # save the histories for analysis and plotting\n",
    "        cushion_history.iloc[step] = cushion\n",
    "        risky_w_history.iloc[step] = risky_w\n",
    "        account_history.iloc[step] = account_value\n",
    "        floorval_history.iloc[step] = floor_value\n",
    "        peak_history.iloc[step] = peak\n",
    "    risky_wealth = start*(1+risky_r).cumprod()\n",
    "    backtest_result = {\n",
    "        \"Wealth\": account_history,\n",
    "        \"Risky Wealth\": risky_wealth, \n",
    "        \"Risk Budget\": cushion_history,\n",
    "        \"Risky Allocation\": risky_w_history,\n",
    "        \"m\": m,\n",
    "        \"start\": start,\n",
    "        \"floor\": floor,\n",
    "        \"risky_r\":risky_r,\n",
    "        \"safe_r\": safe_r,\n",
    "        \"drawdown\": drawdown,\n",
    "        \"peak\": peak_history,\n",
    "        \"floor\": floorval_history\n",
    "    }\n",
    "    return backtest_result\n",
    "\n",
    "\n",
    "def summary_stats(r, riskfree_rate=0.03):\n",
    "    \"\"\"\n",
    "    Return a DataFrame that contains aggregated summary stats for the returns in the columns of r\n",
    "    \"\"\"\n",
    "    ann_r = r.aggregate(annualize_rets, periods_per_year=12)\n",
    "    ann_vol = r.aggregate(annualize_vol, periods_per_year=12)\n",
    "    ann_sr = r.aggregate(sharpe_ratio, riskfree_rate=riskfree_rate, periods_per_year=12)\n",
    "    dd = r.aggregate(lambda r: drawdown(r).Drawdown.min())\n",
    "    skew = r.aggregate(skewness)\n",
    "    kurt = r.aggregate(kurtosis)\n",
    "    cf_var5 = r.aggregate(var_gaussian, modified=True)\n",
    "    hist_cvar5 = r.aggregate(cvar_historic)\n",
    "    return pd.DataFrame({\n",
    "        \"Annualized Return\": ann_r,\n",
    "        \"Annualized Vol\": ann_vol,\n",
    "        \"Skewness\": skew,\n",
    "        \"Kurtosis\": kurt,\n",
    "        \"Cornish-Fisher VaR (5%)\": cf_var5,\n",
    "        \"Historic CVaR (5%)\": hist_cvar5,\n",
    "        \"Sharpe Ratio\": ann_sr,\n",
    "        \"Max Drawdown\": dd\n",
    "    })\n",
    "\n",
    "\n",
    "def gbm(n_years = 10, n_scenarios=1000, mu=0.07, sigma=0.15, steps_per_year=12, s_0=100.0, prices=True):\n",
    "    \"\"\"\n",
    "    Evolution of Geometric Brownian Motion trajectories, such as for Stock Prices through Monte Carlo\n",
    "    :param n_years:  The number of years to generate data for\n",
    "    :param n_paths: The number of scenarios/trajectories\n",
    "    :param mu: Annualized Drift, e.g. Market Return\n",
    "    :param sigma: Annualized Volatility\n",
    "    :param steps_per_year: granularity of the simulation\n",
    "    :param s_0: initial value\n",
    "    :return: a numpy array of n_paths columns and n_years*steps_per_year rows\n",
    "    \"\"\"\n",
    "    # Derive per-step Model Parameters from User Specifications\n",
    "    dt = 1/steps_per_year\n",
    "    n_steps = int(n_years*steps_per_year) + 1\n",
    "    # the standard way ...\n",
    "    # rets_plus_1 = np.random.normal(loc=mu*dt+1, scale=sigma*np.sqrt(dt), size=(n_steps, n_scenarios))\n",
    "    # without discretization error ...\n",
    "    rets_plus_1 = np.random.normal(loc=(1+mu)**dt, scale=(sigma*np.sqrt(dt)), size=(n_steps, n_scenarios))\n",
    "    rets_plus_1[0] = 1\n",
    "    ret_val = s_0*pd.DataFrame(rets_plus_1).cumprod() if prices else rets_plus_1-1\n",
    "    return ret_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2245e43-56c2-483c-a2fd-401477343dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
